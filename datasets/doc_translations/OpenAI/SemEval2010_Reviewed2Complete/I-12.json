{
    "id": "I-12",
    "original_text": "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values. The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data. The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating. To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself. The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation. Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations. Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1. INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate. In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty. This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent. The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution. The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames. Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty. In the remainder of this paper, we use the term fast-paced to refer to such environments. In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions. Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning. Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction. That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations. In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame. Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias. We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment. The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process. Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate. Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user. There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same. Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation. The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work. However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets). In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making. In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments. The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating. In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system. Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small. The mechanism was successfully tested using a system that simulates a Coordinators environment. The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains. Section 3 provides an overview of the methods we developed. The implementation, empirical setting, and results are given in Sections 4 and 5. A comparison with related methods is given in Section 6 and conclusions in section 7. 2. PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21]. In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change. Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages. Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners). In this domain, scheduling information and constraints are distributed. Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one. Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.) However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively. The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling. The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling. As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19]. In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction. The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner. This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia]. Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption. This work aims to reduce interruption costs by delaying interruptions to times that are convenient. It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions. By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9]. Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5]. Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions. First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider. Second, the interruptibility-estimation models are task-based. Lastly, it relies on continuous monitoring of a users activities. In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure. As a result, it is difficult to determine the actual attentional state of agent-owners [15]. In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24]. For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions. Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation. The mechanisms described in this paper also presume the existence of such sensors. However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited. Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis. Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function. Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings. The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem. The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized. In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility. The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function. We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages. The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn. In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x). The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit. The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation. The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts. The first part, c divided by F(xrv), represents the expected sampling cost. The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv). Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x). However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.) Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users. For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function. The implementation described in Sections 4-5 relies on this fact. Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions. Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption. This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains. The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information. For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24]. Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information. Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs. Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3. THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment. We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents. The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point. Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy). The accuracy of the estimation will vary widely if it is based on only a small number of observations. For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5). Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function. Eventually this method yields a very accurate estimation for the expected interruption cost. However, in the initial stages of the process, its estimation deviates significantly from the true value. This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions. Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains. One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents. Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner. This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios. Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters. People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions. Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner. When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them. The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically. Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics. It is notable that the cost of transferring observations between different CA modules of different agents is relatively small. This information can be transferred as part of regular negotiation communication between agents. The volume of such communication is negligible: it involves just the transmission of new observations values. In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment. Each new observation obtained either by that CA or any of the other CAs updates this estimation. The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1). Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation. The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners. In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database. The additional observations the CA takes from other agents are used only to model its owners characteristics. Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches. Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce. The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 . While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution. We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population. We then merge the data and rank each measurement from lowest to highest. All sequences of ties are assigned an average rank. From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis. This level of confidence becomes the measure for the level of similarity between the two owners. The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism. Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent. However, cases of identical matches are likely to be very uncommon. Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence. Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence. At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used. In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2). As the number of its direct observations increases, the CA module refines the number of additional observations required. Again, there are two conflicting effects. On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners. On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis. Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis. The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases. At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases. When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function. For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4. EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS. This testbed environment includes a variable number of agents, each corresponding to a single CA module. Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated. The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms. The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped. This type of function is ideal for representing empirical distribution functions. It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1). For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user. Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.) The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted. Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval. The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption. The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption). The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting. Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used. Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models. They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged. The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions. At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5. RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types. The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost. Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2). The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function. Type Agents Rect. Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique. Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs. The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing). The data is given as a function of the accumulated number of observations collected. The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type. Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5. First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data. For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse. Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism. Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all. In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance. Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve. The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types. For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge). Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall. Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data. This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data. Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical. Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated. These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted. They used a multi-rectangular probability distribution function to represent The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment. We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used. We ran 10000 simulation runs. For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated. Each simulation ran 40 time steps. At each time step each one of the agents accumulated one additional observation. Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded. The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents. As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement. Thus, the more data collected, the greater the difference between this latter method and the two other methods. The average difference between selective-sharing and self-learning decreases as more data is collected. Finally, we measured the effect of the number of types in the environment. For this purpose, we used the same self-generation method, but controlled the number of types generated for each run. The number of types is a good indication for the level of heterogeneity in the environment. For each number of types, we ran 10000 simulations. Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent). Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment. As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases. Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates. However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with. In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6. RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper. Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing. However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7]. Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users. This capability is closely related to clustering and classification, an area widely studied in machine learning. Given space considerations, our review of this area is restricted to some representative approaches for clustering. In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains. Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes. An additional difficulty is defining the distance measure. Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3]. However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data. Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes. The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12]. This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution. However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments. For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200). While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity. While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data. To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper. Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data). In these applications, it is used primarily as an identification tool and ranking criterion. 7. DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated. It is computationally lightweight and very simple to execute. Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available. It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique. Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type. The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations. Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments. Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments). Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated. The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned. Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8. ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No. FA8750-05-C-0033. Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government. We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9. REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey. A method, system, and tools for intelligent interruption management. In TAMODIA 05, pages 123-126, New York, NY, USA, 2005. ACM Press. [2] P. Berkhin. Survey of clustering data mining techniques. Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu. Incremental clustering for mining in a data warehousing environment. In Proc. 24th Int. Conf. Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering clusters in large spatial databases with noise. In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen. A decision procedure for autonomous agents to reason about interaction with humans. In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt. Bayesian network classifiers. Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl. Combining collaborative filtering with personal agents for better recommendations. In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair, and E. Horvitz. Sensing techniques for mobile interaction. In UIST 00, pages 91-100, New York, NY, USA, 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel. Models of attention in computing and communication: from principles to applications. Commun. ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier. Whos asking for help?: a bayesian approach to intelligent assistance. In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani. Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence. Prentice Hall, 1997. [12] S. Kullback and R. Leibler. On information and sufficiency. Ann. Math. Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith. Gaze and speech in attentive user interfaces. In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney. On a test of whether one of 2 random variables is stochastically larger than the other. Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure. Technology and command: Implications for military operations in the twenty-first century. Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild. Search. In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado. Machine learning methods for predicting failures in hard drives: A multiple-instance application. J. Mach. Learn. Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz. Estimating information value in collaborative multi-agent planning systems. In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz. Timing interruptions for better human-computer coordinated planning. In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal. The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration. In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper. An application view of coordinators: Coordination managers for first responders. In AAAI, pages 908-915, 2004. [22] F Wilcoxon. Individual comparisons by ranking methods. Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara. Bayesian learning in negotiation. In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen, and T. Ioerger. A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield. In SCI-2001, pages 58-63, 2001. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209",
    "original_translation": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión inteligente de interrupciones. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209",
    "original_sentences": [
        "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
        "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
        "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
        "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
        "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
        "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
        "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
        "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
        "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
        "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
        "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
        "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
        "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
        "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
        "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
        "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
        "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
        "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
        "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
        "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
        "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
        "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
        "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
        "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
        "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
        "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
        "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
        "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
        "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
        "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
        "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
        "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
        "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
        "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
        "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
        "Section 3 provides an overview of the methods we developed.",
        "The implementation, empirical setting, and results are given in Sections 4 and 5.",
        "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
        "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
        "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
        "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
        "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
        "In this domain, scheduling information and constraints are distributed.",
        "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
        "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
        "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
        "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
        "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
        "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
        "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
        "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
        "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
        "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
        "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
        "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
        "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
        "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
        "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
        "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
        "Second, the interruptibility-estimation models are task-based.",
        "Lastly, it relies on continuous monitoring of a users activities.",
        "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
        "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
        "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
        "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
        "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
        "The mechanisms described in this paper also presume the existence of such sensors.",
        "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
        "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
        "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
        "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
        "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
        "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
        "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
        "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
        "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
        "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
        "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
        "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
        "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
        "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
        "The first part, c divided by F(xrv), represents the expected sampling cost.",
        "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
        "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
        "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
        "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
        "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
        "The implementation described in Sections 4-5 relies on this fact.",
        "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
        "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
        "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
        "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
        "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
        "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
        "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
        "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
        "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
        "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
        "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
        "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
        "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
        "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
        "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
        "Eventually this method yields a very accurate estimation for the expected interruption cost.",
        "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
        "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
        "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
        "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
        "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
        "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
        "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
        "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
        "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
        "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
        "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
        "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
        "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
        "This information can be transferred as part of regular negotiation communication between agents.",
        "The volume of such communication is negligible: it involves just the transmission of new observations values.",
        "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
        "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
        "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
        "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
        "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
        "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
        "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
        "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
        "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
        "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
        "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
        "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
        "We then merge the data and rank each measurement from lowest to highest.",
        "All sequences of ties are assigned an average rank.",
        "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
        "This level of confidence becomes the measure for the level of similarity between the two owners.",
        "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
        "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
        "However, cases of identical matches are likely to be very uncommon.",
        "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
        "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
        "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
        "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
        "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
        "Again, there are two conflicting effects.",
        "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
        "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
        "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
        "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
        "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
        "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
        "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
        "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
        "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
        "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
        "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
        "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
        "This type of function is ideal for representing empirical distribution functions.",
        "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
        "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
        "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
        "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
        "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
        "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
        "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
        "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
        "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
        "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
        "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
        "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
        "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
        "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
        "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
        "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
        "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
        "Type Agents Rect.",
        "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
        "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
        "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
        "The data is given as a function of the accumulated number of observations collected.",
        "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
        "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
        "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
        "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
        "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
        "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
        "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
        "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
        "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
        "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
        "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
        "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
        "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
        "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
        "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
        "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
        "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
        "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
        "We ran 10000 simulation runs.",
        "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
        "Each simulation ran 40 time steps.",
        "At each time step each one of the agents accumulated one additional observation.",
        "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
        "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
        "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
        "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
        "The average difference between selective-sharing and self-learning decreases as more data is collected.",
        "Finally, we measured the effect of the number of types in the environment.",
        "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
        "The number of types is a good indication for the level of heterogeneity in the environment.",
        "For each number of types, we ran 10000 simulations.",
        "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
        "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
        "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
        "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
        "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
        "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
        "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
        "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
        "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
        "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
        "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
        "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
        "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
        "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
        "An additional difficulty is defining the distance measure.",
        "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
        "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
        "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
        "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
        "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
        "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
        "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
        "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
        "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
        "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
        "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
        "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
        "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
        "It is computationally lightweight and very simple to execute.",
        "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
        "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
        "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
        "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
        "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
        "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
        "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
        "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
        "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
        "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
        "FA8750-05-C-0033.",
        "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
        "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
        "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
        "A method, system, and tools for intelligent interruption management.",
        "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
        "ACM Press. [2] P. Berkhin.",
        "Survey of clustering data mining techniques.",
        "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
        "Incremental clustering for mining in a data warehousing environment.",
        "In Proc. 24th Int.",
        "Conf.",
        "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
        "A density-based algorithm for discovering clusters in large spatial databases with noise.",
        "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
        "A decision procedure for autonomous agents to reason about interaction with humans.",
        "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
        "Bayesian network classifiers.",
        "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
        "Combining collaborative filtering with personal agents for better recommendations.",
        "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
        "Pierce, M. Sinclair, and E. Horvitz.",
        "Sensing techniques for mobile interaction.",
        "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
        "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
        "Models of attention in computing and communication: from principles to applications.",
        "Commun.",
        "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
        "Whos asking for help? : a bayesian approach to intelligent assistance.",
        "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
        "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
        "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
        "On information and sufficiency.",
        "Ann.",
        "Math.",
        "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
        "Gaze and speech in attentive user interfaces.",
        "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
        "On a test of whether one of 2 random variables is stochastically larger than the other.",
        "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
        "Technology and command: Implications for military operations in the twenty-first century.",
        "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
        "Search.",
        "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
        "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
        "J. Mach.",
        "Learn.",
        "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
        "Estimating information value in collaborative multi-agent planning systems.",
        "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
        "Timing interruptions for better human-computer coordinated planning.",
        "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
        "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
        "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
        "An application view of coordinators: Coordination managers for first responders.",
        "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
        "Individual comparisons by ranking methods.",
        "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
        "Bayesian learning in negotiation.",
        "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
        "Yen, and T. Ioerger.",
        "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
        "In SCI-2001, pages 58-63, 2001.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
    ],
    "translated_text_sentences": [
        "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros.",
        "El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos.",
        "El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando.",
        "Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo.",
        "El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación.",
        "Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes.",
        "Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1.",
        "INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar.",
        "En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre.",
        "Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático.",
        "La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica.",
        "Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados.",
        "Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre.",
        "En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos.",
        "En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones.",
        "Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje.",
        "Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción.",
        "Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones.",
        "En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario.",
        "Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto.",
        "Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico.",
        "El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje.",
        "Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar.",
        "Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente.",
        "No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales.",
        "Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación.",
        "El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo.",
        "Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos).",
        "En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones.",
        "En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido.",
        "El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando.",
        "En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema.",
        "Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño.",
        "El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores.",
        "La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido.",
        "La sección 3 proporciona una visión general de los métodos que desarrollamos.",
        "La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5.",
        "Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2.",
        "La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21].",
        "En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación.",
        "Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona.",
        "Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios).",
        "En este dominio, la información de programación y las restricciones están distribuidas.",
        "Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local.",
        "Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos).",
        "Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida.",
        "La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación.",
        "El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes.",
        "Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19].",
        "En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción.",
        "Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario.",
        "Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros].",
        "La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción.",
        "Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes.",
        "Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones.",
        "Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9].",
        "El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5].",
        "Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones.",
        "Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos.",
        "Segundo, los modelos de estimación de interrumpibilidad son basados en tareas.",
        "Por último, depende de la monitorización continua de las actividades de un usuario.",
        "En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna.",
        "Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15].",
        "En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24].",
        "Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a...",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones.",
        "Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento.",
        "Los mecanismos descritos en este documento también presuponen la existencia de tales sensores.",
        "Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados.",
        "Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua.",
        "Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad.",
        "Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos.",
        "El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema.",
        "La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción.",
        "En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada.",
        "El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria.",
        "Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda.",
        "La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite.",
        "En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x).",
        "El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo.",
        "El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación.",
        "El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes.",
        "La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo.",
        "El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv).",
        "Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x).",
        "Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.)",
        "Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios.",
        "Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución.",
        "La implementación descrita en las Secciones 4-5 se basa en este hecho.",
        "Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones.",
        "Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción.",
        "Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido.",
        "El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información.",
        "Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24].",
        "Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información.",
        "Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita.",
        "Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3.",
        "EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno.",
        "Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes.",
        "El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación.",
        "Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva).",
        "La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones.",
        "Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5).",
        "Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución.",
        "Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción.",
        "Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real.",
        "Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas.",
        "Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido.",
        "Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios.",
        "Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA.",
        "Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares.",
        "Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados.",
        "Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones.",
        "Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario.",
        "Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos.",
        "El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios.",
        "Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios.",
        "Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo.",
        "Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes.",
        "El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones.",
        "En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno.",
        "Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación.",
        "El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1).",
        "Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación.",
        "El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios.",
        "En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente.",
        "Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios.",
        "La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos.",
        "Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos.",
        "La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14].",
        "Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua.",
        "Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población.",
        "Luego fusionamos los datos y clasificamos cada medición de menor a mayor.",
        "Todas las secuencias de empates se les asigna un rango promedio.",
        "De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada.",
        "El Sexto Internacional.",
        "En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula.",
        "Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios.",
        "El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente.",
        "Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario.",
        "Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes.",
        "Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto.",
        "Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza.",
        "Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud.",
        "En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2).",
        "A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas.",
        "Nuevamente, hay dos efectos conflictivos.",
        "Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios.",
        "Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis.",
        "Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon.",
        "La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta.",
        "Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas.",
        "Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen.",
        "Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4.",
        "ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators.",
        "Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único.",
        "Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando.",
        "El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones.",
        "Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular.",
        "Este tipo de función es ideal para representar funciones de distribución empíricas.",
        "Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1).",
        "Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico.",
        "Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme).",
        "El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar.",
        "Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto.",
        "El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto.",
        "El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio).",
        "El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando.",
        "Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados.",
        "Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica.",
        "También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado.",
        "El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente.",
        "En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5.",
        "RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad.",
        "La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción.",
        "Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2).",
        "El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos.",
        "Agentes de tipado rect.",
        "El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva.",
        "Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación.",
        "Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva).",
        "Los datos se presentan como una función del número acumulado de observaciones recopiladas.",
        "El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo.",
        "De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5.",
        "Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados.",
        "Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor.",
        "En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo.",
        "Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos.",
        "A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento.",
        "Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje.",
        "El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos.",
        "Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge).",
        "Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general.",
        "En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos.",
        "Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo.",
        "Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica.",
        "Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente.",
        "Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido.",
        "Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno.",
        "Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados.",
        "Realizamos 10000 ejecuciones de simulación.",
        "Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria.",
        "Cada simulación se ejecutó durante 40 pasos de tiempo.",
        "En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional.",
        "Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8).",
        "La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes.",
        "Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional.",
        "Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos.",
        "La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos.",
        "Finalmente, medimos el efecto del número de tipos en el entorno.",
        "Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución.",
        "El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente.",
        "Para cada número de tipos, realizamos 10000 simulaciones.",
        "La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente).",
        "Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno.",
        "Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos.",
        "Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora.",
        "Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información.",
        "En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6.",
        "TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento.",
        "El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo.",
        "Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7].",
        "La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios.",
        "Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático.",
        "Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación.",
        "A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios.",
        "De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos.",
        "Una dificultad adicional es definir la medida de distancia.",
        "Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3].",
        "Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes.",
        "Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales.",
        "El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12].",
        "Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria.",
        "Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos.",
        "Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200).",
        "Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto.",
        "Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados.",
        "Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento.",
        "El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays).",
        "En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación.",
        "DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar.",
        "Es computacionalmente ligero y muy simple de ejecutar.",
        "La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo.",
        "También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única.",
        "Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo.",
        "Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones.",
        "Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado.",
        "Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate).",
        "La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua.",
        "El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo.",
        "Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones.",
        "AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International.",
        "FA8750-05-C-0033.",
        "Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos.",
        "Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9.",
        "REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey.",
        "Un método, sistema y herramientas para la gestión inteligente de interrupciones.",
        "En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005.",
        "ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin.",
        "Encuesta de técnicas de minería de datos de agrupamiento.",
        "Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu.",
        "Agrupamiento incremental para la minería en un entorno de almacenamiento de datos.",
        "En Proc. 24th Int.",
        "This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation?",
        "Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu.",
        "Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido.",
        "En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen.",
        "Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos.",
        "En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt.",
        "Clasificadores de redes bayesianas.",
        "Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl.",
        "Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas.",
        "En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J.",
        "Pierce, M. Sinclair y E. Horvitz.",
        "Técnicas de detección para interacción móvil.",
        "En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000.",
        "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel.",
        "Modelos de atención en informática y comunicación: de principios a aplicaciones.",
        "Comunicación.",
        "ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier.",
        "¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente.",
        "En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani.",
        "Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial.",
        "Prentice Hall, 1997. [12] S. Kullback y R. Leibler.",
        "Sobre información y suficiencia.",
        "Ana.",
        "Matemáticas.",
        "Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith.",
        "Mirada y habla en interfaces de usuario atentas.",
        "En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney.",
        "En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra.",
        "Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure.",
        "Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno.",
        "Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild.",
        "Buscar.",
        "En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado.",
        "Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias.",
        "J. Mach.",
        "Aprender.",
        "Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz.",
        "Estimación del valor de la información en sistemas colaborativos de planificación multiagente.",
        "En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz.",
        "Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras.",
        "En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal.",
        "El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte.",
        "En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper.",
        "Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes.",
        "En AAAI, páginas 908-915, 2004. [22] F Wilcoxon.",
        "Comparaciones individuales mediante métodos de clasificación.",
        "Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara.",
        "Aprendizaje bayesiano en negociación.",
        "En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
        "Yen y T. Ioerger.",
        "Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla.",
        "En SCI-2001, páginas 58-63, 2001.",
        "El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209"
    ],
    "error_count": 2,
    "keys": {
        "probabilistic parameter": {
            "translated_key": "parámetro probabilístico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a <br>probabilistic parameter</br> that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a <br>probabilistic parameter</br> by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "This paper addresses the problem of learning the distribution of the values of a <br>probabilistic parameter</br> that represents a characteristic of a person who is interacting with a computer agent.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a <br>probabilistic parameter</br> by taking advantage of data collected by other CAs in its environment."
            ],
            "translated_annotated_samples": [
                "Este documento aborda el problema de aprender la distribución de los valores de un <br>parámetro probabilístico</br> que representa una característica de una persona que está interactuando con un agente informático.",
                "EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un <br>parámetro probabilístico</br> aprovechando los datos recopilados por otros CAs en su entorno."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un <br>parámetro probabilístico</br> que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un <br>parámetro probabilístico</br> aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión inteligente de interrupciones. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "agent": {
            "translated_key": "agente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an <br>agent</br>, operating within a multi-<br>agent</br> system, has no a priori information about the structure of the distribution of parameter values.",
                "The <br>agent</br> must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the <br>agent</br> to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer <br>agent</br>.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an <br>agent</br> accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the <br>agent</br> is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-<br>agent</br> distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-<br>agent</br> setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an <br>agent</br> to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given <br>agent</br> depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-<br>agent</br> settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each <br>agent</br> obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each <br>agent</br> operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each <br>agent</br> receives a different view of the tasks and structures that constitute the full multi-<br>agent</br> problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one <br>agent</br> must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The <br>agent</br>-owner relationship is a collaborative one, with the <br>agent</br> needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of <br>agent</br>-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an <br>agent</br> cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an <br>agent</br> needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The <br>agent</br> can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an <br>agent</br> can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the <br>agent</br> can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) The more observations an <br>agent</br> can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the <br>agent</br> is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other <br>agent</br> is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another <br>agent</br> is smaller than the overall number of observations the other <br>agent</br> has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners <br>agent</br>.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each <br>agent</br> is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-<br>agent</br> scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., <br>agent</br> III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the <br>agent</br> of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-<br>agent</br> environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each <br>agent</br>).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every <br>agent</br> will have a potential similar <br>agent</br> to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 <br>agent</br> scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an <br>agent</br> to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an <br>agent</br> can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-<br>agent</br> planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent <br>agent</br> architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an <br>agent</br>, operating within a multi-<br>agent</br> system, has no a priori information about the structure of the distribution of parameter values.",
                "The <br>agent</br> must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the <br>agent</br> to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer <br>agent</br>.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an <br>agent</br> accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution."
            ],
            "translated_annotated_samples": [
                "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un <br>agente</br>, operando dentro de un sistema multi<br>agente</br>, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros.",
                "El <br>agente</br> debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos.",
                "El artículo describe un mecanismo que permite al <br>agente</br> mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros <br>agente</br>s con los que está coordinando.",
                "Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un <br>agente</br> informático.",
                "La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del <br>agente</br>. El escenario básico que consideramos es aquel en el que un <br>agente</br> acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un <br>agente</br>, operando dentro de un sistema multi<br>agente</br>, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El <br>agente</br> debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al <br>agente</br> mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros <br>agente</br>s con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un <br>agente</br> informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del <br>agente</br>. El escenario básico que consideramos es aquel en el que un <br>agente</br> acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "information sharing": {
            "translated_key": "compartir información",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "decision making": {
            "translated_key": "toma de decisiones",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for <br>decision making</br> in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents <br>decision making</br>1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs <br>decision making</br> process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for <br>decision making</br> in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents <br>decision making</br>1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "This error could seriously degrade the CAs <br>decision making</br> process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions."
            ],
            "translated_annotated_samples": [
                "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la <br>toma de decisiones</br> en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros.",
                "La característica a ser aprendida está claramente relacionada con un factor importante en la <br>toma de decisiones</br> del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica.",
                "Este error podría degradar seriamente el proceso de <br>toma de decisiones</br> de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la <br>toma de decisiones</br> en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la <br>toma de decisiones</br> del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de <br>toma de decisiones</br> de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión inteligente de interrupciones. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "fast-paced environment": {
            "translated_key": "entorno de ritmo rápido",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a <br>fast-paced environment</br> (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a <br>fast-paced environment</br> (e.g., rescue environments)."
            ],
            "translated_annotated_samples": [
                "Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un <br>entorno de ritmo rápido</br> (por ejemplo, entornos de rescate)."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un <br>entorno de ritmo rápido</br> (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión inteligente de interrupciones. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multi-agent distributed system": {
            "translated_key": "sistema distribuido de múltiples agentes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a <br>multi-agent distributed system</br> in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "We consider this problem in the context of a <br>multi-agent distributed system</br> in which computer agents support people who are carrying out complex tasks in a dynamic environment."
            ],
            "translated_annotated_samples": [
                "Consideramos este problema en el contexto de un <br>sistema distribuido de múltiples agentes</br> en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un <br>sistema distribuido de múltiples agentes</br> en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión inteligente de interrupciones. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "learning mechanism": {
            "translated_key": "mecanismo de aprendizaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a <br>learning mechanism</br> must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our <br>learning mechanism</br>, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-<br>learning mechanism</br> is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "Therefore, to use a data-sharing approach, a <br>learning mechanism</br> must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "In our <br>learning mechanism</br>, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-<br>learning mechanism</br> is constant regardless of the number of types in the environment."
            ],
            "translated_annotated_samples": [
                "Por lo tanto, para utilizar un enfoque de intercambio de datos, un <br>mecanismo de aprendizaje</br> debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación.",
                "En nuestro <br>mecanismo de aprendizaje</br>, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno.",
                "Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del <br>mecanismo de autoaprendizaje</br> es constante independientemente del número de tipos en el entorno."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un <br>mecanismo de aprendizaje</br> debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro <br>mecanismo de aprendizaje</br>, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del <br>mecanismo de autoaprendizaje</br> es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión inteligente de interrupciones. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209 ",
            "candidates": [],
            "error": [
                [
                    "mecanismo de aprendizaje",
                    "mecanismo de aprendizaje",
                    "mecanismo de autoaprendizaje"
                ]
            ]
        },
        "selective-sharing": {
            "translated_key": "compartición selectiva",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as <br>selective-sharing</br>, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE <br>selective-sharing</br> MECHANISM This section presents the <br>selective-sharing</br> mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The <br>selective-sharing</br> mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the <br>selective-sharing</br> mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the <br>selective-sharing</br> mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the <br>selective-sharing</br> mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the <br>selective-sharing</br> mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the <br>selective-sharing</br> mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and <br>selective-sharing</br>).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All <br>selective-sharing</br> % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the <br>selective-sharing</br> mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the <br>selective-sharing</br> mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The <br>selective-sharing</br> mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the <br>selective-sharing</br> mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the <br>selective-sharing</br> mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the <br>selective-sharing</br> mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the <br>selective-sharing</br> mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate <br>selective-sharing</br>, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All <br>selective-sharing</br> % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed <br>selective-sharing</br> method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between <br>selective-sharing</br> and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the <br>selective-sharing</br> mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the <br>selective-sharing</br> mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the <br>selective-sharing</br> mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to <br>selective-sharing</br>.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "<br>selective-sharing</br> relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The <br>selective-sharing</br> mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "<br>selective-sharing</br> allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, <br>selective-sharing</br> does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the <br>selective-sharing</br> mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the <br>selective-sharing</br> mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "Our adaptive approach, which we will refer to throughout the paper as <br>selective-sharing</br>, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "THE <br>selective-sharing</br> MECHANISM This section presents the <br>selective-sharing</br> mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "The <br>selective-sharing</br> mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the <br>selective-sharing</br> mechanism.",
                "At the beginning of its process, the <br>selective-sharing</br> mechanism has almost no data to rely on, and thus no similarity measure can be used."
            ],
            "translated_annotated_samples": [
                "Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como <br>compartición selectiva</br>, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño.",
                "EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el <br>mecanismo de compartición selectiva</br> mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno.",
                "El mecanismo de <br>intercambio selectivo</br> se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios.",
                "El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del <br>mecanismo de selección de compartir selectivamente</br>.",
                "Al principio de su proceso, el <br>mecanismo de selección y compartición</br> casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como <br>compartición selectiva</br>, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el <br>mecanismo de compartición selectiva</br> mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de <br>intercambio selectivo</br> se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del <br>mecanismo de selección de compartir selectivamente</br>. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el <br>mecanismo de selección y compartición</br> casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. ",
            "candidates": [],
            "error": [
                [
                    "compartición selectiva",
                    "mecanismo de compartición selectiva",
                    "intercambio selectivo",
                    "mecanismo de selección de compartir selectivamente",
                    "mecanismo de selección y compartición"
                ]
            ]
        },
        "parameter estimation": {
            "translated_key": "estimación de parámetros",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "<br>parameter estimation</br> IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "<br>parameter estimation</br> IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21]."
            ],
            "translated_annotated_samples": [
                "La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre gestión de interrupciones revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión inteligente de interrupciones. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "adjustable autonomy": {
            "translated_key": "autonomía ajustable",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the interruption management literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent interruption management.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "interruption management": {
            "translated_key": "gestión de interrupciones",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data David Sarne, Barbara J. Grosz School of Engineering and Applied Sciences Harvard University, Cambridge MA 02138 USA {sarned,grosz}@eecs.harvard.edu ABSTRACT This paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent, operating within a multi-agent system, has no a priori information about the structure of the distribution of parameter values.",
                "The agent must be able to produce estimations even when it may have made only a small number of direct observations, and thus it must be able to operate with sparse data.",
                "The paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating.",
                "To avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations, the mechanism weighs the contributions of other agents observations based on a real-time estimation of the level of similarity between each of these agents and itself.",
                "The coordination autonomy module of a coordination-manager system provided an empirical setting for evaluation.",
                "Simulation-based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agents own observations as well as estimations based on an unweighted aggregate of all other agents observations.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Parameter learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Intelligent agents, Multiagent systems; G.3 [Mathematics of Computing]: Probability and Statistics-Distribution functions General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION For many real-world scenarios, autonomous agents need to operate in dynamic, uncertain environments in which they have only incomplete information about the results of their actions and characteristics of other agents or people with whom they need to cooperate or collaborate.",
                "In such environments, agents can benefit from sharing information they gather, pooling their individual experiences to improve their estimations of unknown parameters required for reasoning about actions under uncertainty.",
                "This paper addresses the problem of learning the distribution of the values of a probabilistic parameter that represents a characteristic of a person who is interacting with a computer agent.",
                "The characteristic to be learned is (or is clearly related to) an important factor in the agents decision making.1 The basic setting we consider is one in which an agent accumulates observations about a specific user characteristic and uses them to produce a timely estimate of some measure that depends on that characteristics distribution.",
                "The mechanisms we develop are designed to be useful in a range of application domains, such as disaster rescue, that are characterized by environments in which conditions may be rapidly changing, actions (whether of autonomous agents or of people) and the overall operations occur at a fast pace, and decisions must be made within tightly constrained time frames.",
                "Typically, agents must make decisions in real time, concurrent with task execution, and in the midst of great uncertainty.",
                "In the remainder of this paper, we use the term fast-paced to refer to such environments.",
                "In fast-paced environments, information gathering may be limited, and it is not possible to learn offline or to wait until large amounts of data are collected before making decisions.",
                "Fast-paced environments impose three constraints on any mechanism for learning a distribution function (including the large range of Bayesian update techniques [23]): (a) the no structure constraint: no a priori information about the structure of the estimated parameters distribution nor any initial data from which such structure can be inferred is available; (b) the limited use constraint: agents typically need to produce only a small number of estimations in total for this parameter; (c) the early use constraint: high accuracy is a critical requirement even in the initial stages of learning.",
                "Thus, the goal of the estimation methods presented in this paper is to minimize the average error over time, rather than to determine an accurate value at the end of a long period of interaction.",
                "That is, the agent is expected to work with the user for a limited time, and it attempts to minimize the overall error in its estimations.",
                "In such environments, an agents individually acquired data (its own observations) are too sparse for it to obtain good estimations in the requisite time frame.",
                "Given the no-structure-constraint of the environment, approaches that depend on structured distributions may result in a significantly high estimation bias.",
                "We consider this problem in the context of a multi-agent distributed system in which computer agents support people who are carrying out complex tasks in a dynamic environment.",
                "The fact that agents are part of a multi-agent setting, in which other agents may 1 Learning the distribution rather than just determining some value in the distribution is important whenever the overall shape of the distribution and not just such individual features as mean are important. also be gathering data to estimate a similar characteristic of their users, offers the possibility for an agent to augment its own observations with those of other agents, thus improving the accuracy of its learning process.",
                "Furthermore, in the environments we consider, agents are usually accumulating data at a relatively similar rate.",
                "Nonetheless, the extent to which the observations of other agents will be useful to a given agent depends on the extent to which their users characteristics distributions are correlated with that of this agents user.",
                "There is no guarantee that the distribution for two different agents is highly, positively correlated, let alone that they are the same.",
                "Therefore, to use a data-sharing approach, a learning mechanism must be capable of effectively identifying the level of correlation between the data collected by different agents and to weigh shared data depending on the level of correlation.",
                "The design of a coordination autonomy (CA) module within a coordination-manager system (as part of the DARPA Coordinators project [18]), in which agents support a distributed scheduling task, provided the initial motivation and a conceptual setting for this work.",
                "However, the mechanisms themselves are general and can be applied not only to other fast-paced domains, but also in other multi-agent settings in which agents are collecting data that overlaps to some extent, at approximately similar rates, and in which the environment imposes the no-structure, limited- and early-use constraints defined above (e.g., exploration of remote planets).",
                "In particular, our techniques would be useful in any setting in which a group of agents undertakes a task in a new environment, with each agent obtaining observations at a similar rate of individual parameters they need for their decision-making.",
                "In this paper, we present a mechanism that was used for learning key user characteristics in fast-paced environments.",
                "The mechanism provides relatively accurate estimations within short time frames by augmenting an individual agents direct observations with observations obtained by other agents with which it is coordinating.",
                "In particular, we focus on the related problems of estimating the cost of interrupting a person and estimating the probability that that person will have the information required by the system.",
                "Our adaptive approach, which we will refer to throughout the paper as selective-sharing, allows our CA to improve the accuracy of its distribution-based estimations in comparison to relying only on the interactions with a specific user (subsequently, self-learning) or pooling all data unconditionally (average all), in particular when the number of available observations is relatively small.",
                "The mechanism was successfully tested using a system that simulates a Coordinators environment.",
                "The next section of the paper describes the problem of estimating user-related parameters in fastpaced domains.",
                "Section 3 provides an overview of the methods we developed.",
                "The implementation, empirical setting, and results are given in Sections 4 and 5.",
                "A comparison with related methods is given in Section 6 and conclusions in section 7. 2.",
                "PARAMETER ESTIMATION IN FASTPACED DOMAINS The CA module and algorithms we describe in this paper were developed and tested in the Coordinators domain [21].",
                "In this domain, autonomous agents, called Coordinators, are intended to help maximize an overall team objective by handling changes in the task schedule as conditions of operation change.",
                "Each agent operates on behalf of its owner (e.g., the team leader of a firstresponse team or a unit commander) whose schedule it manages.",
                "Thus, the actual tasks being scheduled are executed either by owners or by units they oversee, and the agents responsibility is limited to maintaining the scheduling of these tasks and coordinating with the agents of other human team members (i.e., other owners).",
                "In this domain, scheduling information and constraints are distributed.",
                "Each agent receives a different view of the tasks and structures that constitute the full multi-agent problem-typically only a partial, local one.",
                "Schedule revisions that affect more than one agent must be coordinated, so agents thus must share certain kinds of information. (In a team context they may be designed to share other types as well.)",
                "However, the fast-paced nature of the domain constrains the amount of information they can share, precluding a centralized solution; scheduling problems must be solved distributively.",
                "The agent-owner relationship is a collaborative one, with the agent needing to interact with its owner to obtain task and environment information relevant to scheduling.",
                "The CA module is responsible for deciding intelligently when and how to interact with the owner for improving the agents scheduling.",
                "As a result, the CA must estimate the expected benefit of any such interaction and the cost associated with it [19].",
                "In general, the net benefit of a potential interaction is PV − C, where V is the value of the information the user may have, P is the probability that the user has this information, and C is the cost associated with an interaction.",
                "The values of P, V , and C are time-varying, and the CA estimates their value at the intended time of initiating the interaction with its owner.",
                "This paper focuses on the twin problems of estimating the parameters P and C, both of which are user-centric in the sense of being determined by characteristics of the owner and the environment in which the owner is operating); it presumes a mechanism for determining V [18]. 2.1 Estimating Interruption Costs The cost of interrupting owners derives from the potential degradation in performance of tasks they are doing caused by the disruption [1; 9, inter alia].",
                "Research on interaction management has deployed sensor-based statistical models of human interruptibility to infer the degree of distraction likely to be caused by an interruption.",
                "This work aims to reduce interruption costs by delaying interruptions to times that are convenient.",
                "It typically uses Bayesian models to learn a users current or likely future focus of attention from an ongoing stream of actions.",
                "By using sensors to provide continuous incoming indications of the users attentional state, these models attempt to provide a means for computing probability distributions over a users attention and intentions [9].",
                "Work which examines such interruptibility-cost factors as user frustration and distractability [10] includes work on the cost of repeatedly bothering the user which takes into account the fact that recent interruptions and difficult questions should carry more weight than interruptions in the distant past or straightforward questions [5].",
                "Although this prior work uses interruptibility estimates to balance the interactions estimated importance against the degree of distraction likely to be caused, it differs from the fast-paced environments problem we address in three ways that fundamentally change the nature of the problem and hence alter the possible solutions.",
                "First, it considers settings in which the computer system has information that may be relevant to its user rather than the user (owner) having information needed by the system, which is the complement of the information exchange situation we consider.",
                "Second, the interruptibility-estimation models are task-based.",
                "Lastly, it relies on continuous monitoring of a users activities.",
                "In fast-paced environments, there usually is no single task structure, and some of the activities themselves may have little internal structure.",
                "As a result, it is difficult to determine the actual attentional state of agent-owners [15].",
                "In such settings, owners must make complex decisions that typically involve a number of other members of their units, while remaining reactive to events that diverge from expectations [24].",
                "For instance, during disaster rescue, a first-response unit may begin rescuing survivors trapped in a burning house, when a wall collapses suddenly, forcing the unit to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 203 retract and re-plan their actions.",
                "Prior work has tracked users focus of attention using a range of devices, including those able to monitor gestures [8] and track eyegaze to identify focus of visual attention [13, 20], thus enabling estimations of cognitive load and physical indicators of performance degradation.",
                "The mechanisms described in this paper also presume the existence of such sensors.",
                "However, in contrast to prior work, which relies on these devices operating continuously, our mechanism presumes that fast-paced environments only allow for the activation of sensors for short periods of time on an ad-hoc basis, because agents resources are severely limited.",
                "Methods that depend on predicting what a person will do next based only on what the user is currently doing (e.g., MDPs) are not appropriate for modeling focus of attention in fast-paced domains, because an agent cannot rely on a persons attentional state being well structured and monitoring can only be done on a sporadic, non-continuous basis.",
                "Thus, at any given time, the cost of interaction with the user is essentially probabilistic, as reflected over a single random monitoring event, and can be assigned a probability distribution function.",
                "Consequently, in fast-paced environments, an agent needs a sampling strategy by which the CA samples its owners interruptibility level (with some cost) and decides whether to initiate an interaction at this specific time or to delay until a lower cost is observed in future samplings.",
                "The method we describe in the remainder of this subsection applies concepts from economic search theory [16] to this problem.",
                "The CAs cost estimation uses a mechanism that integrates the distribution of an owners interruptibility level (as estimated by the CA) into an economic search strategy, in a way that the overall combined cost of sensor costs and interaction costs is minimized.",
                "In its most basic form, the economic search problem aims to identify an opportunity that will minimize expected cost or maximize expected utility.",
                "The search process itself is associated with a cost, and opportunities (in our case, interruption opportunities) are associated with a stationary distribution function.",
                "We use a sequential search strategy [16] in which one observation is drawn at a time, over multiple search stages.",
                "The dominating strategy in this model is a reservation-value based strategy which determines a lower bound, and keeps drawing samples as long as no opportunity above the bound was drawn.",
                "In particular, we consider the situation in which an agents owner has an interruption cost described by a probability distribution function (pdf) f(x) and a cumulative distribution function (cdf) F(x).",
                "The agent can activate sensing devices to get an estimation of the interruption cost, x, at the current time, but there is a cost c of operating the sensing devices for a single time unit.",
                "The CA module sets a reservation value and as long as the sensor-based observation x is greater than this reservation value, the CA will wait and re-sample the user for a new estimation.",
                "The expected cost, V (xrv), using such a strategy with reservation value xrv is described by Equation 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv) , (1) which decomposes into two parts.",
                "The first part, c divided by F(xrv), represents the expected sampling cost.",
                "The second, the integral divided by F(xrv), represents the expected cost of interruption, because the expected number of search cycles is (random) geometric and the probability of success is F(xrv).",
                "Taking the derivative of the left-hand-side of Equation 1 and equating it to zero, yields the characteristics of the optimal reservation value, namely x∗ rv must satisfy, V (x∗ rv) = x∗ rv. (2) Substituting (2) in Equation 1 yields Equation 3 (after integration by parts) from which the optimal reservation value, x∗ rv, and consequently (from Equation 2) V (x∗ rv) can be computed. c = Z x∗ rv y=0 F(y) (3) This method, which depends on extracting the optimal sequence of sensor-based user sampling, relies heavily on the structure of the distribution function, f(x).",
                "However, we need only a portion of the distribution function, namely from the origin to the reservation value. (See Equation 1 and Figure 1.)",
                "Thus, when we consider sharing data, it is not necessary to rely on complete similarity in the distribution function of different users.",
                "For some parameters, including the users interruptibility level, it is enough to rely on similarity in the relevant portion of the distribution function.",
                "The implementation described in Sections 4-5 relies on this fact.",
                "Figure 1: The distribution structure affecting the expected costs calculation 2.2 Estimating the Probability of Having Information One way an agent can estimate the probability a user will have information it needs (e.g., will know at a specific interruption time, with some level of reliability, the actual outcome of a task currently being executed) is to rely on prior interactions with this user, calculating the ratio between the number of times the user had the information and the total number of interactions.",
                "Alternatively, the agent can attempt to infer this probability from measurable characteristics of the users behavior, which it can assess without requiring an interruption.",
                "This indirect approach, which does not require interrupting the user, is especially useful in fast-paced domains.",
                "The CA module we designed uses such an indirect method: ownerenvironment interactions are used as a proxy for measuring whether the owner has certain information.",
                "For instance, in Coordinatorslike scenarios, owners may obtain a variety of information through occasional coordination meetings of all owners, direct communication with other individual owners participating in the execution of a joint task (through which they may learn informally about the existence or status of other actions they are executing), open communications they overhear (e.g. if commanders leave their radios open, they can listen to messages associated with other teams in their area), and other formal or informal communication channels [24].",
                "Thus, owners levels of communication with others, which can be obtained without interrupting them, provide some indication of the frequency with which they obtain new information.",
                "Given occasional updates about its owners level of communication, the CA can estimate the probability that a random interaction with the owner will yield the information it needs.",
                "Denoting the probability distribution function of the amount of communication the user generally maintains with its environment by g(x), and using the transformation function Z(x), mapping from a level of communication, x, to a probability of having the information, the expected probability of getting the information that is needed from the owner when interrupting at a given time can be calculated from P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) The more observations an agent can accumulate about the distribution of the frequency of an owners interaction with the environment at a given time, the better it can estimate the probability the owner has the information needed by the system. 3.",
                "THE SELECTIVE-SHARING MECHANISM This section presents the selective-sharing mechanism by which the CA learns the distribution function of a probabilistic parameter by taking advantage of data collected by other CAs in its environment.",
                "We first explain the need for increasing the number of observations used as the basis of estimation and then present a method for determining how much data to adopt from other agents.",
                "The most straightforward method for the CA to learn the distribution functions associated with the different parameters characterizing an owner is by building a histogram based on the observations it has accumulated up to the estimation point.",
                "Based on this histogram, the CA can estimate the parameter either by taking into account the entire range of values (e.g., to estimate the mean) or a portion of it (e.g., to find the expected cost when using a reservation-value-based strategy).",
                "The accuracy of the estimation will vary widely if it is based on only a small number of observations.",
                "For example, Figure 2 illustrates the reservation-value-based cost calculated according to observations received from an owner with a uniform interruption cost distribution U(0, 100) as a function of the number of accumulated observations used for generating the distribution histogram. (In this simulation, device activation cost was taken to be c = 0.5).",
                "Figure 2: The convergence of a single CA to its optimal strategy These deviations from the actual (true) value (which is 10 in this case, according to Equation 3) is because the sample used in each stage cannot accurately capture the actual structure of the distribution function.",
                "Eventually this method yields a very accurate estimation for the expected interruption cost.",
                "However, in the initial stages of the process, its estimation deviates significantly from the true value.",
                "This error could seriously degrade the CAs decision making process: underestimating the cost may result in initiating costly, non-beneficial interactions, and overestimating the cost might result in missing opportunities for valuable interactions.",
                "Any improvement that can be achieved in predicting the cost values, especially in the initial stages of learning, can make a significant difference in performance, especially because the agent is severely limited in the number of times it can interact with its owner in fastpaced domains.",
                "One way to decrease the deviation from the actual value is by augmenting the data the CA acquires by observing its owner with observations made by other owners agents.",
                "Such an approach depends on identifying other owners with distribution functions for the characteristic of interest similar to the CAs owner.",
                "This dataaugmentation idea is simple: different owners may exhibit similar basic behaviors or patterns in similar fast-paced task scenarios.",
                "Since they are all coordinating on a common overall task and are operating in the same environment, it is reasonable to assume some level of similarity in the distribution function of their modeled parameters.",
                "People vary in their behavior, so, obviously, there may be different types of owners: some will emphasize communication with their teams, and some will spend more time on map-based planning; some will dislike being disturbed while trying to evaluate their teams progress, while others may be more open to interruptions.",
                "Consequently, an owners CA is likely to be able to find some CAs that are working with owners who are similar to its owner.",
                "When adopting data collected by other agents, the two main questions are which agents the CA should rely on and to what extent it should rely on each of them.",
                "The selective-sharing mechanism relies on a statistical measure of similarity that allows the CA of any specific user to identify the similarity between its owner and other owners dynamically.",
                "Based on this similarity level, the CA decides if and to what degree to import other CAs data in order to augment its direct observations, and thus to enable better modeling of its owners characteristics.",
                "It is notable that the cost of transferring observations between different CA modules of different agents is relatively small.",
                "This information can be transferred as part of regular negotiation communication between agents.",
                "The volume of such communication is negligible: it involves just the transmission of new observations values.",
                "In our learning mechanism, the CA constantly updates its estimation of the level of similarity between its owner and the owners represented by other CAs in the environment.",
                "Each new observation obtained either by that CA or any of the other CAs updates this estimation.",
                "The similarity level is determined using the Wilcoxon rank-sum test (Subsection 3.1).",
                "Whenever it is necessary to produce a parameter estimate, the CA decides on the number of additional observations it intends to rely on for extracting its estimation.",
                "The number of additional observations to be taken from each other agent is a function of the number of observations it currently has from former interactions with its owner and the level of confidence the CA has in the similarity between its owner and other owners.",
                "In most cases, the number of observations the CA will want to take from another agent is smaller than the overall number of observations the other agent has; thus, it randomly samples (without repetitions) the required number of observations from this other agents database.",
                "The additional observations the CA takes from other agents are used only to model its owners characteristics.",
                "Future similarity level determination is not affected by this information augmentation procedure. 3.1 The Wilcoxon Test We use a nonparametric method (i.e., one that makes no assumptions about the parametric form of the distributions each set is drawn from), because user characteristics in fast-paced domains do not have the structure needed for parametric approaches.",
                "Two additional advantages of a non-parametric approach are their usefulness for dealing with unexpected, outlying observations (possibly problematic for a parametric approach), and the fact that non-parametric approaches are computationally very simple and thus ideal for settings in which computational resources are scarce.",
                "The Wilcoxon rank-sum test we use is a nonparametric alternative to the two-sample t-test [22, 14]2 .",
                "While the t-test compares means, the Wilcoxon test can be used to test the null hypothesis that two populations X and Y have the same continuous distribution.",
                "We assume that we have independent random samples {x1, x2, ..., xm} and {y1, y2, ..., yn}, of sizes m and n respectively, from each population.",
                "We then merge the data and rank each measurement from lowest to highest.",
                "All sequences of ties are assigned an average rank.",
                "From the sum of the ranks of the smaller 2 Chi-Square Goodness-of-Fit Test is for a single sample and thus not suitable.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 205 sample, we calculate the test statistic and extract the level of confidence for rejecting the null hypothesis.",
                "This level of confidence becomes the measure for the level of similarity between the two owners.",
                "The Wilcoxon test does not require that the data originates from a normally distributed population or that the distribution is characterized by a finite set of parameters. 3.2 Determining Required Information Correctly identifying the right number of additional observations to gather is a key determinant of success of the selective-sharing mechanism.",
                "Obviously, if the CA can identify another owner who has identical characteristics to the owner it represents, then it should use all of the observations collected by that owners agent.",
                "However, cases of identical matches are likely to be very uncommon.",
                "Furthermore, even to establish that another user is identical to its own, the CA would need substantial sample sizes to have a relatively high level of confidence.",
                "Thus, usually the CA needs to decide how much to rely on another agents data while estimating various levels of similarity with a changing level of confidence.",
                "At the beginning of its process, the selective-sharing mechanism has almost no data to rely on, and thus no similarity measure can be used.",
                "In this case, the CA module relies heavily on other agents, in the expectation that all owners have some basic level of similarity in their distribution (see Section 2).",
                "As the number of its direct observations increases, the CA module refines the number of additional observations required.",
                "Again, there are two conflicting effects.",
                "On one hand, the more data the CA has, the better it can determine its level of confidence in the similarity ratings it has for other owners.",
                "On the other hand, assuming there is some difference among owners (even if not noticed yet), as the number of its direct observations increases, the owners own data should gain weight in its analysis.",
                "Therefore, when CAi decides how many additional observations, Oi j should be adopted from CAjs database, it calculates Oi j as follows: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) where N is the number of observations CAi already has (which is similar in magnitude to the number of observations CAj has) and αi,j is the confidence of rejecting the Wilcoxon null hypothesis.",
                "The function in Equation 5 ensures that the number of additional observations to be taken from another CA module increases as the confidence in the similarity with the source for these additional observations increases.",
                "At the same time, it ensures that the level of dependency on external observations decreases as the number of direct observations increases.",
                "When calculating the parameter αi,j, we always perform the test over the interval relevant to the originating CAs distribution function.",
                "For example, when estimating the cost of interrupting the user, we apply the Wilcoxon test only for observations in the interval that starts from zero and ends slightly to the right of the formerly estimated RV (see Figure 1). 4.",
                "EMPIRICAL SETTING We tested the selective-sharing mechanism in a system that simulates a distributed, Coordinators-like MAS.",
                "This testbed environment includes a variable number of agents, each corresponding to a single CA module.",
                "Each agent is assigned an external source (simulating an owner) which it periodically samples to obtain a value from the distribution being estimated.",
                "The simulation system enabled us to avoid unnecessary inter-agent scheduling and communication overhead (which are an inherent part of the Coordinators environment) and thus to better isolate the performance and effectiveness of the estimation and decision-making mechanisms.",
                "The distribution functions used in the experiments (i.e., the distribution functions assigned to each user in the simulated environment) are multi-rectangular shaped.",
                "This type of function is ideal for representing empirical distribution functions.",
                "It is composed of k rectangles, where each rectangle i is defined over the interval (xi−1, xi), and represents a probability pi, ( Pk i=1 pi =1).",
                "For any value x in rectangle i, we can formulate F(x) and f(x) as: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6) For example, the multi-rectangular function in Figure 3 depicts a possible interruption cost distribution for a specific user.",
                "Each rectangle is associated with one of the users typical activities, characterized by a set of typical interruption costs. (We assume the distribution of cost within each activity is uniform.)",
                "The rectangular area represents the probability of the user being engaged in this type of activity when she is randomly interrupted.",
                "Any overlap between the interruption costs of two or more activities results in a new rectangle for the overlapped interval.",
                "The user associated with the above distribution function spends most of her time in reporting (notice that this is the largest rectangle in terms of area), an activity associated with a relatively high cost of interruption.",
                "The user also spends a large portion of her time in planning (associated with a very high cost of interruption), monitoring his team (with a relatively small interruption cost) and receiving reports (mid-level cost of interruption).",
                "The user spends a relatively small portion of her time in scouting the enemy (associated with relatively high interruption cost) and resting.",
                "Figure 3: Representing interruption cost distribution using a multi-rectangular function Multi-rectangular functions are modular and allow the representation of any distribution shape by controlling the number and dimensions of the rectangles used.",
                "Furthermore, these functions have computational advantages, mostly due to the ability to re-use many of their components when calculating the optimal reservation value in economical search models.",
                "They also fit well the parameters the CA is trying to estimate in fast-paced domains, because these parameters are mostly influenced by activities in which the user is engaged.",
                "The testbed system enabled us to define either hand-crafted or automatically generated multi-rectangular distribution functions.",
                "At each step of a simulation, each of the CAs samples its owner (i.e., all CAs in the system collect data at a similar rate) and then estimates the parameter (either the expected cost when using the sequential interruption technique described in Section 2 or the probability that the owner will have the required information) using one of the following methods: (a) relying solely on direct observation (self-learning) data; (b) relying on the combined data of all other agents (average all); and, (c) relying on its own data and selective portions of the other agents data based on the selective-sharing mechanism described in Section 3. 5.",
                "RESULTS We present the results in two parts: (1) using a specific sample environment for illustrating the basic behavior of the selectivesharing mechanism; and (2) using general environments that were automatically generated. 206 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.1 Sample Environment To illustrate the gain obtained by using the selective-sharing mechanism, we used an environment of 10 agents, associated with 5 different interruptibility cost distribution function types.",
                "The table in Figure 4 details the division of the 10 agents into types, the dimensions of the rectangles that form the distribution functions, and the theoretical mean and reservation value (RV) (following Equation 3) with a cost c = 2 for sensing the interruption cost.",
                "Even though the means of the five types are relatively similar, the use of a reservation-value based interruption strategy yields relatively different expected interruption costs (RV , following Equation 2).",
                "The histogram in this figure depicts the number of observations obtained for each bin of size 1 out of a sample of 100000 observations taken from each types distribution function.",
                "Type Agents Rect.",
                "Range prob mean RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 type I type II type III type IV type V #ofobservations range Figure 4: Users interruptibility cost distribution functions (5 types) Figure 5 gives CA performance in estimating the expected cost of interruption when using the reservation-value based interruption initiation technique.",
                "Each graph presents the average prediction accuracy (in terms of the absolute deviation from the theoretical value, so the lower the curve the better the performance) of a different type, based on 10000 simulation runs.",
                "The three curves in each graph represent the methods being compared (self-learning, average all, and selective-sharing).",
                "The data is given as a function of the accumulated number of observations collected.",
                "The sixth graph in the figure is the average for all types, weighted according to the number of agents of each type.",
                "Similarly, the following table summarizes the overall average performance in terms of the absolute deviation from the theoretical value of each of the different methods: Iterations Self-Learning Averaging-All Selective-Sharing % Improvement3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Table 1: Average absolute error along time Several observations may be made from Figure 5.",
                "First, although the average-all method may produce relatively good results, it quickly reaches stagnation, while the other two methods exhibit continuous improvement as a function of the amount of accumulated data.",
                "For the Figure 4 environment, average-all is a good strategy for agents of type II, IV and V, because the theoretical reservation value of each of these types is close to the one obtained based on the aggregated distribution function (i.e., 21.27).4 However, for types I and III for which the optimal RV differs from that value, the average-all method performs significantly worse.",
                "Overall, the sixth graph and the table above show that while in this specific environment the average-all method works well in the first interactions, it 3 The improvement is measured in percentages relative to the self-learning method. 4 The value is obtained by constructing the weighted aggregated distributed function according to the different agents types and extracting the optimal RV using Equation 3. 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type I 0 4 8 12 16 20 1 6 11 16 21 26 31 36 selective sharing self-learning average all 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 Type III 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Type V 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Weighted Average Figure 5: Average absolute deviation from the theoretical RV in each method (10000 runs) is quickly outperformed by the selective-sharing mechanism.",
                "Furthermore, the more user observations the agents accumulate (i.e., as we extend the horizontal axis), the better the other two methods are in comparison to average-all.",
                "In the long run (and as shown in the following subsection for the general case), the average-all method exhibits the worst performance.",
                "Second, the selective-sharing mechanism starts with a significant improvement in comparison to relying on the agents own observations, and then this improvement gradually decreases until finally its performance curve coincides with the self-learning methods curve.",
                "The selective-sharing mechanism performs better or worse, depending on the type, because the Wilcoxon test cannot guarantee an exact identification of similarity; different combinations of distribution function can result in an inability to exactly identify the similar users for some of the specific types.",
                "For example, for type I agents, the selective-sharing mechanism actually performs worse than self-learning in the short term (in the long run the two methods performance converge).",
                "Nevertheless, for the other types in our example, the selective-sharing mechanism is the most efficient one, and outperforms the other two methods overall.",
                "Third, it is notable that for agents that have a unique type (e.g., agent III), the selective-sharing mechanism quickly converges towards relying on self-collected data.",
                "This behavior guarantees that even in scenarios in which users are completely different, the method exhibits a graceful initial degradation but manages, within a few time steps, to adopt the proper behavior of counting exclusively on self-generated data.",
                "Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.",
                "Thus, the selective-sharing mechanism enables the agent of type V, despite its unique distribution function, to adopt relevant information collected by agents of types IV which improves its estimation of the expected interruption cost. 5.2 General Evaluation To evaluate selective-sharing, we ran a series of simulations in which the environment was randomly generated.",
                "These experiments focused on the CAs estimations of the probability that the user would have the required information if interrupted.",
                "They used a multi-rectangular probability distribution function to represent The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 207 the amount of communication the user is engaged in with its environment.",
                "We models the growth of the probability the user has the required information as a function of the amount of communication using the logistic function,5 G(x) = 1 + e −x 12 1 + 60e −x 12 . (7) The expected (mean) value of the parameter representing the probability the user has the required information is thus μ = Z ∞ y=0 G(y)f(y)dy = kX i=1 hx + 708ln(60 + e x 12 )pi 60(xi − xi−1) ixi xi−1 (8) where k is the number of rectangles used.",
                "We ran 10000 simulation runs.",
                "For each simulation, a new 20-agent environment was automatically generated by the system, and the agents were randomly divided into a random number of different types.6 For each type, a random 3-rectangle distribution function was generated.",
                "Each simulation ran 40 time steps.",
                "At each time step each one of the agents accumulated one additional observation.",
                "Each CA calculated an estimate of the probability its user had the necessary information according to the three methods, and the absolute error (difference from the theoretical value calculated according to Equation 8) was recorded.",
                "The following table summarizes the average performance of the three mechanisms along different time horizons (measured at 5, 15 and 40 time steps): Iterations Self-Learning Averaging-All Selective-Sharing % Improvement 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Table 2: Average absolute error along time steps As can be seen in the table above, the proposed selective-sharing method outperforms the two other methods over any execution in which more than 15 observations are collected by each of the agents.",
                "As in the sample environment, the average-all method performs well in the initial few time steps, but does not exhibit further improvement.",
                "Thus, the more data collected, the greater the difference between this latter method and the two other methods.",
                "The average difference between selective-sharing and self-learning decreases as more data is collected.",
                "Finally, we measured the effect of the number of types in the environment.",
                "For this purpose, we used the same self-generation method, but controlled the number of types generated for each run.",
                "The number of types is a good indication for the level of heterogeneity in the environment.",
                "For each number of types, we ran 10000 simulations.",
                "Figure 6 depicts the performance of the different methods (for a 40-observation collection period for each agent).",
                "Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.",
                "As expected, the average-all mechanism performs best when all agents are of the same type; however its performance deteriorates as the number of types increases.",
                "Similarly, the selective-sharing mechanism exhibits good results when all agents are of the same type, and as the number of types increases, its performance deteriorates.",
                "However, the performance decrease is significantly more modest in comparison to the one experienced in the average-all mechanism. 5 The specific coefficients used guarantee an S-like curve of growth, along the interval (0, 100), where the initial stage of growth is approximately exponential, followed by asymptotically slowing growth. 6 In this suggested environment-generation scheme there is no guarantee that every agent will have a potential similar agent to share information with.",
                "In those non-rare scenarios where the CA is the only one of its type, it will rapidly need to stop relying on others. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Self Learning Average All Selective Sharing number of types averageabsoluteerror Figure 6: Average absolute deviation from actual value in 20 agent scenarios as a function of the agents heterogeneity level Overall, the selective-sharing mechanism outperforms both other methods for any number of types greater than one. 6.",
                "RELATED WORK In addition to the <br>interruption management</br> literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "Collaborative filtering, which makes predictions (filtering) about the interests of a user [7], operates similarly to selective-sharing.",
                "However, collaborative filtering systems exhibit poor performance when there is not sufficient information about the users and when there is not sufficient information about a new user whose taste the system attempts to predict [7].",
                "Selective-sharing relies on the ability to find similarity between specific parts of the probability distribution function associated with a characteristic of different users.",
                "This capability is closely related to clustering and classification, an area widely studied in machine learning.",
                "Given space considerations, our review of this area is restricted to some representative approaches for clustering.",
                "In spite of the richness of available clustering algorithms (such as the famous K-means clustering algorithm [11], hierarchical methods, Bayesian classifiers [6], and maximum entropy), various characteristics of fast-paced domains do not align well with the features of attributesbased clustering mechanisms, suggesting these mechanisms would not perform well in such domains.",
                "Of particular importance is that the CA needs to find similarity between functions, defined over a continuous interval, with no distinct pre-defined attributes.",
                "An additional difficulty is defining the distance measure.",
                "Many clustering techniques have been used in data mining [2], with particular focus on incremental updates of the clustering, due to the very large size of the databases [3].",
                "However the applicability of these to fast-paced domains is quite limited because they rely on a large set of existing data.",
                "Similarly, clustering algorithms designed for the task of class identification in spatial databases (e.g., relying on a density-based notion [4]) are not useful for our case, because our data has no spatial attributes.",
                "The most relevant method for our purposes is the Kullback-Leibler relative entropy index that is used in probability theory and information theory [12].",
                "This measure, which can also be applied on continuous random variables, relies on a natural distance measure from a true probability distribution (either observation-based or calculated) to an arbitrary probability distribution.",
                "However, the method will perform poorly in scenarios in which the functions alternate between different levels while keeping the general structure and moments.",
                "For example, consider the two functions f(x) = ( x mod2)/100 and g(x) = ( x mod2)/100 defined over the interval (0, 200).",
                "While these two functions are associated with almost identical reservation values (for any sampling cost) and mean, the Kullback-Leibler method will assign a poor correlation between 208 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) them, while our Wilcoxon-based approach will give them the highest rank in terms of similarity.",
                "While the Wilcoxon test is a widely used statistical procedure [22, 14], it is usually used for comparing two sets of single-variate data.",
                "To our knowledge, no attempt has been made yet to extend its properties as an infrastructure for determining with whom and to what extent information should be shared, as presented in this paper.",
                "Typical use of this non-parametric tool includes detection of rare events in time series (e.g., a hard drive failure prediction [17]) and bioinformatics applications (e.g., finding informative genes from microarray data).",
                "In these applications, it is used primarily as an identification tool and ranking criterion. 7.",
                "DISCUSSION AND CONCLUSIONS The selective-sharing mechanism presented in this paper does not make any assumptions about the format of the data used or about the structure of the distribution function of the parameter to be estimated.",
                "It is computationally lightweight and very simple to execute.",
                "Selective-sharing allows an agent to benefit from other agents observations in scenarios in which data sources of the same type are available.",
                "It also guarantees, as a fallback, performance equivalent to that of a self-learner when the information source is unique.",
                "Furthermore, selective-sharing does not require any prior knowledge about the types of information sources available in the environment or of the number of agents associated with each type.",
                "The results of our simulations demonstrate the selective-sharing mechanisms effectiveness in improving the estimation produced for probabilistic parameters based on a limited set of observations.",
                "Furthermore, most of the improvement is achieved in initial interactions, which is of great importance for agents operating in fast-paced environments.",
                "Although we tested the selective-sharing mechanism in the context of the Coordinators project, it is applicable in any MAS environment having the characteristics of a fast-paced environment (e.g., rescue environments).",
                "Evidence for its general effectiveness is given in the general evaluation section, where environments were continuously randomly generated.",
                "The Wilcoxon statistic used as described in this paper to provide a classifier for similarity between users provides high flexibility with low computational costs and is applicable for any characteristic being learned.",
                "Its use provides a good measure of similarity which an agent can use to decide how much external information to adopt for its assessments. 8.",
                "ACKNOWLEDGEMENT The research reported in this paper was supported in part by contract number 55-000720, a subcontract to SRI Internationals DARPA Contract No.",
                "FA8750-05-C-0033.",
                "Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government.",
                "We are grateful to an anonymous AAMAS reviewer for an exceptionally comprehensive review of this paper. 9.",
                "REFERENCES [1] P. Adamczyk, S. Iqbal, and B. Bailey.",
                "A method, system, and tools for intelligent <br>interruption management</br>.",
                "In TAMODIA 05, pages 123-126, New York, NY, USA, 2005.",
                "ACM Press. [2] P. Berkhin.",
                "Survey of clustering data mining techniques.",
                "Technical report, Accrue Software, San Jose, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer, and X. Xu.",
                "Incremental clustering for mining in a data warehousing environment.",
                "In Proc. 24th Int.",
                "Conf.",
                "Very Large Data Bases, VLDB, pages 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander, and X. Xu.",
                "A density-based algorithm for discovering clusters in large spatial databases with noise.",
                "In KDD-96, pages 226-231, 1996. [5] M. Fleming and R. Cohen.",
                "A decision procedure for autonomous agents to reason about interaction with humans.",
                "In AAAI Spring Symp. on Interaction between Humans and Autonomous Systems over Extended Operation, 2004. [6] N. Friedman, D. Geiger, and M. Goldszmidt.",
                "Bayesian network classifiers.",
                "Machine Learning, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker, and J. Riedl.",
                "Combining collaborative filtering with personal agents for better recommendations.",
                "In AAAI/IAAI, pages 439-446, 1999. [8] K. Hinckley, J.",
                "Pierce, M. Sinclair, and E. Horvitz.",
                "Sensing techniques for mobile interaction.",
                "In UIST 00, pages 91-100, New York, NY, USA, 2000.",
                "ACM Press. [9] E. Horvitz, C. Kadie, T. Paek, and D. Hovel.",
                "Models of attention in computing and communication: from principles to applications.",
                "Commun.",
                "ACM, 46(3):52-59, 2003. [10] B. Hui and C. Boutilier.",
                "Whos asking for help? : a bayesian approach to intelligent assistance.",
                "In IUI 06, 2006. [11] J. Jang, C. Sun, and E. Mizutani.",
                "Neuro-Fuzzy and Soft Computing A Computational Approach to Learning and Machine Intelligence.",
                "Prentice Hall, 1997. [12] S. Kullback and R. Leibler.",
                "On information and sufficiency.",
                "Ann.",
                "Math.",
                "Statist., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai, and B. Smith.",
                "Gaze and speech in attentive user interfaces.",
                "In ICMI, pages 1-7, 2000. [14] H. Mann and D. Whitney.",
                "On a test of whether one of 2 random variables is stochastically larger than the other.",
                "Annals of Mathematical Statistics, 18:50-60, 1947. [15] W. McClure.",
                "Technology and command: Implications for military operations in the twenty-first century.",
                "Maxwell Air Force Base, Center for Strategy and Technology, 2000. [16] J. McMillan and M. Rothschild.",
                "Search.",
                "In Robert J. Aumann and Amsterdam Sergiu Hart, editors, Handbook of Game Theory with Economic Applications, pages 905-927. 1994. [17] J. Murray, G. Hughes, and K. Kreutz-Delgado.",
                "Machine learning methods for predicting failures in hard drives: A multiple-instance application.",
                "J. Mach.",
                "Learn.",
                "Res., 6:783-816, 2005. [18] D. Sarne and B. J. Grosz.",
                "Estimating information value in collaborative multi-agent planning systems.",
                "In AAMAS07, page (to appear), 2007. [19] D. Sarne and B. J. Grosz.",
                "Timing interruptions for better human-computer coordinated planning.",
                "In AAAI Spring Symp. on Distributed Plan and Schedule Management, 2006. [20] R. Vertegaal.",
                "The GAZE groupware system: Mediating joint attention in multiparty communication and collaboration.",
                "In CHI, pages 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik, and R. VanRiper.",
                "An application view of coordinators: Coordination managers for first responders.",
                "In AAAI, pages 908-915, 2004. [22] F Wilcoxon.",
                "Individual comparisons by ranking methods.",
                "Biometrics, 1:80-83, 1945. [23] D. Zeng and K. Sycara.",
                "Bayesian learning in negotiation.",
                "In AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems, pages 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J.",
                "Yen, and T. Ioerger.",
                "A distributed intelligent agent architecture for simulating aggregate-level behavior and interactions on the battlefield.",
                "In SCI-2001, pages 58-63, 2001.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 209"
            ],
            "original_annotated_samples": [
                "RELATED WORK In addition to the <br>interruption management</br> literature reviewed in Section 2, several other areas of prior work are relevant to the selective-sharing mechanism described in this paper.",
                "A method, system, and tools for intelligent <br>interruption management</br>."
            ],
            "translated_annotated_samples": [
                "TRABAJOS RELACIONADOS Además de la literatura sobre <br>gestión de interrupciones</br> revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento.",
                "Un método, sistema y herramientas para la <br>gestión inteligente de interrupciones</br>."
            ],
            "translated_text": "Compartir experiencias para aprender las características de los usuarios en entornos dinámicos con datos escasos. David Sarne, Barbara J. Grosz. Escuela de Ingeniería y Ciencias Aplicadas, Universidad de Harvard, Cambridge MA 02138, EE. UU. {sarned, grosz}@eecs.harvard.edu. RESUMEN Este artículo investiga el problema de estimar el valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe ser capaz de producir estimaciones incluso cuando solo haya realizado un pequeño número de observaciones directas, por lo que debe ser capaz de operar con datos escasos. El artículo describe un mecanismo que permite al agente mejorar significativamente su estimación al complementar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar sesgos no deseados en entornos relativamente heterogéneos mientras se utiliza de manera efectiva datos relevantes para mejorar sus estimaciones, el mecanismo pondera las contribuciones de las observaciones de otros agentes basándose en una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y él mismo. El módulo de autonomía de coordinación de un sistema de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en simulaciones demostraron que el mecanismo propuesto supera a las estimaciones basadas exclusivamente en las observaciones de un agente, así como a las estimaciones basadas en un agregado no ponderado de las observaciones de todos los demás agentes. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de parámetros; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Agentes inteligentes, Sistemas multiagente; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Funciones de distribución Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN Para muchos escenarios del mundo real, los agentes autónomos necesitan operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y las características de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, combinando sus experiencias individuales para mejorar sus estimaciones de los parámetros desconocidos necesarios para razonar sobre acciones en situaciones de incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que está interactuando con un agente informático. La característica a ser aprendida está claramente relacionada con un factor importante en la toma de decisiones del agente. El escenario básico que consideramos es aquel en el que un agente acumula observaciones sobre una característica específica del usuario y las utiliza para producir una estimación oportuna de alguna medida que depende de la distribución de esa característica. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate en caso de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales ocurren a un ritmo acelerado, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Normalmente, los agentes deben tomar decisiones en tiempo real, de forma simultánea con la ejecución de la tarea y en medio de una gran incertidumbre. En el resto de este documento, utilizamos el término de ritmo rápido para referirnos a tales entornos. En entornos de ritmo acelerado, la recopilación de información puede ser limitada, y no es posible aprender sin conexión o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones a cualquier mecanismo para aprender una función de distribución (incluyendo la amplia gama de técnicas de actualización bayesiana [23]): (a) la restricción de no estructura: no se dispone de información a priori sobre la estructura de la distribución de parámetros estimados ni de datos iniciales a partir de los cuales se pueda inferir dicha estructura; (b) la restricción de uso limitado: los agentes típicamente necesitan producir solo un pequeño número de estimaciones en total para este parámetro; (c) la restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado e intente minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo necesario. Dada la falta de restricciones de estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden resultar en un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno multiagente, en el cual otros agentes también pueden estar recopilando datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente pueda complementar sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes suelen acumular datos a una tasa relativamente similar. Sin embargo, el grado en que las observaciones de otros agentes serán útiles para un agente dado depende del grado en que las distribuciones de las características de sus usuarios estén correlacionadas con las de los usuarios de este agente. No hay garantía de que la distribución de dos agentes diferentes esté altamente, positivamente correlacionada, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y de ponderar los datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de gestión de coordinación (como parte del proyecto Coordinadores de DARPA [18]), en el que los agentes respaldan una tarea de programación distribuida, proporcionó la motivación inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos multiagentes en los que los agentes están recopilando datos que se superponen en cierta medida, a tasas aproximadamente similares, y en los que el entorno impone las restricciones de no estructura, uso limitado y temprano definidas anteriormente (por ejemplo, la exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes lleve a cabo una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para la toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender las características clave de los usuarios en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas en plazos cortos al complementar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se está coordinando. En particular, nos enfocamos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos a lo largo del documento como compartición selectiva, permite que nuestro CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con depender únicamente de las interacciones con un usuario específico (posteriormente, autoaprendizaje) o agrupar todos los datos incondicionalmente (promedio de todos), en particular cuando el número de observaciones disponibles es relativamente pequeño. El mecanismo fue probado con éxito utilizando un sistema que simula un entorno de Coordinadores. La siguiente sección del artículo describe el problema de estimar parámetros relacionados con el usuario en dominios de ritmo rápido. La sección 3 proporciona una visión general de los métodos que desarrollamos. La implementación, el entorno empírico y los resultados se presentan en las Secciones 4 y 5. Una comparación con métodos relacionados se presenta en la Sección 6 y las conclusiones en la sección 7. 2. La ESTIMACIÓN DE PARÁMETROS EN DOMINIOS DE RÁPIDO MOVIMIENTO El módulo de CA y los algoritmos que describimos en este documento fueron desarrollados y probados en el dominio de Coordinadores [21]. En este dominio, agentes autónomos, llamados Coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de respuesta inicial o un comandante de unidad) cuyo horario gestiona. Por lo tanto, las tareas reales que se programan son ejecutadas ya sea por los propietarios o por las unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, la información de programación y las restricciones están distribuidas. Cada agente recibe una vista diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente solo una parcial y local. Las revisiones de horarios que afectan a más de un agente deben ser coordinadas, por lo que los agentes deben compartir ciertos tipos de información. (En un contexto de equipo, también pueden estar diseñados para compartir otros tipos). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada; los problemas de programación deben resolverse de forma distribuida. La relación agente-propietario es colaborativa, con el agente necesitando interactuar con su propietario para obtener información de tareas y del entorno relevante para la programación. El módulo de CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de cualquier interacción de este tipo y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV − C, donde V es el valor de la información que el usuario puede tener, P es la probabilidad de que el usuario tenga esta información, y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y el CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, ambos de los cuales son centrados en el usuario en el sentido de ser determinados por las características del propietario y el entorno en el que el propietario está operando); se presume un mecanismo para determinar V [18]. 2.1 Estimación de Costos de Interrupción El costo de interrumpir a los propietarios se deriva de la posible degradación en el rendimiento de las tareas que están realizando causada por la interrupción [1; 9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de la interrumpibilidad humana para inferir el grado de distracción que probablemente causará una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción retrasando las interrupciones a momentos que sean convenientes. Normalmente utiliza modelos bayesianos para aprender el enfoque actual o probable futuro en la atención de un usuario a partir de un flujo continuo de acciones. Al utilizar sensores para proporcionar indicaciones continuas entrantes del estado de atención de los usuarios, estos modelos intentan proporcionar un medio para calcular distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina factores de costo de interrumpibilidad como la frustración del usuario y la distracción [10] incluye trabajo sobre el costo de molestar repetidamente al usuario, teniendo en cuenta que las interrupciones recientes y las preguntas difíciles deben tener más peso que las interrupciones en el pasado lejano o preguntas sencillas [5]. Aunque este trabajo previo utiliza estimaciones de interrumpibilidad para equilibrar la importancia estimada de las interacciones con el grado de distracción probable que se causará, difiere del problema de entornos de ritmo acelerado que abordamos en tres aspectos que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran las posibles soluciones. Primero, considera escenarios en los que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga la información necesaria para el sistema, lo cual es el complemento de la situación de intercambio de información que consideramos. Segundo, los modelos de estimación de interrumpibilidad son basados en tareas. Por último, depende de la monitorización continua de las actividades de un usuario. En entornos de ritmo acelerado, generalmente no hay una estructura de tarea única, y algunas de las actividades mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado de atención real de los agentes propietarios [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a varios miembros de sus unidades, al mismo tiempo que permanecen reactivos a eventos que se desvían de las expectativas [24]. Por ejemplo, durante un rescate en caso de desastre, una unidad de primeros auxilios puede comenzar a rescatar a sobrevivientes atrapados en una casa en llamas, cuando de repente se derrumba una pared, obligando a la unidad a... La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 203 retiran y replanifican sus acciones. Trabajos previos han seguido el enfoque de atención de los usuarios utilizando una variedad de dispositivos, incluidos aquellos capaces de monitorear gestos [8] y rastrear la mirada para identificar el enfoque de atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también presuponen la existencia de tales sensores. Sin embargo, a diferencia de trabajos anteriores, que dependen de que estos dispositivos operen de forma continua, nuestro mecanismo supone que en entornos de ritmo rápido solo se permite la activación de sensores por breves períodos de tiempo de manera ad hoc, ya que los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación basándose únicamente en lo que el usuario está haciendo actualmente (por ejemplo, MDPs) no son apropiados para modelar el enfoque de atención en dominios de ritmo rápido, ya que un agente no puede depender de que el estado de atención de una persona esté bien estructurado y el monitoreo solo se puede hacer de forma esporádica, no continua. Por lo tanto, en cualquier momento dado, el costo de la interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y puede asignarse una función de distribución de probabilidad. Por consiguiente, en entornos de ritmo acelerado, un agente necesita una estrategia de muestreo mediante la cual el CA muestrea el nivel de interrumpibilidad de sus propietarios (con algún costo) y decide si iniciar una interacción en ese momento específico o retrasarla hasta que se observe un costo menor en futuros muestreos. El método que describimos en el resto de esta subsección aplica conceptos de la teoría económica de búsqueda [16] a este problema. La estimación de costos de los CAs utiliza un mecanismo que integra la distribución del nivel de interrumpibilidad de un propietario (según lo estimado por el CA) en una estrategia de búsqueda económica, de manera que se minimice el costo combinado total de los costos de sensores y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximice la utilidad esperada. El proceso de búsqueda en sí mismo está asociado con un costo, y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociadas con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se extrae una observación a la vez, a lo largo de múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue extrayendo muestras siempre y cuando no se haya extraído ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (pdf) f(x) y una función de distribución acumulada (cdf) F(x). El agente puede activar dispositivos de detección para obtener una estimación del costo de interrupción, x, en el momento actual, pero hay un costo c de operar los dispositivos de detección por una unidad de tiempo. El módulo CA establece un valor de reserva y mientras la observación basada en el sensor x sea mayor que este valor de reserva, el CA esperará y volverá a muestrear al usuario para una nueva estimación. El costo esperado, V (xrv), utilizando tal estrategia con un valor de reserva xrv, está descrito por la Ecuación 1, V (xrv) = c + R xrv y=0 yf(y) F(xrv), (1) la cual se descompone en dos partes. La primera parte, c dividido por F(xrv), representa el costo esperado de muestreo. El segundo término, la integral dividida por F(xrv), representa el costo esperado de interrupción, ya que el número esperado de ciclos de búsqueda es geométrico (aleatorio) y la probabilidad de éxito es F(xrv). Tomar la derivada del lado izquierdo de la Ecuación 1 y igualarla a cero, nos da las características del valor óptimo de reserva, es decir, x∗ rv debe satisfacer, V (x∗ rv) = x∗ rv. (2) Sustituir (2) en la Ecuación 1 nos da la Ecuación 3 (después de integración por partes) a partir de la cual se puede calcular el valor óptimo de reserva, x∗ rv, y consecuentemente (a partir de la Ecuación 2) V (x∗ rv). c = Z x∗ rv y=0 F(y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basada en sensores, se basa en gran medida en la estructura de la función de distribución, f(x). Sin embargo, solo necesitamos una parte de la función de distribución, específicamente desde el origen hasta el valor de reserva. (Ver Ecuación 1 y Figura 1.) Por lo tanto, al considerar compartir datos, no es necesario depender de una similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrumpibilidad de los usuarios, es suficiente confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de los costos esperados 2.2 Estimación de la Probabilidad de Tener Información Una forma en que un agente puede estimar la probabilidad de que un usuario tenga la información que necesita (por ejemplo, saber en un momento específico de interrupción, con cierto nivel de confiabilidad, el resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la proporción entre el número de veces que el usuario tenía la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad a partir de las características medibles del comportamiento de los usuarios, que puede evaluar sin necesidad de interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método tan indirecto: las interacciones propietario-entorno se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios como Coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender de manera informal sobre la existencia o estado de otras acciones que están ejecutando), comunicaciones abiertas que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área), y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otras personas, que pueden obtenerse sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre el nivel de comunicación de sus propietarios, el CA puede estimar la probabilidad de que una interacción aleatoria con el propietario proporcione la información que necesita. Denotando la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g(x), y utilizando la función de transformación Z(x), que mapea desde un nivel de comunicación, x, a una probabilidad de tener la información, la probabilidad esperada de obtener la información necesaria del propietario al interrumpir en un momento dado se puede calcular como P = Z ∞ 0 Z(x)g(x)dy. (4) 204 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Cuantas más observaciones pueda acumular un agente sobre la distribución de la frecuencia de la interacción de un propietario con el entorno en un momento dado, mejor podrá estimar la probabilidad de que el propietario tenga la información necesaria para el sistema. 3. EL MECANISMO DE COMPARTICIÓN SELECTIVA Esta sección presenta el mecanismo de compartición selectiva mediante el cual el CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CAs en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de estimación y luego presentamos un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que el CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construyendo un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Basándose en este histograma, el CA puede estimar el parámetro teniendo en cuenta todo el rango de valores (por ejemplo, para estimar la media) o una parte de él (por ejemplo, para encontrar el costo esperado al utilizar una estrategia basada en el valor de reserva). La precisión de la estimación variará ampliamente si se basa en solo un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U(0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución. (En esta simulación, el costo de activación del dispositivo se tomó como c = 0.5). Figura 2: La convergencia de un único CA a su estrategia óptima. Estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la Ecuación 3) se deben a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real de la función de distribución. Finalmente, este método produce una estimación muy precisa del costo esperado de interrupción. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de la CA: subestimar el costo puede resultar en la iniciación de interacciones costosas y no beneficiosas, mientras que sobreestimar el costo podría resultar en perder oportunidades para interacciones valiosas. Cualquier mejora que se pueda lograr en predecir los valores de coste, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en la cantidad de veces que puede interactuar con su propietario en dominios de ritmo rápido. Una forma de disminuir la desviación del valor real es aumentando los datos adquiridos por el CA al observar a su propietario con observaciones realizadas por agentes de otros propietarios. Un enfoque así depende de identificar otros propietarios con funciones de distribución para la característica de interés similares al propietario de las CA. Esta idea de aumento de datos es simple: diferentes propietarios pueden exhibir comportamientos básicos o patrones similares en escenarios de tareas rápidas similares. Dado que todos están coordinando en una tarea general común y operan en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo tanto, obviamente, puede haber diferentes tipos de líderes: algunos enfatizarán la comunicación con sus equipos, y otros pasarán más tiempo en la planificación basada en mapas; algunos no les gustará ser interrumpidos mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden ser más abiertos a las interrupciones. Por consiguiente, es probable que un CA de propietarios pueda encontrar algunos CAs que estén trabajando con propietarios similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes debería confiar el CA y en qué medida debería confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite al CA de un usuario específico identificar dinámicamente la similitud entre su propietario y otros propietarios. Basándose en este nivel de similitud, la CA decide si y en qué medida importar los datos de otras CAs para ampliar sus observaciones directas, y así permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de agentes diferentes es relativamente bajo. Esta información puede ser transferida como parte de la comunicación regular de negociación entre agentes. El volumen de dicha comunicación es insignificante: solo implica la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, el CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CAs en el entorno. Cada nueva observación obtenida ya sea por ese CA o por cualquiera de los otros CAs actualiza esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rangos de Wilcoxon (Subsección 3.1). Cuando sea necesario producir una estimación de parámetros, el CA decide sobre la cantidad de observaciones adicionales en las que pretende basarse para extraer su estimación. El número de observaciones adicionales que se deben tomar de cada otro agente es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y del nivel de confianza que tiene el CA en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que el CA querrá tomar de otro agente es menor que el número total de observaciones que tiene el otro agente; por lo tanto, selecciona aleatoriamente (sin repeticiones) el número requerido de observaciones de la base de datos de este otro agente. Las observaciones adicionales que el agente de aprendizaje toma de otros agentes solo se utilizan para modelar las características de sus propietarios. La determinación del nivel de similitud futuro no se ve afectada por este procedimiento de aumento de información. 3.1 La Prueba de Wilcoxon Utilizamos un método no paramétrico (es decir, uno que no hace suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características de los usuarios en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para tratar observaciones inesperadas y atípicas (posiblemente problemáticas para un enfoque paramétrico) y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto, ideales para entornos en los que los recursos computacionales son escasos. La prueba de suma de rangos de Wilcoxon que utilizamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14]. Mientras que la prueba t compara medias, la prueba de Wilcoxon se puede utilizar para probar la hipótesis nula de que dos poblaciones X e Y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} e {y1, y2, ..., yn}, de tamaños m y n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de menor a mayor. Todas las secuencias de empates se les asigna un rango promedio. De la suma de los rangos de las 2 pruebas de bondad de ajuste de Chi-Cuadrado más pequeñas es para una sola muestra y, por lo tanto, no es adecuada. El Sexto Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 205 muestra, calculamos la estadística de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. El test de Wilcoxon no requiere que los datos provengan de una población distribuida normalmente o que la distribución esté caracterizada por un conjunto finito de parámetros. Determinar correctamente la cantidad de observaciones adicionales necesarias es un factor clave para el éxito del mecanismo de selección de compartir selectivamente. Obviamente, si el CA puede identificar a otro propietario que tenga características idénticas al propietario que representa, entonces debería utilizar todas las observaciones recopiladas por el agente de ese propietario. Sin embargo, los casos de coincidencias idénticas probablemente sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, el CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, usualmente el CA necesita decidir cuánto confiar en los datos de otros agentes al estimar varios niveles de similitud con un nivel cambiante de confianza. Al principio de su proceso, el mecanismo de selección y compartición casi no tiene datos en los que basarse, por lo que no se puede utilizar ninguna medida de similitud. En este caso, el módulo de CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA perfecciona la cantidad de observaciones adicionales requeridas. Nuevamente, hay dos efectos conflictivos. Por un lado, cuantos más datos tenga la CA, mejor podrá determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, asumiendo que existe alguna diferencia entre los propietarios (aunque aún no se haya notado), a medida que aumenta el número de sus observaciones directas, los datos de los propietarios deberían ganar peso en su análisis. Por lo tanto, cuando CAi decide cuántas observaciones adicionales, Oi j, deben adoptarse de la base de datos de CAjs, calcula Oi j de la siguiente manera: Oi j = N ∗ (1 − αi,j) √ N + 2 + ln(N) N (5) donde N es el número de observaciones que CAi ya tiene (que es similar en magnitud al número de observaciones que CAj tiene) y αi,j es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la Ecuación 5 asegura que la cantidad de observaciones adicionales a tomar de otro módulo de CA aumente a medida que la confianza en la similitud con la fuente de estas observaciones adicionales aumenta. Al mismo tiempo, se asegura de que el nivel de dependencia de observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi,j, siempre realizamos la prueba en el intervalo relevante para la función de distribución de las CAs de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha de la RV estimada anteriormente (ver Figura 1). 4. ENTORNO EMPÍRICO Probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido similar a Coordinators. Este entorno de prueba incluye un número variable de agentes, cada uno correspondiente a un módulo de CA único. Cada agente se le asigna una fuente externa (simulando un propietario) de la cual toma muestras periódicamente para obtener un valor de la distribución que se está estimando. El sistema de simulación nos permitió evitar la programación innecesaria entre agentes y la sobrecarga de comunicación (que son parte inherente del entorno de Coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) tienen forma multi-rectangular. Este tipo de función es ideal para representar funciones de distribución empíricas. Está compuesto por k rectángulos, donde cada rectángulo i está definido en el intervalo (xi−1, xi), y representa una probabilidad pi, ( Σk i=1 pi =1). Para cualquier valor x en el rectángulo i, podemos formular F(x) y f(x) de la siguiente manera: f(x) = pi xi − xi−1 F(x) = i−1X j=1 pj + (x − xi−1)pi xi − xi−1 (6). Por ejemplo, la función multi-rectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizada por un conjunto de costos típicos de interrupción. (Suponemos que la distribución de costos dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario esté involucrado en este tipo de actividad cuando es interrumpido al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades resulta en un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo informando (tenga en cuenta que este es el rectángulo más grande en términos de área), una actividad asociada con un costo de interrupción relativamente alto. El usuario también dedica una gran parte de su tiempo a la planificación (asociada con un costo de interrupción muy alto), monitorear a su equipo (con un costo de interrupción relativamente bajo) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una parte relativamente pequeña de su tiempo en la exploración del enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representación de la distribución del costo de interrupción utilizando una función multi-rectangular. Las funciones multi-rectangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en modelos de búsqueda económica. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, ya que estos parámetros están principalmente influenciados por las actividades en las que el usuario está involucrado. El sistema de prueba nos permitió definir funciones de distribución multi-rectangulares, ya sea hechas a mano o generadas automáticamente. En cada paso de una simulación, cada uno de los CA muestrea a su propietario (es decir, todos los CA en el sistema recopilan datos a una tasa similar) y luego estima el parámetro (ya sea el costo esperado al usar la técnica de interrupción secuencial descrita en la Sección 2 o la probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) basándose únicamente en la observación directa de datos (autoaprendizaje); (b) basándose en los datos combinados de todos los demás agentes (promedio de todos); y, (c) basándose en sus propios datos y porciones selectivas de los datos de los otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3.5. RESULTADOS Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo de intercambio selectivo; y (2) utilizando entornos generales que fueron generados automáticamente. 206 El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.1 Entorno de Muestra Para ilustrar la ganancia obtenida al utilizar el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociados con 5 tipos diferentes de funciones de distribución de costos de interrumpibilidad. La tabla en la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y el valor medio teórico y el valor de reserva (RV) (siguiendo la Ecuación 3) con un costo c = 2 para detectar el costo de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, siguiendo la Ecuación 2). El histograma en esta figura representa el número de observaciones obtenidas para cada intervalo de tamaño 1 de una muestra de 100,000 observaciones tomadas de cada función de distribución de tipos. Agentes de tipado rect. El rango de probabilidad significa RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25 III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 tipo I tipo II tipo III tipo IV tipo V # de observaciones rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 muestra el rendimiento de CA en la estimación del costo esperado de la interrupción al utilizar la técnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión promedio de la predicción (en términos de la desviación absoluta del valor teórico, por lo que cuanto más bajo sea la curva, mejor será el rendimiento) de un tipo diferente, basado en 10000 ejecuciones de simulación. Las tres curvas en cada gráfica representan los métodos que se están comparando (autoaprendizaje, promedio de todos y compartición selectiva). Los datos se presentan como una función del número acumulado de observaciones recopiladas. El sexto gráfico en la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. De manera similar, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: Iteraciones Autoaprendizaje Promedio de todos Compartir selectivamente % de mejora 3 5 20.08 8.70 9.51 53% 15 12.62 7.84 8.14 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio a lo largo del tiempo Se pueden hacer varias observaciones a partir de la Figura 5. Primero, aunque el método de promedio general puede producir resultados relativamente buenos, rápidamente alcanza estancamiento, mientras que los otros dos métodos muestran una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todos es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca del obtenido basado en la función de distribución agregada (es decir, 21.27). Sin embargo, para los tipos I y III, cuyo RV óptimo difiere de ese valor, el método de promedio de todos funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, mientras que en este entorno específico el método de promedio total funciona bien en las primeras interacciones, es rápidamente superado por el mecanismo de intercambio selectivo. Además, entre más observaciones de usuario acumulen los agentes (es decir, a medida que extendemos el eje horizontal), mejor son los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método de promedio total exhibe el peor rendimiento. Segundo, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las observaciones propias de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de los métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de la similitud; diferentes combinaciones de funciones de distribución pueden resultar en una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes de tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, el rendimiento de los dos métodos converge). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera en rendimiento a los otros dos métodos en general. En tercer lugar, es notable que para agentes que tienen un tipo único (por ejemplo, agente III), el mecanismo de intercambio selectivo converge rápidamente hacia depender de los datos recopilados por sí mismos. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método muestra una degradación inicial suave pero logra, en unos pocos pasos de tiempo, adoptar el comportamiento adecuado de contar exclusivamente con datos generados por sí mismo. Por último, a pesar de la diferencia en su función de distribución general, los agentes de tipo IV y V muestran un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan al cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de selección de compartición permite que el agente de tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de tipo IV, lo que mejora su estimación del costo esperado de interrupción. 5.2 Evaluación General Para evaluar la selección de compartición, realizamos una serie de simulaciones en las que el entorno fue generado aleatoriamente. Estos experimentos se centraron en las estimaciones de los AC sobre la probabilidad de que el usuario tuviera la información requerida si fuera interrumpido. Utilizaron una función de distribución de probabilidad multi-rectangular para representar The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 207 la cantidad de comunicación en la que el usuario está involucrado con su entorno. Modelamos el crecimiento de la probabilidad de que el usuario tenga la información requerida como una función de la cantidad de comunicación utilizando la función logística, G(x) = 1 + e^(-x/12) / (1 + 60e^(-x/12). El valor esperado (promedio) del parámetro que representa la probabilidad de que el usuario tenga la información requerida es así μ = ∫₀^∞ G(y)f(y)dy = kΣᵢ=₁ hᵢ(xᵢ + 708ln(60 + e^(xᵢ/12))pᵢ) / 60(xᵢ - xᵢ₋₁) donde k es el número de rectángulos utilizados. Realizamos 10000 ejecuciones de simulación. Para cada simulación, un nuevo entorno de 20 agentes fue generado automáticamente por el sistema, y los agentes fueron divididos aleatoriamente en un número aleatorio de diferentes tipos. Para cada tipo, se generó una función de distribución de 3 rectángulos de forma aleatoria. Cada simulación se ejecutó durante 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria según los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): Iteraciones Autoaprendizaje Promedio de Todos Compartir Selectivo % de Mejora 5 0.176 0.099 0.103 41.4% 15 0.115 0.088 0.087 23.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio a lo largo de los pasos de tiempo Como se puede ver en la tabla anterior, el método de compartir selectivo propuesto supera a los otros dos métodos en cualquier ejecución en la que se recopilen más de 15 observaciones por cada uno de los agentes. Como en el entorno de muestra, el método de promedio total funciona bien en los primeros pasos de tiempo, pero no muestra una mejora adicional. Por lo tanto, cuantos más datos se recolecten, mayor será la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopila más datos. Finalmente, medimos el efecto del número de tipos en el entorno. Para este propósito, utilizamos el mismo método de auto-generación, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el ambiente. Para cada número de tipos, realizamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observaciones para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como era de esperar, el mecanismo de promedio general funciona mejor cuando todos los agentes son del mismo tipo; sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de compartir selectivamente muestra buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento empeora. Sin embargo, la disminución en el rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo de promedio general. Los coeficientes específicos utilizados garantizan una curva de crecimiento en forma de S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento que se ralentiza asintóticamente. En este esquema de generación de entornos sugerido no hay garantía de que cada agente tenga un agente potencial similar con quien compartir información. En aquellos escenarios no raros donde el CA es el único de su tipo, necesitará dejar de depender rápidamente de los demás. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Autoaprendizaje Promedio Todos Compartir Selectivo número de tipos error absoluto promedio Figura 6: Desviación absoluta promedio del valor real en escenarios de 20 agentes en función del nivel de heterogeneidad de los agentes En general, el mecanismo de compartir selectivamente supera a ambos métodos para cualquier número de tipos mayor que uno. 6. TRABAJOS RELACIONADOS Además de la literatura sobre <br>gestión de interrupciones</br> revisada en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones (filtrado) sobre los intereses de un usuario [7], opera de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo muestran un rendimiento deficiente cuando no hay suficiente información sobre los usuarios y cuando no hay suficiente información sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. La compartición selectiva se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con el agrupamiento y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las limitaciones de espacio, nuestra revisión de esta área se restringe a algunos enfoques representativos para la agrupación. A pesar de la riqueza de algoritmos de agrupamiento disponibles (como el famoso algoritmo de agrupamiento K-medias [11], métodos jerárquicos, clasificadores bayesianos [6] y entropía máxima), varias características de dominios de ritmo rápido no se alinean bien con las características de los mecanismos de agrupamiento basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que el CA necesita encontrar similitud entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupamiento en la minería de datos [2], con un enfoque particular en las actualizaciones incrementales del agrupamiento, debido al tamaño muy grande de las bases de datos [3]. Sin embargo, la aplicabilidad de estos en dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupamiento diseñados para la tarea de identificación de clases en bases de datos espaciales (por ejemplo, basados en una noción basada en la densidad [4]) no son útiles para nuestro caso, ya que nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa de Kullback-Leibler que se utiliza en teoría de la probabilidad y teoría de la información [12]. Esta medida, que también se puede aplicar a variables aleatorias continuas, se basa en una medida de distancia natural de una verdadera distribución de probabilidad (ya sea basada en observaciones o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones alternen entre diferentes niveles manteniendo la estructura general y los momentos. Por ejemplo, considera las dos funciones f(x) = ( x mod2)/100 y g(x) = ( x mod2)/100 definidas en el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método de Kullback-Leibler asignará una correlación pobre entre 208 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) les dará el mayor rango en términos de similitud, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se emplea para comparar dos conjuntos de datos univariados. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida se debe compartir información, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en series temporales (por ejemplo, la predicción de fallos en discos duros [17]) y aplicaciones de bioinformática (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación. DISCUSIÓN Y CONCLUSIONES El mecanismo de selección compartida presentado en este documento no hace suposiciones sobre el formato de los datos utilizados ni sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente ligero y muy simple de ejecutar. La compartición selectiva permite a un agente beneficiarse de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como alternativa, un rendimiento equivalente al de un autoaprendiz cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivo en mejorar la estimación producida para parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayoría de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo acelerado. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinadores, es aplicable en cualquier entorno de SMA que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se presenta en la sección de evaluación general, donde los entornos fueron generados aleatoriamente de forma continua. El estadístico de Wilcoxon utilizado según se describe en este artículo para proporcionar un clasificador de similitud entre usuarios ofrece una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se esté aprendiendo. Su uso proporciona una buena medida de similitud que un agente puede utilizar para decidir cuánta información externa adoptar para sus evaluaciones. AGRADECIMIENTO La investigación reportada en este artículo fue apoyada en parte por el contrato número 55-000720, un subcontrato del Contrato No. DARPA de SRI International. FA8750-05-C-0033. Cualquier opinión, hallazgo y conclusión, o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA o el Gobierno de los Estados Unidos. Estamos agradecidos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este artículo. 9. REFERENCIAS [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la <br>gestión inteligente de interrupciones</br>. En TAMODIA 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press. [2] P. Berkhin. \n\nACM Press. [2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupamiento. Informe técnico, Software Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. Agrupamiento incremental para la minería en un entorno de almacenamiento de datos. En Proc. 24th Int. This seems to be an incomplete sentence. Could you please provide more context or the full sentence for an accurate translation? Bases de Datos Muy Grandes, VLDB, páginas 323-333, 24-27 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en bases de datos espaciales grandes con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para agentes autónomos para razonar sobre la interacción con humanos. En el Simposio de Primavera de AAAI sobre la Interacción entre Humanos y Sistemas Autónomos durante Operaciones Extendidas, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de redes bayesianas. Aprendizaje automático, 29:131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando filtrado colaborativo con agentes personales para recomendaciones más acertadas. En AAAI/IAAI, páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para interacción móvil. En UIST 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press. [9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: de principios a aplicaciones. Comunicación. ACM, 46(3):52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién está pidiendo ayuda? : un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing: Un enfoque computacional para el aprendizaje y la inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Estadíst., 22:79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en interfaces de usuario atentas. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba para determinar si una de las 2 variables aleatorias es estocásticamente mayor que la otra. Anales de Estadística Matemática, 18:50-60, 1947. [15] W. McClure. Tecnología y comando: Implicaciones para las operaciones militares en el siglo veintiuno. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de Teoría de Juegos con Aplicaciones Económicas, páginas 905-927. 1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: Una aplicación de múltiples instancias. J. Mach. Aprender. Res., 6:783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación multiagente. En AAMAS07, página (por aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones temporales para una mejor planificación coordinada entre humanos y computadoras. En el Simposio de Primavera de la AAAI sobre Gestión Distribuida de Planes y Horarios, 2006. [20] R. Vertegaal. El sistema de software GAZE: Mediando la atención conjunta en la comunicación y colaboración multiparte. En CHI, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. VanRiper. Una vista de aplicación de coordinadores: Gerentes de coordinación para los primeros intervinientes. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales mediante métodos de clasificación. Biometría, 1:80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En el Simposio AAAI sobre Adaptación, Co-evolución y Aprendizaje en Sistemas Multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agentes inteligentes distribuidos para simular el comportamiento e interacciones a nivel agregado en el campo de batalla. En SCI-2001, páginas 58-63, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 209 ",
            "candidates": [],
            "error": [
                [
                    "gestión de interrupciones",
                    "gestión inteligente de interrupciones"
                ]
            ]
        }
    }
}