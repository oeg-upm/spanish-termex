{
    "id": "C-3",
    "original_text": "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic. One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application. Another problem is adaptation to the changing characteristics of the grid environment. Existing solutions to these two problems require that a performance model for an application is known. However, constructing such models is a complex task. In this paper, we investigate an approach that does not require performance models. We start an application on any set of resources. During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics. Then, we adjust the resource set to better fit the application needs. This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements. We evaluate our approach in a number of scenarios typical for the Grid. Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1. Introduction In recent years, grid computing has become a real alternative to traditional parallel computing. A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20). However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers. One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance. Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion. In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs). Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application. Also, new, better resources may become available. To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions. The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available. This approach has been adopted by a number of systems (5; 14; 18). For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution. Predicting the application runtime on a given set of resources, however, requires knowledge about the application. Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have. In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model. We start an application on any set of resources. During the application run, we periodically collect information about the communication times and idle times of the processors. We use these statistics to automatically estimate the resource requirements of the application. Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters. Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory. Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment. A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing. It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)). It should not use static load balancing or be very sensitive to wide121 area latencies. We have applied our ideas to divide-and-conquer applications, which satisfy these requirements. Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20). We believe that our approach can be extended to other classes of applications with the given assumptions. We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20). We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios. The rest of this paper is structured as follows. In Section 2, we explain what assumptions we are making about the applications and grid resources. In Section 3, we present our resource selection and adaptation strategy. In Section 4, we describe its implementation in the Satin framework. In Section 5, we evaluate our approach in a number of grid scenarios. In Section 6, we compare our approach with the related work. Finally, in Section 7, we conclude and describe future work. 2. Background and assumptions In this section, we describe our assumptions about the applications and their resources. We assume the following resource model. The applications are running on multiple sites at the same time, where sites are clusters or supercomputers. We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3). Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth. The different sites are connected by a WAN. Communication between sites suffers from high latencies. We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths. We studied the adaptation problem in the context of divide-andconquer applications. However, we believe that our methodology can be used for other types of applications as well. In this section we summarize the assumptions about applications that are important to our approach. The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation. In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable. Processors can be added or removed at any point in the computation with little overhead. The second assumption is that the application can efficiently run on processors with different speeds. This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19). Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)). We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources. Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3. Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment. In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator. The adaptation coordinator periodically collects performance statistics from the application processors. We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources. The coordinator uses statistics from application processors to compute the weighted average efficiency. If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors. A heuristic formula is used to decide which processors have to be removed. During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors. These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency. Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating. Efficiency indicates the benefit of using multiple processors. Typically, the efficiency drops as new processors are added to the computation. Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10). The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized. Adding processors beyond this number yields little benefit. This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%. Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains. For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor. The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1. Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle. Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors. In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors. Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle. The computation is divided into monitoring periods. After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period. Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication. To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used. Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks. Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size. This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard. In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application. Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines). There is a trade-off between the accuracy of speed measurements and the overhead it incurs. The longer the benchmark, the greater the accuracy of the measurement. The more often it is run, the faster changes in processor speed are detected. In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause. Processors run the benchmark at such frequency so as not to exceed the specified overhead. In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected. This optimization will further reduce the benchmarking overhead. Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size. The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period. Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure. The sizes of tasks can vary by many orders of magnitude. At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator. Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster. The clocks of the processors are not synchronized with each other or with the clock of the coordinator. Each processor decides separately when it is time to send data. Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors. This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax. When it exceeds Emax, the coordinator requests new processors from the scheduler. The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested. The coordinator starts removing processors when the weighted average efficiency drops below Emin. The number of nodes that are removed again depends on the weighted average efficiency. The lower the efficiency, the more nodes are removed. The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%. Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors. In that case, removing bad processors will be beneficial for the application. Such low efficiency might also indicate that we simply have too many processors. In that case, removing some processors may not be beneficial but it will not harm the application. The coordinator always tries to remove the worst processors. The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead). High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient. Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication. Therefore, processors belonging to the worst cluster are preferred. Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise. The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster. The ic overhead of a cluster is an average of processor inter-cluster overheads. The α, β and γ coefficients determine the relative importance of the terms. Those coefficients are established empirically. Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation. Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application. In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes. After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation. Figure 1 shows a schematic view of the adaptation strategy. Dashed lines indicate a part that is not supported yet, as will be explained below. This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available). Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed. After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources. Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed. If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.) Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2. The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1. Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted. Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22). For example, adding nodes to a computation can be improved. Currently, we add any nodes the scheduler gives us. However, it would be more efficient to ask for the fastest processors among the available ones. This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way. Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous. An alternative approach would be ranking the processors based on parameters such as clock speed and cache size. This approach is sometimes used for resource selection for sequential applications (14). However, it is less accurate than using an application specific benchmark. Also, during application execution, we can learn some application requirements and pass them to the scheduler. One example is minimal bandwidth required by the application. The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed. The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum. Alternatively, information from a grid monitoring system can be used. Such bounds can be passed to the scheduler to avoid adding inappropriate resources. It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed. Currently we use blacklisting - we simply do not allow adding resources we removed before. This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes. We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered. If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available. Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available. Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality. The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications. We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4. Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications. With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code. Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing. Satin also provides transparent fault tolerance and malleability (23). With Satin, removing and adding processors from/to an ongoing computation incurs little overhead. We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator. The coordinator is implemented as a separate process. Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21). The core of Ibis is also implemented in Java. The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid. Ibis also provides the Ibis Registry. The Registry provides, among others, a membership service to the processors taking part in the computation. The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other. The Registry also offers fault detection (additional to the fault detection provided by the communication channels). Finally, the Registry provides the possibility to send signals to application processes. The coordinator uses this functionality to notify the processors that they need to leave the computation. Currently the Registry is implemented as a centralized server. For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers. Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency. In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system. Zorilla can be easily replaced with another grid scheduler. In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5. Performance evaluation In this section, we will evaluate our approach. We will demonstrate the performance of our mechanism in a few scenarios. The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur. This scenario allows us to measure the overhead of the adaptation support. The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links. For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version. In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed. In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3. Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4. Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes. This allows us to measure the overhead of benchmarking and collecting statistics. In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications. All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities. One of the clusters consists of 72 nodes, the others of 32 nodes. Each node contains two 1 GHz Pentium processors. Within a cluster, the nodes are connected by Fast Ethernet. The clusters are connected by the Dutch university Internet backbone. In our experiments, we used the Barnes-Hut N-body simulation. BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces. The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes. The nodes are equally divided over 3 clusters (12 nodes in each cluster). On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes. As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3). Those runtimes are shown in Figure 2, first group of bars. The comparison between runtime 3 and 1 shows the overhead of adaptation support. In this experiment it is around 15%. Almost all overhead comes from benchmarking. The benchmark is run 1-2 times per monitoring period. This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency. The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes). Using longer running applications would not allow us to finish the experimentation in a reasonable time. However, real-world grid applications typically need hours, days or even weeks to complete. For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower. For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%. Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use. This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started. We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c). The nodes were located in 1 or 2 clusters. In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters. This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version. Those runtimes are shown in Figure 2. Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3. Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters. After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters. Such a situation may happen when an application with a higher priority is started on some of the resources. Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions. After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5. Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6. Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3. Also, the iteration times became very variable. The adaptive version reacted by removing the overloaded nodes. After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes. So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values. This reduced the total runtime by 14%. The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters. We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s. To simulate low bandwidth we use the traffic-shaping techniques described in (6). The iteration durations in this experiment are shown in Figure 5. The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds. The adaptive version removed the badly connected cluster after the first monitoring period. As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38. This brought the iteration times down to around 100 seconds. The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters. Again, we simulated an overloaded uplink to one of the clusters. Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters. The iteration durations are shown in Figure 6. Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds. The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average. After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%. Since this value lies between Emin and Emax, no nodes are added or removed. This example illustrates what the advantages of opportunistic migration would be. There were faster nodes available in the system. If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further. Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters. After 500 seconds, 2 out of 3 clusters crash. The iteration durations are shown in Figure 7. After the crash, the iteration duration raised from 100 to 200 seconds. The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version. The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds. The total runtime was reduced by 13% (Figure 2). 6. Related work A number of Grid projects address the question of resource selection and adaptation. In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes. In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected. If performance degradation is detected during the computation, the resource selection phase is repeated. GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance. ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator. The main difference between these approaches and our approach is the use of performance models. The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach. However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7. Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete. Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal. As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller. Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications. Cactus (2) and GridWay (14) do not use performance models. However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus). In that case, the resource selection problem boils down to selecting the fastest machine or cluster. Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected. The application is migrated if performance degradation is detected or better resources are discovered. Both Cactus and GridWay use the number of iterations per time unit as the performance indicator. The main limitation of this methodology is that it is suitable only for sequential or single-site applications. Moreover, resource selection based on clock speed is not always accurate. Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems. The resource selection problem was also studied by the AppLeS project (5). In the context of this project, a number of applications were studied and performance models for these applications were created. Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set. AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application. Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications. Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied. The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account. Therefore, the problem is reduced to finding the right number of workers. The approach here is similar to ours in that no performance model is used. Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7. Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments. Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources. However, creating performance models is inherently difficult and requires knowledge about the application. We propose an approach that does not require in-depth knowledge about the application. We start the application on an arbitrary set of resources and monitor its performance. The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements. We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary. This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors. Our approach also allows the application to adapt to the changing grid conditions. The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines. If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes. The badness of the nodes is defined by a heuristic formula. If the weighted average efficiency raises above a certain level, new nodes are added. Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc. The application adapts fully automatically to changing conditions. We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments). Future work will involve extending our adaptation strategy to support opportunistic migration. This, however, requires grid schedulers with more sophisticated functionality than currently exists. Further research is also needed to decrease the benchmarking overhead. For example, the information about CPU load could be used to decrease the benchmarking frequency. Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run. For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions. Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands). This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators. Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl). This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ). References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo. Parallel program/component adaptivity management. In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf. The cactus worm: Experiments with resource discovery and allocation in a grid environment. Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor. Enabling applications on the grid - a gridlab overview. Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A. Brewer. ATLAS: An Infrastructure for Global Computing. In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov. Adaptive Computing on the Grid Using AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley. Experiences in programming a traffic shaper. In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski. GridSAT: A Chaff-based Distributed SAT Solver for the Grid. In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal. Simple localityaware co-allocation in peer-to-peer supercomputing. In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska. Speedup versus efficiency in parallel systems. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I. Foster. Globus toolkit version 4: Software for serviceoriented systems. In IFIP International Conference on Network and Parallel Computing, pages 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth. An Enabling Framework for Master-Worker Applications on the Computational Grid. In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny. Adaptive scheduling for master-worker applications on the computational grid. In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente. A framework for adaptive execution in grids. Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema. Experiences with the KOALA Co-Allocating Scheduler in Multiclusters. In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman. Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects. In 5th Intl Symp. On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat. A performance analysis of transposition-table-driven work scheduling in distributed search. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra. Self adaptivity in Grid computing. Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal. Efficient load balancing for wide-area divide-and-conquer applications. In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal. Satin: Simple and Efficient Java-based Grid Programming. Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal. Ibis: a Flexible and Efficient Java-based Grid Programming Environment. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes. The network weather service: A distributed resource performance forecasting service for metacomputing. Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal. Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid. In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129",
    "original_translation": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129",
    "original_sentences": [
        "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
        "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
        "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
        "Another problem is adaptation to the changing characteristics of the grid environment.",
        "Existing solutions to these two problems require that a performance model for an application is known.",
        "However, constructing such models is a complex task.",
        "In this paper, we investigate an approach that does not require performance models.",
        "We start an application on any set of resources.",
        "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
        "Then, we adjust the resource set to better fit the application needs.",
        "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
        "We evaluate our approach in a number of scenarios typical for the Grid.",
        "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
        "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
        "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
        "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
        "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
        "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
        "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
        "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
        "Also, new, better resources may become available.",
        "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
        "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
        "This approach has been adopted by a number of systems (5; 14; 18).",
        "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
        "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
        "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
        "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
        "We start an application on any set of resources.",
        "During the application run, we periodically collect information about the communication times and idle times of the processors.",
        "We use these statistics to automatically estimate the resource requirements of the application.",
        "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
        "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
        "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
        "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
        "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
        "It should not use static load balancing or be very sensitive to wide121 area latencies.",
        "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
        "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
        "We believe that our approach can be extended to other classes of applications with the given assumptions.",
        "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
        "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
        "The rest of this paper is structured as follows.",
        "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
        "In Section 3, we present our resource selection and adaptation strategy.",
        "In Section 4, we describe its implementation in the Satin framework.",
        "In Section 5, we evaluate our approach in a number of grid scenarios.",
        "In Section 6, we compare our approach with the related work.",
        "Finally, in Section 7, we conclude and describe future work. 2.",
        "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
        "We assume the following resource model.",
        "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
        "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
        "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
        "The different sites are connected by a WAN.",
        "Communication between sites suffers from high latencies.",
        "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
        "We studied the adaptation problem in the context of divide-andconquer applications.",
        "However, we believe that our methodology can be used for other types of applications as well.",
        "In this section we summarize the assumptions about applications that are important to our approach.",
        "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
        "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
        "Processors can be added or removed at any point in the computation with little overhead.",
        "The second assumption is that the application can efficiently run on processors with different speeds.",
        "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
        "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
        "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
        "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
        "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
        "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
        "The adaptation coordinator periodically collects performance statistics from the application processors.",
        "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
        "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
        "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
        "A heuristic formula is used to decide which processors have to be removed.",
        "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
        "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
        "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
        "Efficiency indicates the benefit of using multiple processors.",
        "Typically, the efficiency drops as new processors are added to the computation.",
        "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
        "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
        "Adding processors beyond this number yields little benefit.",
        "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
        "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
        "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
        "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
        "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
        "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
        "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
        "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
        "The computation is divided into monitoring periods.",
        "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
        "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
        "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
        "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
        "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
        "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
        "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
        "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
        "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
        "The longer the benchmark, the greater the accuracy of the measurement.",
        "The more often it is run, the faster changes in processor speed are detected.",
        "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
        "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
        "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
        "This optimization will further reduce the benchmarking overhead.",
        "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
        "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
        "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
        "The sizes of tasks can vary by many orders of magnitude.",
        "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
        "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
        "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
        "Each processor decides separately when it is time to send data.",
        "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
        "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
        "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
        "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
        "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
        "The number of nodes that are removed again depends on the weighted average efficiency.",
        "The lower the efficiency, the more nodes are removed.",
        "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
        "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
        "In that case, removing bad processors will be beneficial for the application.",
        "Such low efficiency might also indicate that we simply have too many processors.",
        "In that case, removing some processors may not be beneficial but it will not harm the application.",
        "The coordinator always tries to remove the worst processors.",
        "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
        "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
        "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
        "Therefore, processors belonging to the worst cluster are preferred.",
        "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
        "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
        "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
        "The α, β and γ coefficients determine the relative importance of the terms.",
        "Those coefficients are established empirically.",
        "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
        "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
        "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
        "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
        "Figure 1 shows a schematic view of the adaptation strategy.",
        "Dashed lines indicate a part that is not supported yet, as will be explained below.",
        "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
        "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
        "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
        "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
        "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
        "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
        "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
        "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
        "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
        "For example, adding nodes to a computation can be improved.",
        "Currently, we add any nodes the scheduler gives us.",
        "However, it would be more efficient to ask for the fastest processors among the available ones.",
        "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
        "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
        "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
        "This approach is sometimes used for resource selection for sequential applications (14).",
        "However, it is less accurate than using an application specific benchmark.",
        "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
        "One example is minimal bandwidth required by the application.",
        "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
        "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
        "Alternatively, information from a grid monitoring system can be used.",
        "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
        "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
        "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
        "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
        "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
        "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
        "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
        "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
        "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
        "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
        "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
        "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
        "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
        "Satin also provides transparent fault tolerance and malleability (23).",
        "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
        "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
        "The coordinator is implemented as a separate process.",
        "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
        "The core of Ibis is also implemented in Java.",
        "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
        "Ibis also provides the Ibis Registry.",
        "The Registry provides, among others, a membership service to the processors taking part in the computation.",
        "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
        "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
        "Finally, the Registry provides the possibility to send signals to application processes.",
        "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
        "Currently the Registry is implemented as a centralized server.",
        "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
        "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
        "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
        "Zorilla can be easily replaced with another grid scheduler.",
        "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
        "Performance evaluation In this section, we will evaluate our approach.",
        "We will demonstrate the performance of our mechanism in a few scenarios.",
        "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
        "This scenario allows us to measure the overhead of the adaptation support.",
        "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
        "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
        "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
        "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
        "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
        "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
        "This allows us to measure the overhead of benchmarking and collecting statistics.",
        "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
        "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
        "One of the clusters consists of 72 nodes, the others of 32 nodes.",
        "Each node contains two 1 GHz Pentium processors.",
        "Within a cluster, the nodes are connected by Fast Ethernet.",
        "The clusters are connected by the Dutch university Internet backbone.",
        "In our experiments, we used the Barnes-Hut N-body simulation.",
        "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
        "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
        "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
        "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
        "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
        "Those runtimes are shown in Figure 2, first group of bars.",
        "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
        "In this experiment it is around 15%.",
        "Almost all overhead comes from benchmarking.",
        "The benchmark is run 1-2 times per monitoring period.",
        "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
        "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
        "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
        "However, real-world grid applications typically need hours, days or even weeks to complete.",
        "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
        "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
        "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
        "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
        "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
        "The nodes were located in 1 or 2 clusters.",
        "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
        "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
        "Those runtimes are shown in Figure 2.",
        "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
        "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
        "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
        "Such a situation may happen when an application with a higher priority is started on some of the resources.",
        "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
        "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
        "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
        "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
        "Also, the iteration times became very variable.",
        "The adaptive version reacted by removing the overloaded nodes.",
        "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
        "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
        "This reduced the total runtime by 14%.",
        "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
        "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
        "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
        "The iteration durations in this experiment are shown in Figure 5.",
        "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
        "The adaptive version removed the badly connected cluster after the first monitoring period.",
        "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
        "This brought the iteration times down to around 100 seconds.",
        "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
        "Again, we simulated an overloaded uplink to one of the clusters.",
        "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
        "The iteration durations are shown in Figure 6.",
        "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
        "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
        "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
        "Since this value lies between Emin and Emax, no nodes are added or removed.",
        "This example illustrates what the advantages of opportunistic migration would be.",
        "There were faster nodes available in the system.",
        "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
        "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
        "After 500 seconds, 2 out of 3 clusters crash.",
        "The iteration durations are shown in Figure 7.",
        "After the crash, the iteration duration raised from 100 to 200 seconds.",
        "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
        "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
        "The total runtime was reduced by 13% (Figure 2). 6.",
        "Related work A number of Grid projects address the question of resource selection and adaptation.",
        "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
        "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
        "If performance degradation is detected during the computation, the resource selection phase is repeated.",
        "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
        "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
        "The main difference between these approaches and our approach is the use of performance models.",
        "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
        "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
        "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
        "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
        "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
        "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
        "Cactus (2) and GridWay (14) do not use performance models.",
        "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
        "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
        "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
        "The application is migrated if performance degradation is detected or better resources are discovered.",
        "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
        "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
        "Moreover, resource selection based on clock speed is not always accurate.",
        "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
        "The resource selection problem was also studied by the AppLeS project (5).",
        "In the context of this project, a number of applications were studied and performance models for these applications were created.",
        "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
        "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
        "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
        "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
        "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
        "Therefore, the problem is reduced to finding the right number of workers.",
        "The approach here is similar to ours in that no performance model is used.",
        "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
        "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
        "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
        "However, creating performance models is inherently difficult and requires knowledge about the application.",
        "We propose an approach that does not require in-depth knowledge about the application.",
        "We start the application on an arbitrary set of resources and monitor its performance.",
        "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
        "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
        "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
        "Our approach also allows the application to adapt to the changing grid conditions.",
        "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
        "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
        "The badness of the nodes is defined by a heuristic formula.",
        "If the weighted average efficiency raises above a certain level, new nodes are added.",
        "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
        "The application adapts fully automatically to changing conditions.",
        "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
        "Future work will involve extending our adaptation strategy to support opportunistic migration.",
        "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
        "Further research is also needed to decrease the benchmarking overhead.",
        "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
        "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
        "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
        "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
        "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
        "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
        "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
        "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
        "Parallel program/component adaptivity management.",
        "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
        "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
        "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
        "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
        "Enabling applications on the grid - a gridlab overview.",
        "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
        "Brewer.",
        "ATLAS: An Infrastructure for Global Computing.",
        "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
        "Adaptive Computing on the Grid Using AppLeS.",
        "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
        "Experiences in programming a traffic shaper.",
        "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
        "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
        "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
        "Simple localityaware co-allocation in peer-to-peer supercomputing.",
        "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
        "Speedup versus efficiency in parallel systems.",
        "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
        "Foster.",
        "Globus toolkit version 4: Software for serviceoriented systems.",
        "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
        "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
        "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
        "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
        "Adaptive scheduling for master-worker applications on the computational grid.",
        "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
        "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
        "A framework for adaptive execution in grids.",
        "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
        "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
        "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
        "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
        "In 5th Intl Symp.",
        "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
        "A performance analysis of transposition-table-driven work scheduling in distributed search.",
        "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
        "Self adaptivity in Grid computing.",
        "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
        "Efficient load balancing for wide-area divide-and-conquer applications.",
        "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
        "Satin: Simple and Efficient Java-based Grid Programming.",
        "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
        "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
        "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
        "The network weather service: A distributed resource performance forecasting service for metacomputing.",
        "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
        "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
        "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
    ],
    "translated_text_sentences": [
        "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
        "de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas.",
        "Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación.",
        "Otro problema es la adaptación a las características cambiantes del entorno de la red.",
        "Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación.",
        "Sin embargo, construir tales modelos es una tarea compleja.",
        "En este artículo, investigamos un enfoque que no requiere modelos de rendimiento.",
        "Iniciamos una aplicación en cualquier conjunto de recursos.",
        "Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas.",
        "Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación.",
        "Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento.",
        "Evaluamos nuestro enfoque en varios escenarios típicos para la Red.",
        "Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1.",
        "En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional.",
        "Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo.",
        "Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras.",
        "Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento.",
        "Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental.",
        "En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha.",
        "Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad.",
        "Además, nuevos y mejores recursos pueden estar disponibles.",
        "Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes.",
        "El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos.",
        "Este enfoque ha sido adoptado por varios sistemas (5; 14; 18).",
        "Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución.",
        "Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación.",
        "Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener.",
        "En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento.",
        "Iniciamos una aplicación en cualquier conjunto de recursos.",
        "Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores.",
        "Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación.",
        "A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros.",
        "Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría.",
        "Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante.",
        "Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla.",
        "Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado.",
        "No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área.",
        "Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos.",
        "La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20).",
        "Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas.",
        "Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20).",
        "Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente.",
        "El resto de este documento está estructurado de la siguiente manera.",
        "En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica.",
        "En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos.",
        "En la Sección 4, describimos su implementación en el marco de trabajo Satin.",
        "En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula.",
        "En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado.",
        "Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2.",
        "Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos.",
        "Asumimos el siguiente modelo de recursos.",
        "Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras.",
        "También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3).",
        "Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda.",
        "Los diferentes sitios están conectados por una WAN.",
        "La comunicación entre los sitios sufre de altas latencias.",
        "Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda.",
        "Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás.",
        "Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones.",
        "En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque.",
        "La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso.",
        "En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables.",
        "Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional.",
        "La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes.",
        "Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19).",
        "Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)).",
        "Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red.",
        "Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área.",
        "Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red.",
        "Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación.",
        "El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación.",
        "Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos.",
        "El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada.",
        "Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores.",
        "Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados.",
        "Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados.",
        "Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia.",
        "La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose.",
        "La eficiencia indica el beneficio de utilizar múltiples procesadores.",
        "Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo.",
        "Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10).",
        "El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza.",
        "Agregar procesadores más allá de este número aporta poco beneficio.",
        "Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%.",
        "Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento.",
        "Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido.",
        "El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1.",
        "Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos.",
        "La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos.",
        "En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados.",
        "Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo.",
        "La computación se divide en períodos de monitoreo.",
        "Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período.",
        "Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster.",
        "Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado.",
        "Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación.",
        "Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema.",
        "Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil.",
        "En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original.",
        "Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido).",
        "Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva.",
        "Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición.",
        "Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador.",
        "En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar.",
        "Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada.",
        "En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador.",
        "Esta optimización reducirá aún más la sobrecarga de referencia.",
        "Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar.",
        "La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo.",
        "Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular.",
        "Los tamaños de las tareas pueden variar por muchas órdenes de magnitud.",
        "Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador.",
        "Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster.",
        "Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador.",
        "Cada procesador decide por separado cuándo es el momento de enviar datos.",
        "Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores.",
        "Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax.",
        "Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador.",
        "El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores.",
        "El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin.",
        "El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada.",
        "Cuanto menor sea la eficiencia, más nodos se eliminan.",
        "Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%.",
        "Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados.",
        "En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación.",
        "Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores.",
        "En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación.",
        "El coordinador siempre intenta eliminar los procesadores más deficientes.",
        "La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead).",
        "Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente.",
        "Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia.",
        "Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster.",
        "La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario.",
        "La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido.",
        "El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador.",
        "Los coeficientes α, β y γ determinan la importancia relativa de los términos.",
        "Esos coeficientes se establecen de manera empírica.",
        "Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación.",
        "Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación.",
        "En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores.",
        "Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación.",
        "La Figura 1 muestra una vista esquemática de la estrategia de adaptación.",
        "Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación.",
        "Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles).",
        "Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados.",
        "Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos.",
        "Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados.",
        "Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos).",
        "Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2.",
        "Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1.",
        "Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente.",
        "Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22).",
        "Por ejemplo, se puede mejorar agregando nodos a una computación.",
        "Actualmente, agregamos cualquier nodo que nos proporcione el planificador.",
        "Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles.",
        "Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación.",
        "Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos.",
        "Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché.",
        "Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14).",
        "Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación.",
        "Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador.",
        "Un ejemplo es el ancho de banda mínimo requerido por la aplicación.",
        "El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres.",
        "El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo.",
        "Alternativamente, se puede utilizar información de un sistema de monitoreo de red.",
        "Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados.",
        "Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar.",
        "Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente.",
        "Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye.",
        "Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos.",
        "Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores.",
        "Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles.",
        "Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad.",
        "Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas.",
        "Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos.",
        "Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula.",
        "Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario.",
        "Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto.",
        "Satin también proporciona tolerancia a fallos transparente y maleabilidad (23).",
        "Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto.",
        "Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación.",
        "El coordinador se implementa como un proceso separado.",
        "Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21).",
        "El núcleo de Ibis también está implementado en Java.",
        "El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea.",
        "Ibis también proporciona el Registro Ibis.",
        "El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación.",
        "El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente.",
        "El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación).",
        "Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación.",
        "El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación.",
        "Actualmente, el Registro está implementado como un servidor centralizado.",
        "Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras.",
        "Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación.",
        "En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema.",
        "Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula.",
        "En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11).",
        "Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque.",
        "Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios.",
        "El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc.",
        "Este escenario nos permite medir el sobrecosto del soporte de adaptación.",
        "Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados.",
        "Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa.",
        "En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores).",
        "En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3.",
        "Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4.",
        "Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos.",
        "Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas.",
        "En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones.",
        "Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas.",
        "Uno de los grupos consiste en 72 nodos, los otros en 32 nodos.",
        "Cada nodo contiene dos procesadores Pentium de 1 GHz.",
        "Dentro de un clúster, los nodos están conectados por Fast Ethernet.",
        "Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa.",
        "En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut.",
        "BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas).",
        "La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos.",
        "Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo).",
        "En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos.",
        "Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3).",
        "Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras.",
        "La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación.",
        "En este experimento es alrededor del 15%.",
        "Casi todos los gastos generales provienen de la comparación con estándares.",
        "El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo.",
        "Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia.",
        "El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos).",
        "El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable.",
        "Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse.",
        "Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación.",
        "Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%.",
        "Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente.",
        "Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación.",
        "Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c).",
        "Los nodos estaban ubicados en 1 o 2 grupos.",
        "En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres.",
        "Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa.",
        "Esos tiempos de ejecución se muestran en la Figura 2.",
        "Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3.",
        "La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres.",
        "Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos.",
        "Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos.",
        "La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa.",
        "Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5.",
        "Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6.",
        "Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3.",
        "Además, los tiempos de iteración se volvieron muy variables.",
        "La versión adaptativa reaccionó eliminando los nodos sobrecargados.",
        "Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos.",
        "Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales.",
        "Esto redujo el tiempo total de ejecución en un 14%.",
        "Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres.",
        "Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s.",
        "Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6).",
        "Las duraciones de las iteraciones en este experimento se muestran en la Figura 5.",
        "Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos.",
        "La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo.",
        "Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38.",
        "Esto redujo los tiempos de iteración a alrededor de 100 segundos.",
        "El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres.",
        "Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres.",
        "Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes.",
        "Las duraciones de las iteraciones se muestran en la Figura 6.",
        "Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos.",
        "La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio.",
        "Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%.",
        "Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos.",
        "Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista.",
        "Había nodos más rápidos disponibles en el sistema.",
        "Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más.",
        "Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres.",
        "Después de 500 segundos, 2 de cada 3 grupos se bloquean.",
        "Las duraciones de las iteraciones se muestran en la Figura 7.",
        "Después del choque, la duración de la iteración aumentó de 100 a 200 segundos.",
        "La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa.",
        "El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos.",
        "El tiempo total de ejecución se redujo en un 13% (Figura 2).",
        "Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos.",
        "En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación.",
        "En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto.",
        "Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos.",
        "GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación.",
        "ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento.",
        "La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento.",
        "La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque.",
        "Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7.",
        "Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo.",
        "Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo.",
        "A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño.",
        "Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares.",
        "Cactus (2) y GridWay (14) no utilizan modelos de rendimiento.",
        "Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus).",
        "En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido.",
        "La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta.",
        "La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores.",
        "Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento.",
        "La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio.",
        "Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa.",
        "Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización.",
        "El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5).",
        "En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones.",
        "Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto.",
        "Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación.",
        "También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST).",
        "La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador.",
        "Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación.",
        "Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores.",
        "El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento.",
        "En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal.",
        "Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid.",
        "Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos.",
        "Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación.",
        "Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación.",
        "Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento.",
        "El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones.",
        "Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario.",
        "Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados.",
        "Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula.",
        "Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas.",
        "Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes.",
        "La maldad de los nodos está definida por una fórmula heurística.",
        "Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos.",
        "Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc.",
        "La aplicación se adapta completamente de forma automática a las condiciones cambiantes.",
        "Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos).",
        "El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista.",
        "Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente.",
        "También se necesita realizar más investigaciones para reducir la sobrecarga de comparación.",
        "Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento.",
        "Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación.",
        "Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas.",
        "Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles).",
        "Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores.",
        "Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl).",
        "Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ).",
        "Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo.",
        "Gestión de adaptabilidad de programas/componentes en paralelo.",
        "En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I.",
        "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf.",
        "El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula.",
        "Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor.",
        "Habilitando aplicaciones en la red - una visión general de gridlab.",
        "Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A.",
        "Cervecero.",
        "ATLAS: Una infraestructura para la computación global.",
        "En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov.",
        "Computación adaptativa en la red utilizando AppLeS.",
        "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley.",
        "Experiencias en programar un modelador de tráfico.",
        "En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski.",
        "GridSAT: Un solucionador SAT distribuido basado en Chaff para la red.",
        "En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal.",
        "Co-asignación simple consciente de la localidad en supercomputación entre pares.",
        "En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska.",
        "Aceleración versus eficiencia en sistemas paralelos.",
        "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I.",
        "Fomentar.",
        "Herramienta Globus versión 4: Software para sistemas orientados a servicios.",
        "En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13.",
        "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth.",
        "Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional.",
        "En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny.",
        "Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional.",
        "En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227.",
        "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente.",
        "Un marco para la ejecución adaptativa en rejillas.",
        "Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema.",
        "Experiencias con el planificador de asignación conjunta KOALA en multiclústeres.",
        "En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman.",
        "Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas.",
        "En el 5to Simposio Internacional.",
        "En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat.",
        "Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida.",
        "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra.",
        "Adaptabilidad automática en la computación en malla.",
        "Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal.",
        "Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área.",
        "En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal.",
        "Satin: Programación en cuadrícula simple y eficiente basada en Java.",
        "Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal.",
        "Ibis: un entorno de programación en malla flexible y eficiente basado en Java.",
        "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes.",
        "El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación.",
        "Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal.",
        "Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red.",
        "En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129"
    ],
    "error_count": 5,
    "keys": {
        "grid computing": {
            "translated_key": "computación en malla",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in <br>grid computing</br> is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, <br>grid computing</br> has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for <br>grid computing</br>.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on <br>grid computing</br>, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in <br>grid computing</br>.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "One important problem in <br>grid computing</br> is resource selection, that is, finding an appropriate resource set for the application.",
                "Introduction In recent years, <br>grid computing</br> has become a real alternative to traditional parallel computing.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for <br>grid computing</br>.",
                "In 1st IEEE/ACM International Workshop on <br>grid computing</br>, pages 214-227.",
                "Self adaptivity in <br>grid computing</br>."
            ],
            "translated_annotated_samples": [
                "Un problema importante en la <br>computación en malla</br> es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación.",
                "En los últimos años, la <br>computación en malla</br> se ha convertido en una verdadera alternativa a la computación paralela tradicional.",
                "Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la <br>computación en malla</br>.",
                "En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227.",
                "Adaptabilidad automática en la <br>computación en malla</br>."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la <br>computación en malla</br> es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la <br>computación en malla</br> se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la <br>computación en malla</br>. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la <br>computación en malla</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "resource selection": {
            "translated_key": "selección de recursos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is <br>resource selection</br>, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is <br>resource selection</br> - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the <br>resource selection</br> problem: the <br>resource selection</br> phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For <br>resource selection</br>, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and <br>resource selection</br> which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our <br>resource selection</br> and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for <br>resource selection</br> for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial <br>resource selection</br>. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of <br>resource selection</br> and adaptation.",
                "In GrADS (18) and ASSIST (1), <br>resource selection</br> and adaptation requires a performance model that allows predicting application runtimes.",
                "In the <br>resource selection</br> phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the <br>resource selection</br> phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the <br>resource selection</br> problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, <br>resource selection</br> based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The <br>resource selection</br> problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of <br>resource selection</br> and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "One important problem in grid computing is <br>resource selection</br>, that is, finding an appropriate resource set for the application.",
                "One important problem is <br>resource selection</br> - selecting a set of compute nodes such that the application achieves good performance.",
                "The adaptation problem can be reduced to the <br>resource selection</br> problem: the <br>resource selection</br> phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "For <br>resource selection</br>, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and <br>resource selection</br> which does not need a performance model."
            ],
            "translated_annotated_samples": [
                "Un problema importante en la computación en malla es la <br>selección de recursos</br>, es decir, encontrar un conjunto de recursos adecuado para la aplicación.",
                "Un problema importante es la <br>selección de recursos</br>: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento.",
                "El problema de adaptación se puede reducir al problema de <br>selección de recursos</br>: la fase de <br>selección de recursos</br> se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos.",
                "Para la <br>selección de recursos</br>, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución.",
                "En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la <br>selección de recursos</br> que no requiere un modelo de rendimiento."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la <br>selección de recursos</br>, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la <br>selección de recursos</br>: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de <br>selección de recursos</br>: la fase de <br>selección de recursos</br> se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la <br>selección de recursos</br>, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la <br>selección de recursos</br> que no requiere un modelo de rendimiento. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "grid environment": {
            "translated_key": "entorno de la red",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the <br>grid environment</br>.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a <br>grid environment</br> this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the <br>grid environment</br>.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a <br>grid environment</br>.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "Another problem is adaptation to the changing characteristics of the <br>grid environment</br>.",
                "In a <br>grid environment</br> this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the <br>grid environment</br>.",
                "The cactus worm: Experiments with resource discovery and allocation in a <br>grid environment</br>."
            ],
            "translated_annotated_samples": [
                "Otro problema es la adaptación a las características cambiantes del <br>entorno de la red</br>.",
                "En un <br>entorno de cuadrícula</br>, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha.",
                "Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el <br>entorno de la red</br>.",
                "El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un <br>entorno de cuadrícula</br>."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del <br>entorno de la red</br>. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un <br>entorno de cuadrícula</br>, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el <br>entorno de la red</br>. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un <br>entorno de cuadrícula</br>. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    "entorno de la red",
                    "entorno de cuadrícula",
                    "entorno de la red",
                    "entorno de cuadrícula"
                ]
            ]
        },
        "parallel computing": {
            "translated_key": "computación paralela",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional <br>parallel computing</br>.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional <br>parallel computing</br>, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and <br>parallel computing</br>, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "Introduction In recent years, grid computing has become a real alternative to traditional <br>parallel computing</br>.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional <br>parallel computing</br>, a standard metric describing the performance of a parallel application is efficiency.",
                "In IFIP International Conference on Network and <br>parallel computing</br>, pages 2-13."
            ],
            "translated_annotated_samples": [
                "En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la <br>computación paralela</br> tradicional.",
                "Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la <br>computación paralela</br> tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia.",
                "En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la <br>computación paralela</br> tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la <br>computación paralela</br> tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "homogeneous parallel environment": {
            "translated_key": "entornos paralelos tradicionales y homogéneos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, <br>homogeneous parallel environment</br>s, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "Even in traditional, <br>homogeneous parallel environment</br>s, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion."
            ],
            "translated_annotated_samples": [
                "Incluso en <br>entornos paralelos tradicionales y homogéneos</br>, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en <br>entornos paralelos tradicionales y homogéneos</br>, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "heterogeneity of resource": {
            "translated_key": "heterogeneidad de recursos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the <br>heterogeneity of resource</br>s: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "In a grid environment this problem is even more difficult, because of the <br>heterogeneity of resource</br>s: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs)."
            ],
            "translated_annotated_samples": [
                "En un entorno de cuadrícula, este problema es aún más difícil debido a la <br>heterogeneidad de recursos</br>: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la <br>heterogeneidad de recursos</br>: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "resource heterogeneity": {
            "translated_key": "heterogeneidad de recursos",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "high-bandwidth local-area network": {
            "translated_key": "redes de área local (LAN) de baja latencia y alta velocidad de banda ancha",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and <br>high-bandwidth local-area network</br>s (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and <br>high-bandwidth local-area network</br>s (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs)."
            ],
            "translated_annotated_samples": [
                "En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde <br>redes de área local (LAN) de baja latencia y alta velocidad de banda ancha</br> hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde <br>redes de área local (LAN) de baja latencia y alta velocidad de banda ancha</br> hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "lower-bandwidth wide-area network": {
            "translated_key": "red de área amplia de baja capacidad de ancho de banda",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "network link": {
            "translated_key": "enlace de red",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded <br>network link</br> 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded <br>network link</br> duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded <br>network link</br> In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded <br>network link</br> In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "Barnes-Hut iteration durations with/without adaptation, overloaded <br>network link</br> 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded <br>network link</br> duration increased by a factor of 2 to 3.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded <br>network link</br> In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded <br>network link</br> In this scenario, we ran the application on 36 nodes in 3 clusters."
            ],
            "translated_annotated_samples": [
                "Duraciones de iteración de Barnes-Hut con/sin adaptación, <br>enlace de red</br> sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6.",
                "Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un <br>enlace de red</br> sobrecargado aumentaron por un factor de 2 a 3.",
                "Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: <br>enlace de red</br> sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres.",
                "El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un <br>enlace de red</br> sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, <br>enlace de red</br> sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un <br>enlace de red</br> sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: <br>enlace de red</br> sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un <br>enlace de red</br> sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "communication time": {
            "translated_key": "tiempos de comunicación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the <br>communication time</br>s and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "During the application run, we periodically collect information about the <br>communication time</br>s and idle times of the processors."
            ],
            "translated_annotated_samples": [
                "Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los <br>tiempos de comunicación</br> y los tiempos de inactividad de los procesadores."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los <br>tiempos de comunicación</br> y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "idle times of the processors": {
            "translated_key": "tiempos de inactividad de los procesadores",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and <br>idle times of the processors</br>.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "During the application run, we periodically collect information about the communication times and <br>idle times of the processors</br>."
            ],
            "translated_annotated_samples": [
                "Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los <br>tiempos de inactividad de los procesadores</br>."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los <br>tiempos de inactividad de los procesadores</br>. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "the processor idle time": {
            "translated_key": "el tiempo de inactividad del procesador",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "degree of parallelism": {
            "translated_key": "grado de paralelismo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the <br>degree of parallelism</br> in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its <br>degree of parallelism</br> allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application <br>degree of parallelism</br> is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "It handles all of the following cases: • automatically adapting the number of processors to the <br>degree of parallelism</br> in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its <br>degree of parallelism</br> allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Adaptation strategy • If the application <br>degree of parallelism</br> is changing during the computation, the number of nodes the application is running on will be automatically adjusted."
            ],
            "translated_annotated_samples": [
                "Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al <br>grado de paralelismo</br> en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado.",
                "Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su <br>grado de paralelismo</br>, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles).",
                "Estrategia de adaptación • Si el <br>grado de paralelismo</br> de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al <br>grado de paralelismo</br> en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su <br>grado de paralelismo</br>, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el <br>grado de paralelismo</br> de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "parallelism degree": {
            "translated_key": "grado de paralelismo",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "overloaded resource": {
            "translated_key": "recursos sobrecargados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from <br>overloaded resource</br>s • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the <br>overloaded resource</br>s will be removed.",
                "After removing the <br>overloaded resource</br>s, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from <br>overloaded resource</br>s. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from <br>overloaded resource</br>s • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the <br>overloaded resource</br>s will be removed.",
                "After removing the <br>overloaded resource</br>s, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from <br>overloaded resource</br>s. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed."
            ],
            "translated_annotated_samples": [
                "Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de <br>recursos sobrecargados</br> • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado.",
                "Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los <br>recursos sobrecargados</br> serán eliminados.",
                "Después de eliminar los <br>recursos sobrecargados</br>, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos.",
                "Por lo tanto, la aplicación será migrada de <br>recursos sobrecargados</br>. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de <br>recursos sobrecargados</br> • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los <br>recursos sobrecargados</br> serán eliminados. Después de eliminar los <br>recursos sobrecargados</br>, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de <br>recursos sobrecargados</br>. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.\nTransacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.\n\nConcurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "divide-and-conquer": {
            "translated_key": "divide y vencerás",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to <br>divide-and-conquer</br> applications, which satisfy these requirements.",
                "<br>divide-and-conquer</br> has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled <br>divide-and-conquer</br> applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by <br>divide-and-conquer</br> applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, <br>divide-and-conquer</br> applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled <br>divide-and-conquer</br> applications.",
                "With Satin, the programmer annotates the sequential code with <br>divide-and-conquer</br> primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin <br>divide-and-conquer</br> framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area <br>divide-and-conquer</br> applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [
                "We have applied our ideas to <br>divide-and-conquer</br> applications, which satisfy these requirements.",
                "<br>divide-and-conquer</br> has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled <br>divide-and-conquer</br> applications (20).",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by <br>divide-and-conquer</br> applications (19).",
                "Unfortunately, <br>divide-and-conquer</br> applications typically exhibit a very irregular structure."
            ],
            "translated_annotated_samples": [
                "Hemos aplicado nuestras ideas a aplicaciones de <br>dividir y conquistar</br>, que cumplen con estos requisitos.",
                "La técnica de <br>divide y vencerás</br> ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20).",
                "Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de <br>división y conquista</br> habilitadas para la cuadrícula (20).",
                "Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de <br>divide y vencerás</br> (19).",
                "Desafortunadamente, las aplicaciones de <br>divide y vencerás</br> suelen presentar una estructura muy irregular."
            ],
            "translated_text": "Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de <br>dividir y conquistar</br>, que cumplen con estos requisitos. La técnica de <br>divide y vencerás</br> ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de <br>división y conquista</br> habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de <br>divide y vencerás</br> (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de <br>divide y vencerás</br> suelen presentar una estructura muy irregular. ",
            "candidates": [],
            "error": [
                [
                    "dividir y conquistar",
                    "divide y vencerás",
                    "división y conquista",
                    "divide y vencerás",
                    "divide y vencerás"
                ]
            ]
        },
        "self-adaptivity": {
            "translated_key": "autoadaptabilidad",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}