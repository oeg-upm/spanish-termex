{
    "id": "I-48",
    "original_text": "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB. 2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model. In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system. A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system. We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy. Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not. We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1. INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1]. Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge. The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15]. However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not. This model of normative systems was further extended by attributing to each agent a single goal in [16]. However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law. In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate. In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority. We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy. Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not. We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4]. We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2. KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8]. A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens). We let S0 denote the set of possible initial states of the system. Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents. It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action. This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation. However, we find it convenient to include within our model the agents that cause transitions. We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A. Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state. Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state. In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure. A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on). A path π such that π[0] = s is an s-path. Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s). We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1. Our running example is of a system with a single non-sharable resource, which is desired by two agents. Consider the Kripke structure depicted in Figure 1. We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here. It is also worth noting that for some domains, other constraints may be more appropriate than simple totality. For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive. Think of pi as meaning agent i has currently control over the resource. Each agent has two possible actions, when in possession of the resource: either give it away, or keep it. Obviously there are infinitely many different s-paths and t-paths. Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8]. Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse. We will use CTL to express agents goals. The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ. We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it. The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language. The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t. K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t. K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner. The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8]. We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3. NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1]. More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not. Different normative systems may differ on whether or not a transition is legal. Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation. The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor. Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η. Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state. We denote the empty normative system by η∅, so η∅ = ∅. Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]). If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η. Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise. Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t). A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever. Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}. Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system. In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system. Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C). Note that we have η C = η (A\\C) and η C = η (A\\C). EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}. Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4. GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system. We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold. The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i. Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy. Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = . We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on. We denote the largest index of any element in γ by |γ|. A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy. Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1]. The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level. Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies. EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself. Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8). Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds. Goal ϕi 6 is a fairness constraint implied by it. Note that A♦pi says that every computation eventually reaches a pi state. This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state. The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi . Goal ϕi 3 says that pi should be true on some branch, from some moment on. It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi . This implies ϕi 1, which says that pi should at least not be impossible. If we even drop that demand, we have the trivial goal ϕi 0. We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi . However, this is not a proper CTL formula. It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent. However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like. Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]). We comment on the implications of alternative goal representations at the conclusion of the next section. A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system. Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent. The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure. We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example. Recall that we have defined S0 as {s, t}. Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not. To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true. Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0. Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale. The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j . Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting. However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied. There are other representations for goals, which would allow us to define cardinal utilities. The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R. We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility. We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity. Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems. Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K). Then the utility of η to agent i wrt K is δi (K, K † η). We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative. Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure. If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system. We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent. A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M . EXAMPLE 1. The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before. Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15]. Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system. Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2. Note that typically K † η K. Then we have (cf. [15]). THEOREM 1. Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1. Let K be a structure, and η a normative system. Let γi denote a goal hierarchy for agent i. 1. Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula). Then, for any normative system η, δi (K, η) ≥ 0. 2. Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε. Then, δi (K † η, K) ≥ 0. Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η. The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true). It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η. The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η. Hence, an agent with only existential goals might well fear any norm η. However, these observations implicitly assume that all agents in the system will comply with the norm. Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do. This motivates us to consider normative system games. 5. NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them. Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective). Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not? Note that this reasoning takes place before the agent is in the system - it is a design time consideration. We can understand the reasoning here as a game, as follows. A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents. Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn . Then we can associate a game - the normative system game - GΣ with Σ, as follows. The agents AG in GΣ are as in Σ. Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system. If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ. Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ. We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ). So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0. In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η). We can now start to investigate some properties of normative system games. EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2. For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only. This means that the transitions are R \\ {(s, s)}. In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1. This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0. Agent 2 of course benefits if agent 1 complies with η3 while 2 does not. His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise. This is a necessary, although not sufficient condition on a norm to expect that everybody respects it. Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows. Let Σ = M , η be a social system. Then the following are equivalent: The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ. The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M . Question: Does there exist an individually rational normative system for M ? THEOREM 2. IRNS is NP-complete, even in one-agent systems. PROOF. For membership of NP, guess a normative system η, and verify that it is individually rational. Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time. To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ. Hence verifying that ui (K † η) > ui (K) requires only polynomial time. For NP-hardness, we reduce SAT [12, p.77]. Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows. First, we define a single agent A = {1}. For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance. We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ. Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )). Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable. First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1]. For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both. So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true. The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ. For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state. The resulting normative system ensures γ1[1], and is thus individually rational. Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7]. Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off. In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient. This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η. If η makes every agent better off than η, then we say η Pareto dominates η. The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M . Question: Is η Pareto efficient for M ? THEOREM 3. PENS is co-NP-complete, even for one-agent systems. PROOF. Let M and η be as in the Theorem. We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete. In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η. For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time. Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time. For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2. Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system. Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M . Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example? Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}. The utilities for each system are given in Table 1. From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7. Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14]. A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs. Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play. Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2). In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ. The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply. If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.) NASH IMPLEMENTATION (NI) : Given: Multi-agent system M . Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation? Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time. THEOREM 4. The NI problem is NP-complete, even for twoagent systems. PROOF. For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time. For NP-hardness, we reduce SAT. Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk . Then we construct an instance of NI as follows. We create two agents, A = {1, 2}. For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state. For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi . Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ. Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true. We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true. No other arcs, apart from those so defined, as included in η. Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system. To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D). For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅. Then ϕ is satisfiable; for suppose not. Then the goals γi [2] are not achievable by any normative system, (by construction). Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η. But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium. This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9]. The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]). In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete. It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem. To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6. CONCLUSIONS Social norms are supposed to restrict our behaviour. Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour. The question then, for an agent is, how to be sure that others will comply with a norm. And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm. Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions. We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them. Of course, our approach is in many senses open for extension or enrichment. An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7. REFERENCES [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge. On the logic of normative systems. In Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman. Alternating-time temporal logic. Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore. Game Theory and the Social Contract Volume 1: Playing Fair. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Game Theory and the Social Contract Volume 2: Just Playing. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm. Complexity of mechanism design. In Proc. UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm. Complexity results about nash equilibria. In Proc. IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a Nash equilibrium. In Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson. Temporal and modal logic. In Handbook of Theor. Comp. Sci. Vol. B, pages 996-1072. Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern. Sometimes and not never revisited: on branching time versus linear time temporal logic. Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz. Choosing social laws for multi-agent systems: Minimality and simplicity. Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein. A Course in Game Theory. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Computational Complexity. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz. On the synthesis of useful social laws for artificial agent societies. In Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz. On social laws for artificial agent societies: Off-line design. In Computational Theories of Interaction and Agency, pages 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. Social laws in alternating time: Effectiveness, feasibility, and synthesis. Synthese, 2007. [16] M. Wooldridge and W. van der Hoek. On obligations and normative ability. Jnl. of Appl. Logic, 3:396-420, 2005. 888 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)",
    "original_translation": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07)",
    "original_sentences": [
        "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
        "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
        "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
        "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
        "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
        "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
        "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
        "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
        "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
        "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
        "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
        "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
        "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
        "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
        "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
        "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
        "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
        "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
        "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
        "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
        "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
        "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
        "We let S0 denote the set of possible initial states of the system.",
        "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
        "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
        "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
        "However, we find it convenient to include within our model the agents that cause transitions.",
        "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
        "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
        "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
        "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
        "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
        "A path π such that π[0] = s is an s-path.",
        "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
        "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
        "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
        "Consider the Kripke structure depicted in Figure 1.",
        "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
        "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
        "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
        "Think of pi as meaning agent i has currently control over the resource.",
        "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
        "Obviously there are infinitely many different s-paths and t-paths.",
        "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
        "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
        "We will use CTL to express agents goals.",
        "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
        "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
        "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
        "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
        "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
        "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
        "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
        "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
        "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
        "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
        "Different normative systems may differ on whether or not a transition is legal.",
        "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
        "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
        "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
        "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
        "We denote the empty normative system by η∅, so η∅ = ∅.",
        "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
        "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
        "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
        "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
        "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
        "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
        "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
        "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
        "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
        "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
        "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
        "Note that we have η C = η (A\\C) and η C = η (A\\C).",
        "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
        "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
        "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
        "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
        "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
        "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
        "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
        "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
        "We denote the largest index of any element in γ by |γ|.",
        "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
        "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
        "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
        "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
        "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
        "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
        "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
        "Goal ϕi 6 is a fairness constraint implied by it.",
        "Note that A♦pi says that every computation eventually reaches a pi state.",
        "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
        "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
        "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
        "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
        "This implies ϕi 1, which says that pi should at least not be impossible.",
        "If we even drop that demand, we have the trivial goal ϕi 0.",
        "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
        "However, this is not a proper CTL formula.",
        "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
        "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
        "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
        "We comment on the implications of alternative goal representations at the conclusion of the next section.",
        "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
        "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
        "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
        "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
        "Recall that we have defined S0 as {s, t}.",
        "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
        "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
        "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
        "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
        "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
        "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
        "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
        "There are other representations for goals, which would allow us to define cardinal utilities.",
        "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
        "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
        "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
        "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
        "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
        "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
        "Then the utility of η to agent i wrt K is δi (K, K † η).",
        "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
        "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
        "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
        "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
        "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
        "EXAMPLE 1.",
        "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
        "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
        "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
        "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
        "Note that typically K † η K. Then we have (cf. [15]).",
        "THEOREM 1.",
        "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
        "Let K be a structure, and η a normative system.",
        "Let γi denote a goal hierarchy for agent i. 1.",
        "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
        "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
        "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
        "Then, δi (K † η, K) ≥ 0.",
        "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
        "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
        "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
        "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
        "Hence, an agent with only existential goals might well fear any norm η.",
        "However, these observations implicitly assume that all agents in the system will comply with the norm.",
        "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
        "This motivates us to consider normative system games. 5.",
        "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
        "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
        "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
        "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
        "We can understand the reasoning here as a game, as follows.",
        "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
        "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
        "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
        "The agents AG in GΣ are as in Σ.",
        "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
        "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
        "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
        "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
        "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
        "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
        "We can now start to investigate some properties of normative system games.",
        "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
        "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
        "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
        "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
        "This means that the transitions are R \\ {(s, s)}.",
        "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
        "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
        "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
        "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
        "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
        "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
        "Let Σ = M , η be a social system.",
        "Then the following are equivalent: The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
        "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
        "Question: Does there exist an individually rational normative system for M ?",
        "THEOREM 2.",
        "IRNS is NP-complete, even in one-agent systems.",
        "PROOF.",
        "For membership of NP, guess a normative system η, and verify that it is individually rational.",
        "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
        "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
        "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
        "For NP-hardness, we reduce SAT [12, p.77].",
        "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
        "First, we define a single agent A = {1}.",
        "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
        "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
        "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
        "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
        "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
        "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
        "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
        "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
        "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
        "The resulting normative system ensures γ1[1], and is thus individually rational.",
        "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
        "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
        "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
        "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
        "If η makes every agent better off than η, then we say η Pareto dominates η.",
        "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
        "Question: Is η Pareto efficient for M ?",
        "THEOREM 3.",
        "PENS is co-NP-complete, even for one-agent systems.",
        "PROOF.",
        "Let M and η be as in the Theorem.",
        "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
        "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
        "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
        "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
        "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
        "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
        "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
        "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
        "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
        "The utilities for each system are given in Table 1.",
        "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
        "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
        "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
        "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
        "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
        "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
        "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
        "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
        "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
        "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
        "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
        "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
        "THEOREM 4.",
        "The NI problem is NP-complete, even for twoagent systems.",
        "PROOF.",
        "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
        "For NP-hardness, we reduce SAT.",
        "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
        "Then we construct an instance of NI as follows.",
        "We create two agents, A = {1, 2}.",
        "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
        "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
        "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
        "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
        "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
        "No other arcs, apart from those so defined, as included in η.",
        "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
        "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
        "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
        "Then ϕ is satisfiable; for suppose not.",
        "Then the goals γi [2] are not achievable by any normative system, (by construction).",
        "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
        "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
        "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
        "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
        "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
        "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
        "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
        "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
        "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
        "The question then, for an agent is, how to be sure that others will comply with a norm.",
        "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
        "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
        "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
        "Of course, our approach is in many senses open for extension or enrichment.",
        "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
        "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
        "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
        "On the logic of normative systems.",
        "In Proc.",
        "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
        "Alternating-time temporal logic.",
        "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
        "Game Theory and the Social Contract Volume 1: Playing Fair.",
        "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
        "Game Theory and the Social Contract Volume 2: Just Playing.",
        "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
        "Complexity of mechanism design.",
        "In Proc.",
        "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
        "Complexity results about nash equilibria.",
        "In Proc.",
        "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
        "The complexity of computing a Nash equilibrium.",
        "In Proc.",
        "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
        "Temporal and modal logic.",
        "In Handbook of Theor.",
        "Comp.",
        "Sci.",
        "Vol.",
        "B, pages 996-1072.",
        "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
        "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
        "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
        "Choosing social laws for multi-agent systems: Minimality and simplicity.",
        "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
        "A Course in Game Theory.",
        "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
        "Computational Complexity.",
        "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
        "On the synthesis of useful social laws for artificial agent societies.",
        "In Proc.",
        "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
        "On social laws for artificial agent societies: Off-line design.",
        "In Computational Theories of Interaction and Agency, pages 597-618.",
        "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
        "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
        "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
        "On obligations and normative ability.",
        "Jnl. of Appl.",
        "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
    ],
    "translated_text_sentences": [
        "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB.",
        "En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo.",
        "En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente.",
        "Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo.",
        "Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía.",
        "Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no.",
        "Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa.",
        "Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1.",
        "Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1].",
        "Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable.",
        "La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15].",
        "Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo.",
        "Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16].",
        "Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social.",
        "En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente.",
        "En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente.",
        "Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía.",
        "Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no.",
        "Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4].",
        "Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa.",
        "Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8].",
        "Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase).",
        "Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema.",
        "Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes.",
        "Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica.",
        "Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación.",
        "Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones.",
        "Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A.",
        "Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado.",
        "Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado.",
        "En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke.",
        "Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente).",
        "Un camino π tal que π[0] = s es un camino s.",
        "Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s).",
        "A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1.",
        "Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes.",
        "Considera la estructura de Kripke representada en la Figura 1.",
        "Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí.",
        "También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad.",
        "Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i.",
        "Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso.",
        "Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo.",
        "Obviamente hay infinitamente muchos caminos s y caminos t diferentes.",
        "Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8].",
        "Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa.",
        "Utilizaremos CTL para expresar los objetivos de los agentes.",
        "La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ.",
        "Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella.",
        "La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje.",
        "La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que.",
        "K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que",
        "K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional.",
        "Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8].",
        "Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3.",
        "SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1].",
        "Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no.",
        "Los diferentes sistemas normativos pueden diferir en si una transición es legal o no.",
        "Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total.",
        "El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor.",
        "Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η.",
        "Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado.",
        "Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅.",
        "Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]).",
        "Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η.",
        "Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso.",
        "Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t).",
        "Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre.",
        "Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}.",
        "Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular.",
        "En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo.",
        "Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
        "Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
        "Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C).",
        "Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C).",
        "EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}.",
        "De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4.",
        "OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo.",
        "Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener.",
        "La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i.",
        "Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía.",
        "Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = .",
        "Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente.",
        "Denotamos el índice más grande de cualquier elemento en γ por |γ|.",
        "Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía.",
        "Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1].",
        "El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior.",
        "Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos.",
        "EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible.",
        "Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8).",
        "Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple.",
        "La meta ϕi 6 es una restricción de equidad implícita en ella.",
        "Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi.",
        "Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro.",
        "El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi.",
        "La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento.",
        "Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi.",
        "Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible.",
        "Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0.",
        "Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi.",
        "Sin embargo, esta no es una fórmula CTL adecuada.",
        "De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes.",
        "Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría.",
        "Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]).",
        "Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección.",
        "Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema.",
        "Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente.",
        "La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke.",
        "Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo.",
        "Recuerde que hemos definido S0 como {s, t}.",
        "Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es.",
        "Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero.",
        "Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0.",
        "Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema.",
        "El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j.",
        "Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto.",
        "Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil.",
        "Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales.",
        "Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R.",
        "Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal.",
        "Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
        "Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad.",
        "Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos.",
        "Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K).",
        "Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η).",
        "A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo.",
        "En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original.",
        "Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original.",
        "Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente.",
        "Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M.",
        "EJEMPLO 1.",
        "La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente.",
        "Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15].",
        "Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema.",
        "Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2.",
        "Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]).",
        "TEOREMA 1.",
        "Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1.",
        "Sea K una estructura y η un sistema normativo.",
        "Que γi denote una jerarquía de objetivos para el agente i. 1.",
        "Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal.",
        "Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2.",
        "Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε.",
        "Entonces, δi (K † η, K) ≥ 0.",
        "El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η.",
        "La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto).",
        "Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η.",
        "Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η.",
        "Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η.",
        "Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma.",
        "Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes.",
        "Esto nos motiva a considerar juegos de sistemas normativos. 5.",
        "JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos.",
        "Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación).",
        "Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no?",
        "Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño.",
        "Podemos entender el razonamiento aquí como un juego, de la siguiente manera.",
        "Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes.",
        "Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn.",
        "Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera.",
        "Los agentes AG en GΣ son como en Σ.",
        "Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo.",
        "Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ.",
        "Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ.",
        "Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ).",
        "Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0.",
        "De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η).",
        "Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos.",
        "Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2.",
        "Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera.",
        "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
        "El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente.",
        "Esto significa que las transiciones son R \\ {(s, s)}.",
        "En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1.",
        "Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0.",
        "El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace.",
        "Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera.",
        "Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten.",
        "Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera.",
        "Que Σ = M , η sea un sistema social.",
        "Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ.",
        "El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M.",
        "¿Existe un sistema normativo individualmente racional para M?",
        "TEOREMA 2.",
        "IRNS es NP-completo, incluso en sistemas de un solo agente.",
        "PRUEBA.",
        "Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente.",
        "Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista.",
        "Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ.",
        "Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico.",
        "Para la NP-dificultad, reducimos SAT [12, p.77].",
        "Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera.",
        "Primero, definimos un agente único A = {1}.",
        "Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS.",
        "Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ.",
        "Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi.",
        "A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio.",
        "Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1].",
        "Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos.",
        "Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero.",
        "El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ.",
        "Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi).",
        "El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual.",
        "Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7].",
        "De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes.",
        "En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto.",
        "Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η.",
        "Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto.",
        "El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M.",
        "¿Es η eficiente en Pareto para M?",
        "TEOREMA 3.",
        "PENS es co-NP-completo, incluso para sistemas de un solo agente.",
        "PRUEBA.",
        "Sean M y η como en el Teorema.",
        "Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo.",
        "En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η.",
        "Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico.",
        "Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista.",
        "Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2.",
        "Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío.",
        "Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M.",
        "Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl.",
        "¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete?",
        "Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}.",
        "Los servicios públicos para cada sistema se encuentran en la Tabla 1.",
        "De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7.",
        "Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14].",
        "Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas.",
        "Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente.",
        "Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2).",
        "En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ.",
        "La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan.",
        "Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios).",
        "IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M.",
        "¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash?",
        "Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
        "Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico.",
        "TEOREMA 4.",
        "El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes.",
        "PRUEBA.",
        "Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico.",
        "Para la NP-dificultad, reducimos SAT.",
        "Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk.",
        "Luego construimos una instancia de NI de la siguiente manera.",
        "Creamos dos agentes, A = {1, 2}.",
        "Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado.",
        "Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi.",
        "Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ.",
        "Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero.",
        "Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero.",
        "Ningún otro arco, aparte de los definidos de esa manera, está incluido en η.",
        "Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico.",
        "Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D).",
        "Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅.",
        "Entonces ϕ es satisfactible; supongamos lo contrario.",
        "Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción).",
        "Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η.",
        "Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash.",
        "Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9].",
        "La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]).",
        "De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo.",
        "No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE.",
        "Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6.",
        "CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento.",
        "Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento.",
        "La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma.",
        "Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma?",
        "La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos.",
        "Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos.",
        "Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento.",
        "Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7.",
        "REFERENCIAS [1] T. Agotnes, W. van der Hoek, J.",
        "A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge.",
        "Sobre la lógica de los sistemas normativos.",
        "En Proc.",
        "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman.",
        "Lógica temporal de tiempo alternante.",
        "Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore.",
        "Teoría de juegos y el contrato social Volumen 1: Jugando limpio.",
        "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
        "Teoría de juegos y el contrato social Volumen 2: Solo jugando.",
        "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm.",
        "Complejidad del diseño de mecanismos.",
        "En Proc.",
        "UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm.",
        "Resultados de complejidad sobre equilibrios de Nash.",
        "En Proc.",
        "IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou.",
        "La complejidad de calcular un equilibrio de Nash.",
        "En Proc.",
        "STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson.",
        "Lógica temporal y modal.",
        "En Manual de Teoría.",
        "This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish.",
        "Ciencia.",
        "Volumen.",
        "B, páginas 996-1072.",
        "Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern.",
        "A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal.",
        "Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz.",
        "Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad.",
        "Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein.",
        "Un curso de teoría de juegos.",
        "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
        "Complejidad computacional.",
        "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz.",
        "Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales.",
        "En Proc.",
        "AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz.",
        "Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea.",
        "En Teorías Computacionales de Interacción y Agencia, páginas 597-618.",
        "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge.",
        "Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis.",
        "Synthese, 2007. [16] M. Wooldridge y W. van der Hoek.",
        "Sobre obligaciones y capacidad normativa.",
        "Rev. de Apl.",
        "Lógica, 3:396-420, 2005. 888 El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07)"
    ],
    "error_count": 0,
    "keys": {
        "normative system game": {
            "translated_key": "juego del sistema normativo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the <br>normative system game</br> - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Then we can associate a game - the <br>normative system game</br> - GΣ with Σ, as follows."
            ],
            "translated_annotated_samples": [
                "Entonces podemos asociar un juego, el <br>juego del sistema normativo</br> - GΣ, con Σ, de la siguiente manera."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el <br>juego del sistema normativo</br> - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multiple goals of increasing priority": {
            "translated_key": "objetivos de prioridad creciente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have <br>multiple goals of increasing priority</br>, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have <br>multiple goals of increasing priority</br>, and investigate the computational complexity and game theoretic properties of this model."
            ],
            "translated_annotated_samples": [
                "En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples <br>objetivos de prioridad creciente</br>, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples <br>objetivos de prioridad creciente</br>, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "game theoretic properties": {
            "translated_key": "propiedades teóricas de juegos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and <br>game theoretic properties</br> of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and <br>game theoretic properties</br> of this model."
            ],
            "translated_annotated_samples": [
                "En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las <br>propiedades teóricas de juegos</br> de este modelo."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las <br>propiedades teóricas de juegos</br> de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "kripke structure": {
            "translated_key": "estructura de Kripke",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the <br>kripke structure</br>, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A <br>kripke structure</br> is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled <br>kripke structure</br> (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled <br>kripke structure</br> simply as a <br>kripke structure</br>.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the <br>kripke structure</br> depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a <br>kripke structure</br> and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some <br>kripke structure</br> K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a <br>kripke structure</br> K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a <br>kripke structure</br> is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a <br>kripke structure</br>, and η is a normative system over K, then K † η denotes the <br>kripke structure</br> obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the <br>kripke structure</br> K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a <br>kripke structure</br>, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the <br>kripke structure</br> that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the <br>kripke structure</br> that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a <br>kripke structure</br> K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular <br>kripke structure</br> K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a <br>kripke structure</br> (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a <br>kripke structure</br>, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a <br>kripke structure</br> for an agent.",
                "The idea is that the utility of a <br>kripke structure</br> is the highest index of any goal that is guaranteed for that agent in the <br>kripke structure</br>.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a <br>kripke structure</br> K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the <br>kripke structure</br> in which the normative system was implemented and the original <br>kripke structure</br>.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the <br>kripke structure</br> of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The <br>kripke structure</br> produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a <br>kripke structure</br> Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the <br>kripke structure</br> constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a <br>kripke structure</br> as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular <br>kripke structure</br> involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "A normative system is then simply a subset of the <br>kripke structure</br>, which contains the arcs that are forbidden by the normative system.",
                "A <br>kripke structure</br> is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "Collecting these components together, an agent-labelled <br>kripke structure</br> (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled <br>kripke structure</br> simply as a <br>kripke structure</br>.",
                "Consider the <br>kripke structure</br> depicted in Figure 1."
            ],
            "translated_annotated_samples": [
                "Un sistema normativo es simplemente un subconjunto de la <br>estructura de Kripke</br>, que contiene los arcos que están prohibidos por el sistema normativo.",
                "Una <br>estructura de Kripke</br> es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase).",
                "Reuniendo estos componentes, una <br>estructura de Kripke</br> etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado.",
                "En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como <br>estructura de Kripke</br> simplemente como una <br>estructura de Kripke</br>.",
                "Considera la <br>estructura de Kripke</br> representada en la Figura 1."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la <br>estructura de Kripke</br>, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una <br>estructura de Kripke</br> es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una <br>estructura de Kripke</br> etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como <br>estructura de Kripke</br> simplemente como una <br>estructura de Kripke</br>. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la <br>estructura de Kripke</br> representada en la Figura 1. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "computation tree logic": {
            "translated_key": "Lógica del Árbol de Cómputo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of <br>computation tree logic</br> (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of <br>computation tree logic</br> (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define <br>computation tree logic</br> (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "We specify an agents goals as a hierarchy of formulae of <br>computation tree logic</br> (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "We specify an agents goals as a hierarchy of formulae of <br>computation tree logic</br> (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define <br>computation tree logic</br> (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8]."
            ],
            "translated_annotated_samples": [
                "Especificamos los objetivos de un agente como una jerarquía de fórmulas de <br>Lógica del Árbol de Cómputo</br> (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía.",
                "Especificamos los objetivos de un agente como una jerarquía de fórmulas de <br>Lógica del Árbol de Computación</br> (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía.",
                "Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la <br>Lógica de Árbol de Computación</br> (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de <br>Lógica del Árbol de Cómputo</br> (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de <br>Lógica del Árbol de Computación</br> (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la <br>Lógica de Árbol de Computación</br> (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    "Lógica del Árbol de Cómputo",
                    "Lógica del Árbol de Computación",
                    "Lógica de Árbol de Computación"
                ]
            ]
        },
        "ordinal utility": {
            "translated_key": "utilidad ordinal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of <br>ordinal utility</br>, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of <br>ordinal utility</br>, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an <br>ordinal utility</br> measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Using this scheme, we define a model of <br>ordinal utility</br>, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "Using this scheme, we define a model of <br>ordinal utility</br>, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "Note that this is an <br>ordinal utility</br> measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale."
            ],
            "translated_annotated_samples": [
                "Usando este esquema, definimos un modelo de <br>utilidad ordinal</br>, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no.",
                "Usando este esquema, definimos un modelo de <br>utilidad ordinal</br>, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no.",
                "Ten en cuenta que esta es una medida de <br>utilidad ordinal</br>: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de <br>utilidad ordinal</br>, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de <br>utilidad ordinal</br>, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de <br>utilidad ordinal</br>: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "computational complexity": {
            "translated_key": "complejidad computacional",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the <br>computational complexity</br> and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the <br>computational complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the <br>computational complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "<br>computational complexity</br>.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the <br>computational complexity</br> and game theoretic properties of this model.",
                "We then characterise the <br>computational complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "We then characterise the <br>computational complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "<br>computational complexity</br>."
            ],
            "translated_annotated_samples": [
                "En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la <br>complejidad computacional</br> y las propiedades teóricas de juegos de este modelo.",
                "Luego caracterizamos la <br>complejidad computacional</br> de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa.",
                "Luego caracterizamos la <br>complejidad computacional</br> de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa.",
                "Complejidad computacional."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la <br>complejidad computacional</br> y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la <br>complejidad computacional</br> de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la <br>complejidad computacional</br> de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "nash implementation": {
            "translated_key": "implementación de Nash",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a <br>nash implementation</br> is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a <br>nash implementation</br> is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 <br>nash implementation</br> Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a <br>nash implementation</br> if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a <br>nash implementation</br>, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a <br>nash implementation</br>, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term <br>nash implementation</br> is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "<br>nash implementation</br> (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a <br>nash implementation</br>?",
                "Verifying that a particular social system forms a <br>nash implementation</br> can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a <br>nash implementation</br>; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a <br>nash implementation</br> can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a <br>nash implementation</br> normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a <br>nash implementation</br> normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a <br>nash implementation</br>, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a <br>nash implementation</br> normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a <br>nash implementation</br>, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a <br>nash implementation</br> is NP-complete.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a <br>nash implementation</br> is NP-complete. 2.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 <br>nash implementation</br> Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a <br>nash implementation</br> if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a <br>nash implementation</br>, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply."
            ],
            "translated_annotated_samples": [
                "Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una <br>implementación de Nash</br> es NP-completa.",
                "Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una <br>implementación de Nash</br> es NP-completa.",
                "Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14].",
                "En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una <br>implementación de Nash</br> si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ.",
                "La intuición es que si Σ es una <br>implementación de Nash</br>, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una <br>implementación de Nash</br> es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una <br>implementación de Nash</br> es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una <br>implementación de Nash</br> si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una <br>implementación de Nash</br>, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "social law": {
            "translated_key": "ley social",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a <br>social law</br> as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a <br>social law</br>.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a <br>social law</br> as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a <br>social law</br>."
            ],
            "translated_annotated_samples": [
                "La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una <br>ley social</br> como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15].",
                "Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una <br>ley social</br>."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una <br>ley social</br> como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una <br>ley social</br>. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multi-agent system": {
            "translated_key": "sistema multiagente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A <br>multi-agent system</br> collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a <br>multi-agent system</br>, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a <br>multi-agent system</br> M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a <br>multi-agent system</br>, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a <br>multi-agent system</br> M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: <br>multi-agent system</br> M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: <br>multi-agent system</br> M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: <br>multi-agent system</br> M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the <br>multi-agent system</br> so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given <br>multi-agent system</br> M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "A <br>multi-agent system</br> collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a <br>multi-agent system</br>, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "Suppose we are given a <br>multi-agent system</br> M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "A social system now is a pair Σ = M , η where M is a <br>multi-agent system</br>, and η is a normative system over M .",
                "Suppose we have a <br>multi-agent system</br> M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective)."
            ],
            "translated_annotated_samples": [
                "Un <br>sistema multiagente</br> reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema.",
                "Formalmente, un <br>sistema multiagente</br>, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente.",
                "Supongamos que se nos da un <br>sistema multiagente</br> M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K).",
                "Un sistema social ahora es un par Σ = M, η donde M es un <br>sistema multiagente</br>, y η es un sistema normativo sobre M.",
                "Supongamos que tenemos un <br>sistema multiagente</br> M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación)."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un <br>sistema multiagente</br> reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un <br>sistema multiagente</br>, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un <br>sistema multiagente</br> M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un <br>sistema multiagente</br>, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un <br>sistema multiagente</br> M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "desirable objective": {
            "translated_key": "objetivo deseable",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some <br>desirable objective</br> will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some <br>desirable objective</br> will emerge."
            ],
            "translated_annotated_samples": [
                "Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún <br>objetivo deseable</br>."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún <br>objetivo deseable</br>. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "constraint": {
            "translated_key": "restricción",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness <br>constraint</br>: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness <br>constraint</br>, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness <br>constraint</br> implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness <br>constraint</br> ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "The requirement that R\\η is total is a reasonableness <br>constraint</br>: it prevents normative systems which lead to states with no successor.",
                "Thanks to our reasonableness <br>constraint</br>, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Goal ϕi 6 is a fairness <br>constraint</br> implied by it.",
                "We remark that it may seem more natural to express a fairness <br>constraint</br> ϕi 6 as A ♦pi ."
            ],
            "translated_annotated_samples": [
                "El requisito de que R\\η sea total es una <br>restricción</br> de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor.",
                "Gracias a nuestra <br>restricción de razonabilidad</br>, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl.",
                "La meta ϕi 6 es una <br>restricción</br> de equidad implícita en ella.",
                "Observamos que puede parecer más natural expresar una <br>restricción de equidad</br> ϕi 6 como A ♦pi."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una <br>restricción</br> de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra <br>restricción de razonabilidad</br>, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una <br>restricción</br> de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una <br>restricción de equidad</br> ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    "restricción",
                    "restricción de razonabilidad",
                    "restricción",
                    "restricción de equidad"
                ]
            ]
        },
        "decision making": {
            "translated_key": "toma de decisiones",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of <br>decision making</br> that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "However, this model was still too impoverished to capture the kinds of <br>decision making</br> that take place when an agent decides whether or not to comply with a social law."
            ],
            "translated_annotated_samples": [
                "Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de <br>toma de decisiones</br> que tienen lugar cuando un agente decide si cumplir o no con una ley social."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de <br>toma de decisiones</br> que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la teoría de juegos para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un juego, de la siguiente manera. Un juego en forma normal estratégica (cf. [11, p.11]) es una estructura: G = AG, S1, . . . , Sn , U1, . . . , Un donde: • AG = {1, . . . , n} es un conjunto de agentes, los jugadores del juego; • Si es el conjunto de estrategias para cada agente i ∈ AG (una estrategia para un agente i no es más que una elección entre acciones alternativas); y • Ui : (S1 × · · · × Sn ) → R es la función de utilidad para el agente i ∈ AG, que asigna una utilidad a cada combinación de elecciones de estrategias para los agentes. Ahora, supongamos que se nos da un sistema social Σ = M, η donde M = K, γ1, . . . , γn. Entonces podemos asociar un juego, el juego del sistema normativo - GΣ, con Σ, de la siguiente manera. Los agentes AG en GΣ son como en Σ. Cada agente i tiene solo dos estrategias disponibles: • C - cumplir (cooperar) con el sistema normativo; y • D - no cumplir (defectar) del sistema normativo. Si S es una tupla de estrategias, una para cada agente, y x ∈ {C, D}, entonces denotamos por AGx S al subconjunto de agentes que juegan la estrategia x en S. Por lo tanto, para un sistema social Σ = M , η , el sistema normativo η AGC S solo implementa las restricciones para aquellos agentes que eligen cooperar en GΣ. Ten en cuenta que esto es lo mismo que η AGD S: el sistema normativo que excluye todas las restricciones de agentes que juegan D en GΣ. Luego definimos las funciones de utilidad Ui para cada i ∈ AG como: Ui (S) = δi (K, η AGC S ). Por ejemplo, si SD es una colección de estrategias en la que cada agente traiciona (es decir, no cumple con la norma), entonces Ui (SD) = δi (K, (η AGD SD)) = ui (K † η∅) - ui (K) = 0. De la misma manera, si SC es una colección de estrategias en la que cada agente coopera (es decir, cumple con la norma), entonces Ui(SC) = δi(K, (η AGD SC)) = ui(K † (η ∅)) = ui(K † η). Ahora podemos comenzar a investigar algunas propiedades de los juegos de sistemas normativos. Para nuestro sistema de ejemplo, hemos mostrado los diferentes valores de U para nuestro sistema de múltiples agentes con la norma η3, es decir, {(s, s), (t, t)} como la segunda tabla de la Figura 2. Por ejemplo, el par (0, 3) en la matriz bajo la entrada S = C, D se obtiene de la siguiente manera. U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). \n\nU1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K). El primer término de esto es la utilidad de 1 en el sistema K donde implementamos η3 para el agente cooperante, es decir, 1, solamente. Esto significa que las transiciones son R \\ {(s, s)}. En este sistema, todavía ϕ1 4 = A E♦p1 es el objetivo más alto para el agente 1. Esta es la misma utilidad para 1 que en K, y por lo tanto, δ1(K, η3 AGC C,D ) = 0. El agente 2, por supuesto, se beneficia si el agente 1 cumple con η3 mientras que el 2 no lo hace. Su utilidad sería 3, ya que η3 AGC C,D es de hecho η1. 5.1 Sistemas Normativos Individualmente Racionales Un sistema normativo es individualmente racional si a cada agente le iría mejor si el sistema normativo fuera impuesto que de otra manera. Esta es una condición necesaria, aunque no suficiente, en una norma para esperar que todos la respeten. Cabe destacar que η3 de nuestro ejemplo es racional individualmente tanto para 1 como para 2, aunque esta no es una situación estable: dado que los demás juegan C, i está mejor jugando D. Podemos caracterizar fácilmente la racionalidad individual con respecto al juego correspondiente en forma estratégica, de la siguiente manera. Que Σ = M , η sea un sistema social. Entonces, lo siguiente es equivalente: El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figura 3: La estructura de Kripke producida en la reducción del Teorema 2; todas las transiciones están asociadas con el agente 1, el único estado inicial es s0. 1. η es individualmente racional en M; 2. ∀i ∈ AG, Ui (SC) > Ui (SD) en el juego GΣ. El problema de decisión asociado con sistemas normativos individualmente racionales es el siguiente: SISTEMA NORMATIVO INDIVIDUALMENTE RACIONAL (SNIR): Dado: Sistema multiagente M. ¿Existe un sistema normativo individualmente racional para M? TEOREMA 2. IRNS es NP-completo, incluso en sistemas de un solo agente. PRUEBA. Para la membresía de NP, adivina un sistema normativo η y verifica que sea racional individualmente. Dado que η ⊆ R, podremos adivinarlo en tiempo polinómico no determinista. Para verificar que es racional individualmente, comprobamos que para todo i, tenemos ui (K † η) > ui (K); calcular K † η es simplemente una resta de conjuntos, por lo que se puede hacer en tiempo polinómico, mientras que determinar el valor de ui (K) para cualquier K se puede hacer con un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico en el K y γ. Por lo tanto, verificar que ui (K † η) > ui (K) solo requiere tiempo polinómico. Para la NP-dificultad, reducimos SAT [12, p.77]. Dada una instancia SAT ϕ sobre variables booleanas x1, . . . , xk, producimos una instancia de IRNS de la siguiente manera. Primero, definimos un agente único A = {1}. Para cada variable booleana xi en la instancia SAT, creamos dos variables booleanas t(xi) y f(xi) en la instancia IRNS. Luego creamos una estructura de Kripke Kϕ con 2k + 1 estados, como se muestra en la Figura 3: los arcos en este grafo corresponden a transiciones en Kϕ. Sea ϕ∗ el resultado de sustituir sistemáticamente, en ϕ, la expresión CTL (E ft(xi)) por cada variable booleana xi. A continuación, considera las siguientes fórmulas: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) Luego definimos la jerarquía de objetivos para todos los agentes 1 de la siguiente manera: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ Sostenemos que existe un sistema normativo individualmente racional para la instancia construida si y solo si ϕ es satisfactorio. Primero, observe que cualquier sistema normativo individualmente racional debe obligar a que γ1[1] sea verdadero, ya que en el sistema original, no tenemos γ1[1]. Para la dirección ⇒, si existe un sistema normativo individualmente racional η, entonces construimos una asignación satisfactoria para ϕ considerando los arcos que están prohibidos por η: la fórmula (1) asegura que debemos prohibir un arco hacia un estado t(xi) o f(xi) para todas las variables xi, pero (2) asegura que no podemos prohibir arcos hacia ambos. Entonces, si prohibimos un arco a un estado t(xi) entonces en la valuación correspondiente para ϕ hacemos que xi sea falso, mientras que si prohibimos un arco a un estado f(xi) entonces hacemos que xi sea verdadero. El hecho de que ϕ∗ sea parte del objetivo asegura que el sistema normativo es, de hecho, una valoración para ϕ. Para ⇐, tenga en cuenta que para cualquier valuación satisfactoria para ϕ podemos construir un sistema normativo individualmente racional η, de la siguiente manera: si la valuación hace que xi sea verdadero, prohibimos el arco hacia el estado f(xi), mientras que si la valuación hace que xi sea falso, prohibimos el arco hacia el estado t(xi). El sistema normativo resultante garantiza γ1[1], y por lo tanto es racional a nivel individual. Observa que la estructura de Kripke construida en la reducción contiene solo un agente, por lo que el Teorema está demostrado. 5.2 Sistemas Normativos Eficientes de Pareto La eficiencia de Pareto es una medida básica de qué tan buena es un resultado particular para un grupo de agentes [11, p.7]. De manera intuitiva, un resultado es eficiente en Pareto si no hay otro resultado que mejore la situación de todos los agentes. En nuestro marco de trabajo, supongamos que se nos da un sistema social Σ = M , η, y se nos pregunta si η es eficiente de Pareto. Esto equivale a preguntar si existe algún otro sistema normativo η tal que cada agente estaría mejor bajo η que con η. Si η hace que cada agente esté mejor que η, entonces decimos que η domina a η según Pareto. El problema de decisión es el siguiente: SISTEMA NORMATIVO EFICIENTE DE PARETO (PENS): Dado: Sistema multiagente M y sistema normativo η sobre M. ¿Es η eficiente en Pareto para M? TEOREMA 3. PENS es co-NP-completo, incluso para sistemas de un solo agente. PRUEBA. Sean M y η como en el Teorema. Mostramos que el problema complementario de PENS, al que nos referimos como DOMINADO POR PARETO, es NP-completo. En este problema, se nos dan M y η, y se nos pregunta si η está dominado por Pareto, es decir, si existe algún η sobre M tal que η mejore la situación de todos los agentes en comparación con η. Para la membresía de NP, simplemente adivina un sistema normativo η y verifica que para todo i ∈ A, tenemos ui (K † η) > ui (K † η) - verificar requiere un número polinómico de problemas de verificación de modelos, cada uno de los cuales toma tiempo polinómico. Dado que η ⊆ R, el sistema normativo puede ser adivinado en tiempo polinómico no determinista. Para la NP-dificultad, reducimos IRNS, el cual sabemos que es NP-completo según el Teorema 2. Dada una instancia M de IRNS, permitimos que M en la instancia de DOMINIO DE PARETO sea como en la instancia de IRNS, y definimos el sistema normativo para DOMINIO DE PARETO como η∅, el sistema normativo vacío. Ahora, es evidente que existe un sistema normativo η que domina a η∅ de Pareto en M si y solo si existe un sistema normativo individualmente racional en M. Dado que el problema del complemento es NP-completo, se deduce que PENS es co-NP-completo. 886 The Sixth Intl. ¿Qué tal las normas eficientes de Pareto para nuestro ejemplo de juguete? Resolver esta pregunta implica encontrar los sistemas normativos dominantes entre η0 = η∅, η1, η2, η3 definidos anteriormente, y η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} y η8 = {(s, t), (t, s)}. Los servicios públicos para cada sistema se encuentran en la Tabla 1. De esto se infiere que las normas eficientes de Pareto son η1, η2, η3, η6 y η7. Ten en cuenta que η8 prohíbe que el recurso se pase de un agente a otro, lo cual no es bueno para ningún agente (dado que hemos elegido S0 = {s, t}, ningún agente puede estar seguro de recibir el recurso, es decir, el objetivo ϕi 1 no es verdadero en K † η8). 5.3 Sistemas Normativos de Implementación Nash El concepto de solución más famoso en la teoría de juegos es, por supuesto, el equilibrio de Nash [11, p.14]. Una colección de estrategias, una para cada agente, se dice que forma un equilibrio de Nash si ningún agente puede beneficiarse haciendo algo distinto a jugar su estrategia, bajo la suposición de que los otros agentes juegan las suyas. Los equilibrios de Nash son importantes porque proporcionan soluciones estables al problema de qué estrategia debe jugar un agente. Cabe destacar que en nuestro ejemplo de juguete, aunque η3 es racional individualmente para cada agente, no es un equilibrio de Nash, ya que dada esta norma, sería beneficioso para el agente 1 desviarse (y lo mismo para el 2). En nuestro marco, decimos que un sistema social Σ = M , η (donde η = η∅) es una implementación de Nash si SC (es decir, todos cumpliendo con el sistema normativo) forma un equilibrio de Nash en el juego GΣ. La intuición es que si Σ es una implementación de Nash, entonces cumplir con el sistema normativo es una solución razonable para todos los involucrados: no puede haber beneficio en desviarse de él, de hecho, hay un incentivo positivo para que todos cumplan. Si Σ no es una implementación de Nash, entonces es poco probable que el sistema normativo tenga éxito, ya que el cumplimiento no es racional para algunos agentes. (Nuestra elección de terminología está deliberadamente seleccionada para reflejar la forma en que se utiliza el término implementación de Nash en la teoría de implementación, o diseño de mecanismos [11, p.185], donde un diseñador de juegos busca lograr ciertos resultados diseñando las reglas del juego de manera que estos resultados sean equilibrios). IMPLEMENTACIÓN DE NASH (NI): Dado: Sistema multiagente M. ¿Existe un sistema normativo no vacío η sobre M tal que M, η forme una implementación de Nash? Verificar que un sistema social particular forme una implementación de Nash se puede hacer en tiempo polinómico: consiste en comprobar: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})). Esto claramente requiere solo un número polinómico de llamadas de verificación de modelos, cada una de las cuales requiere solo tiempo polinómico. TEOREMA 4. El problema de la interacción no cooperativa es NP-completo, incluso para sistemas de dos agentes. PRUEBA. Para la membresía de NP, simplemente adivine un sistema normativo η y verifique que forme una implementación de Nash; dado que η ⊆ R, adivinar se puede hacer en tiempo polinómico no determinista, y como s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figura 4: Reducción para el Teorema 4. como argumentamos anteriormente, verificar que forme una implementación de Nash se puede hacer en tiempo polinómico. Para la NP-dificultad, reducimos SAT. Supongamos que se nos da una instancia SAT ϕ sobre variables booleanas x1, . . . , xk. Luego construimos una instancia de NI de la siguiente manera. Creamos dos agentes, A = {1, 2}. Para cada variable booleana xi creamos dos variables booleanas, t(xi) y f(xi), y luego definimos una estructura de Kripke como se muestra en la Figura 4, con s0 siendo el único estado inicial; la etiquetación de los arcos en la Figura 4 da la función α, y cada estado está etiquetado con las proposiciones que son verdaderas en ese estado. Para cada variable booleana xi, definimos las fórmulas xi y x⊥ i de la siguiente manera: xi = E f(t(xi) ∧ E f((E f(t(xi))) ∧ A f(¬f(xi))) x⊥ i = E f(f(xi) ∧ E f((E f(f(xi))) ∧ A f(¬t(xi))) Sea ϕ∗ la fórmula obtenida de ϕ al sustituir sistemáticamente xi por xi. Cada agente tiene tres objetivos: γi [0] = para ambos i ∈ {1, 2}, mientras que γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) y finalmente, para ambos agentes, γi [2] siendo la conjunción de las siguientes fórmulas: The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) Denominamos al sistema multiagente construido de esta manera como Mϕ. Ahora, demostramos que la instancia SAT ϕ es satisfacible si y solo si Mϕ tiene un sistema normativo de implementación Nash: Para la dirección ⇒, supongamos que ϕ es satisfacible y sea X una valuación satisfactoria, es decir, un conjunto de variables booleanas que hacen que ϕ sea verdadero. Podemos extraer de X un sistema normativo de implementación de Nash η de la siguiente manera: si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que f(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que f(xi) es verdadero; si xi ∈ X, entonces η incluye el arco desde s0 hasta el estado en el que t(xi) es verdadero, e incluye también el arco desde s(2k + 1) hasta el estado en el que t(xi) es verdadero. Ningún otro arco, aparte de los definidos de esa manera, está incluido en η. Observa que η es racional individualmente para ambos agentes: si ambos cumplen con el sistema normativo, entonces lograrán sus objetivos γi [2], lo cual no sucede en el sistema básico. Para ver que η forma una implementación de Nash, observe que si alguno de los agentes se desvía de η, entonces ninguno de los dos logrará sus objetivos γi [2]: el agente 1 prefiere estrictamente (C, C) sobre (D, C), y el agente 2 prefiere estrictamente (C, C) sobre (C, D). Para la dirección ⇐, supongamos que existe un sistema normativo de implementación de Nash η, en cuyo caso η = ∅. Entonces ϕ es satisfactible; supongamos lo contrario. Entonces, los objetivos γi [2] no son alcanzables por ningún sistema normativo, (por construcción). Ahora, dado que η debe prohibir al menos una transición, entonces al menos un agente no lograría que se cumpla su objetivo γi [1] si cumpliera, por lo tanto, al menos uno estaría mejor si se desviara, es decir, no cumpliera con η. Pero esto contradice la suposición de que η es una implementación de Nash, es decir, que (C, C) forma un equilibrio de Nash. Este resultado es quizás de cierto interés técnico más allá de las preocupaciones específicas del presente artículo, ya que está relacionado con dos problemas de interés más amplio: la complejidad del diseño de mecanismos [5] y la complejidad de calcular equilibrios de Nash [6, 7]. 5.4 Lenguajes de Objetivos más Ricos Es interesante considerar qué sucede con la complejidad de los problemas que consideramos anteriormente si permitimos lenguajes más ricos para los objetivos: en particular, CTL ∗ [9]. La diferencia principal es que determinar ui (K) en un sistema multiagente M dado cuando se utiliza un lenguaje objetivo implica resolver un problema completo en PSPACE (ya que la verificación de modelos para CTL ∗ es completa en PSPACE [8]). De hecho, parece que para cada uno de los tres problemas que consideramos anteriormente, el problema correspondiente bajo la suposición de una representación CTL ∗ para objetivos también es PSPACE-completo. No puede ser más fácil, ya que determinar la utilidad de una estructura de Kripke particular implica resolver un problema completo de PSPACE. Para ver la pertenencia a PSPACE podemos aprovechar el hecho de que PSPACE = NPSPACE [12, p.150], y así podemos adivinar el sistema normativo deseado, aplicando un procedimiento de verificación de PSPACE para comprobar que tiene las propiedades deseadas. 6. CONCLUSIONES Se supone que las normas sociales restringen nuestro comportamiento. Por supuesto, tal restricción no tiene por qué ser negativa: el hecho de que el comportamiento de un agente esté restringido puede parecer una limitación, pero puede haber beneficios si puede asumir que otros también limitarán su comportamiento. La pregunta entonces, para un agente, es cómo asegurarse de que otros cumplirán con una norma. Y, para un diseñador de sistemas, ¿cómo asegurarse de que el sistema se comportará de manera social, es decir, de acuerdo con su norma? La teoría de juegos es una herramienta muy natural para analizar y responder a estas preguntas, que implican consideraciones estratégicas, y hemos propuesto una forma de traducir preguntas clave relacionadas con sistemas normativos basados en la lógica a preguntas de teoría de juegos. Hemos propuesto un marco lógico para razonar sobre tales escenarios, y hemos proporcionado algunos costos computacionales para resolver algunas de las preguntas principales sobre ellos. Por supuesto, nuestro enfoque está abierto en muchos sentidos para su extensión o enriquecimiento. Un problema evidente a considerar es la complejidad de las preguntas que planteamos para representaciones más prácticas de los modelos (cf. [1]), y considerar otras clases de objetivos permitidos. 7. REFERENCIAS [1] T. Agotnes, W. van der Hoek, J. A. Rodriguez-Aguilar, C. Sierra y M. Wooldridge. Sobre la lógica de los sistemas normativos. En Proc. IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, y O. Kupferman. Lógica temporal de tiempo alternante. Revista de la ACM, 49(5):672-713, 2002. [3] K. Binmore. Teoría de juegos y el contrato social Volumen 1: Jugando limpio. The MIT Press: Cambridge, MA, 1994. [4] K. Binmore. \n\nLa editorial MIT Press: Cambridge, MA, 1994. [4] K. Binmore. Teoría de juegos y el contrato social Volumen 2: Solo jugando. The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer y T. Sandholm. Complejidad del diseño de mecanismos. En Proc. UAI, Edmonton, Canadá, 2002. [6] V. Conitzer y T. Sandholm. Resultados de complejidad sobre equilibrios de Nash. En Proc. IJCAI-03, pp. 765-771, Acapulco, México, 2003. [7] C. Daskalakis, P. W. Goldberg y C. H. Papadimitriou. La complejidad de calcular un equilibrio de Nash. En Proc. STOC, Seattle, WA, 2006. [8] E. A. Emerson.\nSTOC, Seattle, WA, 2006. [8] E. A. Emerson. Lógica temporal y modal. En Manual de Teoría. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Ciencia. Volumen. B, páginas 996-1072. Elsevier, 1990. [9] E. A. Emerson y J. Y. Halpern. A veces y no nunca revisado: sobre la lógica temporal de tiempo ramificado versus tiempo lineal. Revista de la ACM, 33(1):151-178, 1986. [10] D. Fitoussi y M. Tennenholtz. Seleccionando leyes sociales para sistemas multiagente: Minimalidad y simplicidad. Inteligencia Artificial, 119(1-2):61-101, 2000. [11] M. J. Osborne y A. Rubinstein. Un curso de teoría de juegos. The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.\nLa editorial MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou. Complejidad computacional. Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham y M. Tennenholtz. Sobre la síntesis de leyes sociales útiles para las sociedades de agentes artificiales. En Proc. AAAI, San Diego, CA, 1992. [14] Y. Shoham y M. Tennenholtz. Sobre leyes sociales para sociedades de agentes artificiales: Diseño fuera de línea. En Teorías Computacionales de Interacción y Agencia, páginas 597-618. The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge. \n\nLa editorial MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts y M. Wooldridge. Leyes sociales en tiempo alternante: Efectividad, viabilidad y síntesis. Synthese, 2007. [16] M. Wooldridge y W. van der Hoek. Sobre obligaciones y capacidad normativa. Rev. de Apl. Lógica, 3:396-420, 2005. 888 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "normative system": {
            "translated_key": "sistema normativo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>normative system</br> Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A <br>normative system</br> is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the <br>normative system</br>.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the <br>normative system</br> or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based <br>normative system</br> games; for example, we show that the complexity of checking whether there exists a <br>normative system</br> which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a <br>normative system</br> is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the <br>normative system</br> would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the <br>normative system</br> or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the <br>normative system</br> would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the <br>normative system</br> or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based <br>normative system</br> games; for example, we show that the complexity of checking whether there exists a <br>normative system</br> which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a <br>normative system</br> is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a <br>normative system</br> defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a <br>normative system</br> η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a <br>normative system</br> η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty <br>normative system</br> by η∅, so η∅ = ∅.",
                "Note that the empty <br>normative system</br> η∅ is reasonable with respect to any transition relation R. The effect of implementing a <br>normative system</br> on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a <br>normative system</br> over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A <br>normative system</br> with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular <br>normative system</br>.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the <br>normative system</br>.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a <br>normative system</br> over K. Then: • η C denotes the <br>normative system</br> that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the <br>normative system</br>. • η C denotes the <br>normative system</br> that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the <br>normative system</br> (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a <br>normative system</br>.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a <br>normative system</br> η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated <br>normative system</br> η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a <br>normative system</br> to an agent is the difference between the utility of the Kripke structure in which the <br>normative system</br> was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the <br>normative system</br> were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a <br>normative system</br> over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a <br>normative system</br>.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any <br>normative system</br> η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider <br>normative system</br> games. 5.",
                "<br>normative system</br> GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a <br>normative system</br> η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the <br>normative system</br>, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the <br>normative system</br> game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the <br>normative system</br>; and • D - do not comply with (defect from) the <br>normative system</br>.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the <br>normative system</br> η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the <br>normative system</br> that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of <br>normative system</br> games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A <br>normative system</br> is individually rational if every agent would fare better if the <br>normative system</br> were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL <br>normative system</br> (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational <br>normative system</br> for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a <br>normative system</br> η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational <br>normative system</br> for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational <br>normative system</br> must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational <br>normative system</br> η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the <br>normative system</br> is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational <br>normative system</br> η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting <br>normative system</br> ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other <br>normative system</br> η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT <br>normative system</br> (PENS): Given: Multi-agent system M and <br>normative system</br> η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a <br>normative system</br> η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the <br>normative system</br> can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the <br>normative system</br> for PARETO DOMINATED to be η∅, the empty <br>normative system</br>.",
                "Now, it is straightforward that there exists a <br>normative system</br> η which Pareto dominates η∅ in M iff there exist an individually rational <br>normative system</br> in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the <br>normative system</br>) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the <br>normative system</br> is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the <br>normative system</br> is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty <br>normative system</br> η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a <br>normative system</br> η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation <br>normative system</br>: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation <br>normative system</br> η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the <br>normative system</br>, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation <br>normative system</br> η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any <br>normative system</br>, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired <br>normative system</br>, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "<br>normative system</br> Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "A <br>normative system</br> is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the <br>normative system</br>.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the <br>normative system</br> or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based <br>normative system</br> games; for example, we show that the complexity of checking whether there exists a <br>normative system</br> which has the property of being a Nash implementation is NP-complete.",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a <br>normative system</br> is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge."
            ],
            "translated_annotated_samples": [
                "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB.",
                "Un <br>sistema normativo</br> es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el <br>sistema normativo</br>.",
                "Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el <br>sistema normativo</br> o no.",
                "Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un <br>sistema normativo</br> que tiene la propiedad de ser una implementación de Nash es NP-completa.",
                "Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un <br>sistema normativo</br> es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un <br>sistema normativo</br> es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el <br>sistema normativo</br>. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el <br>sistema normativo</br> o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un <br>sistema normativo</br> que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un <br>sistema normativo</br> es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "goal": {
            "translated_key": "objetivo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single <br>goal</br> in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a <br>goal</br> hierarchy γi for agent i ∈ A is that the further up the hierarchy a <br>goal</br> is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a <br>goal</br> at a particular level in its <br>goal</br> hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a <br>goal</br> hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a <br>goal</br> hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a <br>goal</br> at index x in <br>goal</br> hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a <br>goal</br> hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic <br>goal</br> hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the <br>goal</br> of the previous level.",
                "Although this is a natural property of many <br>goal</br> hierarchies, it is not a property we demand of all <br>goal</br> hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents <br>goal</br> hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired <br>goal</br> of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this <br>goal</br> implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "<br>goal</br> ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The <br>goal</br> ϕi 5 is like the strong <br>goal</br> ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "<br>goal</br> ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial <br>goal</br> ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative <br>goal</br> representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a <br>goal</br> hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a <br>goal</br> hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any <br>goal</br> that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a <br>goal</br> ϕ at index n if there is a logically weaker <br>goal</br> ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: <br>goal</br> ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any <br>goal</br> hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the <br>goal</br> hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a <br>goal</br> hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal <br>goal</br> in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current <br>goal</br> will at least remain true (in fact a <br>goal</br> higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest <br>goal</br> for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the <br>goal</br> hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the <br>goal</br> ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., <br>goal</br> ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] <br>goal</br> achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer <br>goal</br> Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a <br>goal</br> language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "This model of normative systems was further extended by attributing to each agent a single <br>goal</br> in [16].",
                "The intended interpretation of such a <br>goal</br> hierarchy γi for agent i ∈ A is that the further up the hierarchy a <br>goal</br> is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a <br>goal</br> at a particular level in its <br>goal</br> hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a <br>goal</br> hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a <br>goal</br> hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on."
            ],
            "translated_annotated_samples": [
                "Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único <br>objetivo</br> en [16].",
                "La interpretación prevista de una jerarquía de <br>objetivo</br>s γi para el agente i ∈ A es que cuanto más arriba esté un <br>objetivo</br> en la jerarquía, más deseado es por i.",
                "Ten en cuenta que asumimos que si un agente puede lograr un <br>objetivo</br> en un nivel particular de su jerarquía de <br>objetivo</br>s, entonces no le preocupa los objetivos más bajos en la jerarquía.",
                "Formalmente, una jerarquía de <br>objetivos</br>, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = .",
                "Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de <br>objetivos</br>, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único <br>objetivo</br> en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de <br>objetivo</br>s γi para el agente i ∈ A es que cuanto más arriba esté un <br>objetivo</br> en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un <br>objetivo</br> en un nivel particular de su jerarquía de <br>objetivo</br>s, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de <br>objetivos</br>, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de <br>objetivos</br>, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. ",
            "candidates": [],
            "error": [
                [
                    "objetivo",
                    "objetivo",
                    "objetivo",
                    "objetivo",
                    "objetivo",
                    "objetivos",
                    "objetivos"
                ]
            ]
        },
        "logic": {
            "translated_key": "lógica",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree <br>logic</br> (CTL), a widely used <br>logic</br> for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree <br>logic</br> (CTL), a widely used <br>logic</br> for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal <br>logic</br> literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree <br>logic</br> (CTL), a branching time temporal <br>logic</br> intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical <br>logic</br> connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this <br>logic</br>, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning <br>logic</br>-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the <br>logic</br> of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal <br>logic</br>.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal <br>logic</br>.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal <br>logic</br>.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "<br>logic</br>, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "We specify an agents goals as a hierarchy of formulae of Computation Tree <br>logic</br> (CTL), a widely used <br>logic</br> for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree <br>logic</br> (CTL), a widely used <br>logic</br> for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal <br>logic</br> literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree <br>logic</br> (CTL), a branching time temporal <br>logic</br> intended for representing the properties of Kripke structures [8].",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical <br>logic</br> connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner."
            ],
            "translated_annotated_samples": [
                "Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una <br>lógica</br> ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía.",
                "Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una <br>lógica</br> ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía.",
                "Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de <br>lógica temporal</br> de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí.",
                "Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una <br>lógica</br> temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8].",
                "K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una <br>lógica</br> ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una <br>lógica</br> ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de <br>lógica temporal</br> de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una <br>lógica</br> temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. ",
            "candidates": [],
            "error": [
                [
                    "lógica",
                    "lógica",
                    "lógica temporal",
                    "lógica"
                ]
            ]
        },
        "game": {
            "translated_key": "teoría de juegos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and <br>game</br> theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of <br>game</br> theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational complexity of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the complexity of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the <br>game</br> ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of <br>game</br> theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a <br>game</br>, as follows.",
                "A <br>game</br> in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the <br>game</br>; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a <br>game</br> - the normative system <br>game</br> - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding <br>game</br> in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the <br>game</br> GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in <br>game</br> theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the <br>game</br> GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a <br>game</br> designer seeks to achieve some outcomes by designing the rules of the <br>game</br> such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the complexity of mechanism design [5], and the complexity of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "<br>game</br> theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to <br>game</br> theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the complexity of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "<br>game</br> Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "<br>game</br> Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "Complexity of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "Complexity results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The complexity of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in <br>game</br> Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational Complexity.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational complexity and <br>game</br> theoretic properties of this model.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of <br>game</br> theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the <br>game</br> ΣM . 0.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of <br>game</br> theory to analyse them.",
                "We can understand the reasoning here as a <br>game</br>, as follows."
            ],
            "translated_annotated_samples": [
                "En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de <br>juegos</br> de este modelo.",
                "Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la <br>teoría de juegos</br>, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4].",
                "Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el <br>juego</br> ΣM. 0.",
                "JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la <br>teoría de juegos</br> para analizarlos.",
                "Podemos entender el razonamiento aquí como un <br>juego</br>, de la siguiente manera."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la complejidad computacional y las propiedades teóricas de <br>juegos</br> de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la <br>teoría de juegos</br>, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la complejidad computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la complejidad de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de complejidad básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de complejidad teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el <br>juego</br> ΣM. 0. Ten en cuenta que esta es una medida de utilidad ordinal: nos indica, para cualquier agente dado, la utilidad relativa de diferentes estructuras de Kripke, pero los valores de utilidad no están en una escala estándar a nivel del sistema. El hecho de que ui (K1) > ui (K2) ciertamente significa que i prefiere estrictamente K1 sobre K2, pero el hecho de que ui (K) > uj (K) no significa que i valore más a K que j. Por lo tanto, no tiene sentido comparar los valores de utilidad entre agentes, y así, por ejemplo, algunas medidas de utilidad a nivel del sistema (notablemente aquellas que agregan las utilidades individuales, como el bienestar social) no tienen sentido cuando se aplican en este contexto. Sin embargo, como veremos en breve, otras medidas, como la eficiencia de Pareto, pueden aplicarse de manera útil. Existen otras representaciones para los objetivos, que nos permitirían definir utilidades cardinales. Lo más sencillo sería especificar los objetivos γ para un agente como una relación finita, no vacía y biunívoca: γ ⊆ L×R. Suponemos que los valores de x en pares (ϕ, x) ∈ γ están especificados de manera que x para el agente i signifique lo mismo que x para el agente j, y así tenemos utilidad cardinal. Luego definimos la utilidad para i de una estructura de Kripke K como ui(K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}. Los resultados de este artículo, de hecho, se mantienen independientemente de cuál de estas representaciones elijamos en realidad; optamos por el enfoque de jerarquía de objetivos en aras de la simplicidad. Nuestro próximo paso es mostrar cómo, de manera muy similar, podemos elevar la función de utilidad de las estructuras de Kripke a los sistemas normativos. Supongamos que se nos da un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo asociado η sobre K. Para el agente i, sea δi (K, K ) la diferencia en su utilidad al moverse de K a K: δi (K, K ) = ui (K )− ui (K). Entonces, la utilidad de η para el agente i con respecto a K es δi (K, K † η). A veces abusaremos de la notación y simplemente escribiremos δi (K, η) para esto, y nos referiremos a ello como el beneficio para el agente i de implementar η en K. Tenga en cuenta que este beneficio puede ser negativo. En resumen, la utilidad de un sistema normativo para un agente es la diferencia entre la utilidad de la estructura de Kripke en la que se implementó el sistema normativo y la estructura de Kripke original. Si este valor es mayor que 0, entonces al agente le iría mejor si se impusiera el sistema normativo, mientras que si es menor que 0, entonces al agente le iría peor si se impusiera η que en el sistema original. Decimos que η es individualmente racional para i con respecto a K si δi (K, η) > 0, y es individualmente racional en sentido estricto si η es individualmente racional para cada agente. Un sistema social ahora es un par Σ = M, η donde M es un sistema multiagente, y η es un sistema normativo sobre M. EJEMPLO 1. La tabla a la izquierda en la Figura 2 muestra las utilidades δi (K, η) de implementar η en la estructura de Kripke de nuestro ejemplo en curso, para los sistemas normativos η = η∅, η1, η2 y η3, introducidos anteriormente. Recuerde que u1(K) = u2(K) = 4. 4.2 Objetivos Universales y Existenciales 884 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Teniendo en cuenta que una norma η restringe las posibles transiciones del modelo en consideración, hacemos la siguiente observación, tomando prestado de [15]. Algunas clases de objetivos son monótonas o antimonótonas con respecto a la adición de restricciones adicionales a un sistema. Por lo tanto, definamos dos fragmentos del lenguaje de CTL: el lenguaje universal Lu con elemento típico μ, y el fragmento existencial Le con elemento típico ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Digamos, para dos estructuras de Kripke K1 = S, S0 , R1, A, α, V y K2 = S, S0 , R2, A, α, V que K1 es un subsistema de K2 y K2 es un super-sistema de K1, escrito K1 K2 si R1 ⊆ R2. Ten en cuenta que típicamente K † η K. Luego tenemos (cf. [15]). TEOREMA 1. Supongamos que K1 K2 y s ∈ S. Entonces ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ Esto tiene el siguiente efecto al imponer una nueva norma: COROLARIO 1. Sea K una estructura y η un sistema normativo. Que γi denote una jerarquía de objetivos para el agente i. 1. Se supone que el agente tiene utilidad ui (K) igual a n, y γi [n] ∈ Lu, es decir, γi [n] es una fórmula universal. Entonces, para cualquier sistema normativo η, δi (K, η) ≥ 0.2. Se supone que el agente tiene una utilidad ui (K † η) igual a n, y γi [n] es una fórmula existencial ε. Entonces, δi (K † η, K) ≥ 0. El primer ítem del corolario 1 dice que un agente cuyo objetivo máximo actual en un sistema es una fórmula universal, nunca debe temer la imposición de una nueva norma η. La razón es que su objetivo actual al menos seguirá siendo cierto (de hecho, un objetivo más alto en la jerarquía puede volverse cierto). Se deduce de esto que un agente con solo objetivos universales solo puede beneficiarse de la imposición de sistemas normativos η. Lo contrario es cierto para los objetivos existenciales, según el segundo ítem del corolario: nunca puede ser malo para un agente deshacer una norma η. Por lo tanto, un agente con solo metas existenciales bien podría temer cualquier norma η. Sin embargo, estas observaciones asumen implícitamente que todos los agentes en el sistema cumplirán con la norma. Si de hecho lo harán, por supuesto, es una decisión estratégica: en parte depende de lo que el agente piense que harán los otros agentes. Esto nos motiva a considerar juegos de sistemas normativos. 5. JUEGOS DE SISTEMAS NORMATIVOS Ahora tenemos una forma fundamentada de hablar sobre la utilidad de los sistemas normativos para los agentes, por lo que podemos comenzar a aplicar el aparato técnico de la <br>teoría de juegos</br> para analizarlos. Supongamos que tenemos un sistema multiagente M = K, γ1, . . . , γn y un sistema normativo η sobre K. Se propone a los agentes en M que η debería ser impuesta en K, (típicamente para lograr algún objetivo de coordinación). Nuestro agente, digamos agente i, se enfrenta entonces a una elección: ¿debería cumplir con las restricciones del sistema normativo o no? Ten en cuenta que este razonamiento se produce antes de que el agente esté en el sistema, es una consideración en el momento del diseño. Podemos entender el razonamiento aquí como un <br>juego</br>, de la siguiente manera. ",
            "candidates": [],
            "error": [
                [
                    "juegos",
                    "teoría de juegos",
                    "juego",
                    "teoría de juegos",
                    "juego"
                ]
            ]
        },
        "complexity": {
            "translated_key": "complejidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Normative System Games Thomas ◦ Agotnes Dept of Computer Engineering Bergen University College PB.",
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational <br>complexity</br> and game theoretic properties of this model.",
                "In the underlying model of normative systems, we use Kripke structures to represent the possible transitions of a multiagent system.",
                "A normative system is then simply a subset of the Kripke structure, which contains the arcs that are forbidden by the normative system.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripke-based normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We then characterise the computational <br>complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the <br>complexity</br> of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; I.2.4 [Knowledge representation formalisms and methods] General Terms Theory 1.",
                "INTRODUCTION Normative systems, or social laws, have proved to be an attractive approach to coordination in multi-agent systems [13, 14, 10, 15, 1].",
                "Although the various approaches to normative systems proposed in the literature differ on technical details, they all share the same basic intuition that a normative system is a set of constraints on the behaviour of agents in the system; by imposing these constraints, it is hoped that some desirable objective will emerge.",
                "The idea of using social laws to coordinate multi-agent systems was proposed by Shoham and Tennenholtz [13, 14]; their approach was extended by van der Hoek et al. to include the idea of specifying a desirable global objective for a social law as a logical formula, with the idea being that the normative system would be regarded as successful if, after implementing it (i.e., after eliminating all forbidden actions), the objective formula was guaranteed to be satisfied in the system [15].",
                "However, this model did not take into account the preferences of individual agents, and hence neglected to account for possible strategic behaviour by agents when deciding whether to comply with the normative system or not.",
                "This model of normative systems was further extended by attributing to each agent a single goal in [16].",
                "However, this model was still too impoverished to capture the kinds of decision making that take place when an agent decides whether or not to comply with a social law.",
                "In reality, strategic considerations come into play: an agent takes into account not just whether the normative system would be beneficial for itself, but also whether other agents will rationally choose to participate.",
                "In this paper, we develop a model of normative systems in which agents are assumed to have multiple goals, of increasing priority.",
                "We specify an agents goals as a hierarchy of formulae of Computation Tree Logic (CTL), a widely used logic for representing the properties of Kripke structures [8]: the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy.",
                "Using this scheme, we define a model of ordinal utility, which in turn allows us to interpret our Kripkebased normative systems as games, in which agents must determine whether to comply with the normative system or not.",
                "We thus provide a very natural bridge between logical structures and languages and the techniques and concepts of game theory, which have proved to be very powerful for analysing social contract-style scenarios such as normative systems [3, 4].",
                "We then characterise the computational <br>complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the <br>complexity</br> of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "KRIPKE STRUCTURES AND CTL We use Kripke structures as our basic semantic model for multiagent systems [8].",
                "A Kripke structure is essentially a directed graph, with the vertex set S corresponding to possible states of the system being modelled, and the relation R ⊆ S × S capturing the 881 978-81-904262-7-5 (RPS) c 2007 IFAAMAS possible transitions of the system; intuitively, these transitions are caused by agents in the system performing actions, although we do not include such actions in our semantic model (see, e.g., [13, 2, 15] for related models which include actions as first class citizens).",
                "We let S0 denote the set of possible initial states of the system.",
                "Our model is intended to correspond to the well-known interleaved concurrency model from the reactive systems literature: thus an arc corresponds to the execution of an atomic action by one of the processes in the system, which we call agents.",
                "It is important to note that, in contrast to such models as [2, 15], we are therefore here not modelling synchronous action.",
                "This assumption is not in fact essential for our analysis, but it greatly simplifies the presentation.",
                "However, we find it convenient to include within our model the agents that cause transitions.",
                "We therefore assume a set A of agents, and we label each transition in R with the agent that causes the transition via a function α : R → A.",
                "Finally, we use a vocabulary Φ = {p, q, . . .} of Boolean variables to express the properties of individual states S: we use a function V : S → 2Φ to label each state with the Boolean variables true (or satisfied) in that state.",
                "Collecting these components together, an agent-labelled Kripke structure (over Φ) is a 6-tuple: K = S, S0 , R, A, α, V , where: • S is a finite, non-empty set of states, • S0 ⊆ S (S0 = ∅) is the set of initial states; • R ⊆ S × S is a total binary relation on S, which we refer to as the transition relation1 ; • A = {1, . . . , n} is a set of agents; • α : R → A labels each transition in R with an agent; and • V : S → 2Φ labels each state with the set of propositional variables true in that state.",
                "In the interests of brevity, we shall hereafter refer to an agentlabelled Kripke structure simply as a Kripke structure.",
                "A path over a transition relation R is an infinite sequence of states π = s0, s1, . . . which must satisfy the property that ∀u ∈ N: (su , su+1) ∈ R. If u ∈ N, then we denote by π[u] the component indexed by u in π (thus π[0] denotes the first element, π[1] the second, and so on).",
                "A path π such that π[0] = s is an s-path.",
                "Let ΠR(s) denote the set of s-paths over R; since it will usually be clear from context, we often omit reference to R, and simply write Π(s).",
                "We will sometimes refer to and think of an s-path as a possible computation, or system evolution, from s. EXAMPLE 1.",
                "Our running example is of a system with a single non-sharable resource, which is desired by two agents.",
                "Consider the Kripke structure depicted in Figure 1.",
                "We have two states, s and t, and two corresponding Boolean variables p1 and p2, which are 1 In the branching time temporal logic literature, a relation R ⊆ S × S is said to be total iff ∀s ∃s : (s, s ) ∈ R. Note that the term total relation is sometimes used to refer to relations R ⊆ S × S such that for every pair of elements s, s ∈ S we have either (s, s ) ∈ R or (s , s) ∈ R; we are not using the term in this way here.",
                "It is also worth noting that for some domains, other constraints may be more appropriate than simple totality.",
                "For example, one might consider the agent totality requirement, that in every state, every agent has at least one possible transition available: ∀s∀i ∈ A∃s : (s, s ) ∈ R and α(s, s ) = i. 2p t p 2 2 1 s 1 1 Figure 1: The resource control running example. mutually exclusive.",
                "Think of pi as meaning agent i has currently control over the resource.",
                "Each agent has two possible actions, when in possession of the resource: either give it away, or keep it.",
                "Obviously there are infinitely many different s-paths and t-paths.",
                "Let us say that our set of initial states S0 equals {s, t}, i.e., we dont make any assumptions about who initially has control over the resource. 2.1 CTL We now define Computation Tree Logic (CTL), a branching time temporal logic intended for representing the properties of Kripke structures [8].",
                "Note that since CTL is well known and widely documented in the literature, our presentation, though complete, will be somewhat terse.",
                "We will use CTL to express agents goals.",
                "The syntax of CTL is defined by the following grammar: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) where p ∈ Φ.",
                "We denote the set of CTL formula over Φ by LΦ; since Φ is understood, we usually omit reference to it.",
                "The semantics of CTL are given with respect to the satisfaction relation |=, which holds between pairs of the form K, s, (where K is a Kripke structure and s is a state in K), and formulae of the language.",
                "The satisfaction relation is defined as follows: K, s |= ; K, s |= p iff p ∈ V (s) (where p ∈ Φ); K, s |= ¬ϕ iff not K, s |= ϕ; K, s |= ϕ ∨ ψ iff K, s |= ϕ or K, s |= ψ; K, s |= A fϕ iff ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ iff ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) iff ∀π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) iff ∃π ∈ Π(s), ∃u ∈ N, s.t.",
                "K, π[u] |= ψ and ∀v, (0 ≤ v < u) : K, π[v] |= ϕ The remaining classical logic connectives (∧, →, ↔) are assumed to be defined as abbreviations in terms of ¬, ∨, in the conventional manner.",
                "The remaining CTL temporal operators are defined: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ We say ϕ is satisfiable if K, s |= ϕ for some Kripke structure K and state s in K; ϕ is valid if K, s |= ϕ for all Kripke structures K and states s in K. The problem of checking whether K, s |= ϕ for given K, s, ϕ (model checking) can be done in deterministic polynomial time, while checking whether a given ϕ is satisfiable or whether ϕ is valid is EXPTIME-complete [8].",
                "We write K |= ϕ if K, s0 |= ϕ for all s0 ∈ S0 , and |= ϕ if K |= ϕ for all K. 882 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 3.",
                "NORMATIVE SYSTEMS For our purposes, a normative system is simply a set of constraints on the behaviour of agents in a system [1].",
                "More precisely, a normative system defines, for every possible system transition, whether or not that transition is considered to be legal or not.",
                "Different normative systems may differ on whether or not a transition is legal.",
                "Formally, a normative system η (w.r.t. a Kripke structure K = S, S0 , R, A, α, V ) is simply a subset of R, such that R \\ η is a total relation.",
                "The requirement that R\\η is total is a reasonableness constraint: it prevents normative systems which lead to states with no successor.",
                "Let N (R) = {η : (η ⊆ R) & (R \\ η is total)} be the set of normative systems over R. The intended interpretation of a normative system η is that (s, s ) ∈ η means transition (s, s ) is forbidden in the context of η; hence R \\ η denotes the legal transitions of η.",
                "Since it is assumed η is reasonable, we are guaranteed that a legal outward transition exists for every state.",
                "We denote the empty normative system by η∅, so η∅ = ∅.",
                "Note that the empty normative system η∅ is reasonable with respect to any transition relation R. The effect of implementing a normative system on a Kripke structure is to eliminate from it all transitions that are forbidden according to this normative system (see [15, 1]).",
                "If K is a Kripke structure, and η is a normative system over K, then K † η denotes the Kripke structure obtained from K by deleting transitions forbidden in η.",
                "Formally, if K = S, S0 , R, A, α, V , and η ∈ N (R), then let K†η = K be the Kripke structure K = S , S0 , R , A , α , V where: • S = S , S0 = S0 , A = A , and V = V ; • R = R \\ η; and • α is the restriction of α to R : α (s, s ) = j α(s, s ) if (s, s ) ∈ R undefined otherwise.",
                "Notice that for all K, we have K † η∅ = K. EXAMPLE 1. (continued) When thinking in terms of fairness, it seems natural to consider normative systems η that contain (s, s) or (t, t).",
                "A normative system with (s, t) would not be fair, in the sense that A♦A ¬p1 ∨ A♦A ¬p2 holds: in all paths, from some moment on, one agent will have control forever.",
                "Let us, for later reference, fix η1 = {(s, s)}, η2 = {(t, t)}, and η3 = {(s, s), (t, t)}.",
                "Later, we will address the issue of whether or not agents should rationally choose to comply with a particular normative system.",
                "In this context, it is useful to define operators on normative systems which correspond to groups of agents defecting from the normative system.",
                "Formally, let K = S, S0 ,R, A,α, V be a Kripke structure, let C ⊆ A be a set of agents over K, and let η be a normative system over K. Then: • η C denotes the normative system that is the same as η except that it only contains the arcs of η that correspond to the actions of agents in C. We call η C the restriction of η to C, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose to comply with the normative system. • η C denotes the normative system that is the same as η except that it only contains the arcs of η that do not correspond to actions of agents in C. We call η C the exclusion of C from η, and it is defined as: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}.",
                "Thus K † (η C) is the Kripke structure that results if only the agents in C choose not to comply with the normative system (i.e., the only ones who comply are those in A \\ C).",
                "Note that we have η C = η (A\\C) and η C = η (A\\C).",
                "EXAMPLE 1. (Continued) We have η1 {1} = η1 = {(s, s)}, while η1 {1} = η∅ = η1 {2}.",
                "Similarly, we have η3 {1} = {(s, s)} and η3 {1} = {(t, t)}. 4.",
                "GOALS AND UTILITIES Next, we want to be able to capture the goals that agents have, as these will drive an agents strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.",
                "We will model an agents goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.",
                "The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the hierarchy a goal is, the more it is desired by i.",
                "Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the hierarchy.",
                "Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, . . . , ϕk ) in which, by convention, ϕ0 = .",
                "We use a natural number indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, . . . , ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.",
                "We denote the largest index of any element in γ by |γ|.",
                "A particular Kripke structure K is said to satisfy a goal at index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.",
                "Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, . . . , |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].",
                "The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.",
                "Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.",
                "EXAMPLE 1. (continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.",
                "Define each agents goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation, always have the resource, pi (this is expressed in ϕi 8).",
                "Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.",
                "Goal ϕi 6 is a fairness constraint implied by it.",
                "Note that A♦pi says that every computation eventually reaches a pi state.",
                "This may mean that after pi has happened, it will never happen again. ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.",
                "The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually. ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .",
                "Goal ϕi 3 says that pi should be true on some branch, from some moment on.",
                "It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .",
                "This implies ϕi 1, which says that pi should at least not be impossible.",
                "If we even drop that demand, we have the trivial goal ϕi 0.",
                "We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .",
                "However, this is not a proper CTL formula.",
                "It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.",
                "However, our basic <br>complexity</br> results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).",
                "We comment on the implications of alternative goal representations at the conclusion of the next section.",
                "A multi-agent system collects together a Kripke structure (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.",
                "Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, . . . , γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.",
                "The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.",
                "We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1. (continued) Let M = K, γ1, γ2 be the multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.",
                "Recall that we have defined S0 as {s, t}.",
                "Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.",
                "To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard <br>complexity</br> theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0.",
                "Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.",
                "The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .",
                "Thus, it does not make sense to compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate individual utilities, such as social welfare), do not make sense when applied in this setting.",
                "However, as we shall see shortly, other measures - such as Pareto efficiency - can be usefully applied.",
                "There are other representations for goals, which would allow us to define cardinal utilities.",
                "The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.",
                "We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.",
                "We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.",
                "The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.",
                "Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.",
                "Suppose we are given a multi-agent system M = K, γ1, . . . , γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).",
                "Then the utility of η to agent i wrt K is δi (K, K † η).",
                "We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.",
                "Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke structure.",
                "If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.",
                "We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is individually rational for every agent.",
                "A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .",
                "EXAMPLE 1.",
                "The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.",
                "Recall that u1(K) = u2(K) = 4. 4.2 Universal and Existential Goals 884 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following observation, borrowing from [15].",
                "Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.",
                "Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.",
                "Note that typically K † η K. Then we have (cf. [15]).",
                "THEOREM 1.",
                "Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.",
                "Let K be a structure, and η a normative system.",
                "Let γi denote a goal hierarchy for agent i. 1.",
                "Suppose agent is utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).",
                "Then, for any normative system η, δi (K, η) ≥ 0. 2.",
                "Suppose agent is utility ui (K † η) is n, and γi [n] is an existential formula ε.",
                "Then, δi (K † η, K) ≥ 0.",
                "Corollary 1s first item says that an agent whose current maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.",
                "The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).",
                "It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.",
                "The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.",
                "Hence, an agent with only existential goals might well fear any norm η.",
                "However, these observations implicitly assume that all agents in the system will comply with the norm.",
                "Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.",
                "This motivates us to consider normative system games. 5.",
                "NORMATIVE SYSTEM GAMES We now have a principled way of talking about the utility of normative systems for agents, and so we can start to apply the technical apparatus of game theory to analyse them.",
                "Suppose we have a multi-agent system M = K, γ1, . . . , γn and a normative system η over K. It is proposed to the agents in M that η should be imposed on K, (typically to achieve some coordination objective).",
                "Our agent - lets say agent i - is then faced with a choice: should it comply with the strictures of the normative system, or not?",
                "Note that this reasoning takes place before the agent is in the system - it is a design time consideration.",
                "We can understand the reasoning here as a game, as follows.",
                "A game in strategic normal form (cf. [11, p.11]) is a structure: G = AG, S1, . . . , Sn , U1, . . . , Un where: • AG = {1, . . . , n} is a set of agents - the players of the game; • Si is the set of strategies for each agent i ∈ AG (a strategy for an agent i is nothing else than a choice between alternative actions); and • Ui : (S1 × · · · × Sn ) → R is the utility function for agent i ∈ AG, which assigns a utility to every combination of strategy choices for the agents.",
                "Now, suppose we are given a social system Σ = M , η where M = K, γ1, . . . , γn .",
                "Then we can associate a game - the normative system game - GΣ with Σ, as follows.",
                "The agents AG in GΣ are as in Σ.",
                "Each agent i has just two strategies available to it: • C - comply (cooperate) with the normative system; and • D - do not comply with (defect from) the normative system.",
                "If S is a tuple of strategies, one for each agent, and x ∈ {C, D}, then we denote by AGx S the subset of agents that play strategy x in S. Hence, for a social system Σ = M , η , the normative system η AGC S only implements the restrictions for those agents that choose to cooperate in GΣ.",
                "Note that this is the same as η AGD S : the normative system that excludes all the restrictions of agents that play D in GΣ.",
                "We then define the utility functions Ui for each i ∈ AG as: Ui (S) = δi (K, η AGC S ).",
                "So, for example, if SD is a collection of strategies in which every agent defects (i.e., does not comply with the norm), then Ui (SD ) = δi (K, (η AGD SD )) = ui (K † η∅) − ui (K) = 0.",
                "In the same way, if SC is a collection of strategies in which every agent cooperates (i.e., complies with the norm), then Ui (SC ) = δi (K, (η AGD SC )) = ui (K † (η ∅)) = ui (K † η).",
                "We can now start to investigate some properties of normative system games.",
                "EXAMPLE 1. (continued) For our example system, we have displayed the different U values for our multi agent system with the norm η3, i.e., {(s, s), (t, t)} as the second table of Figure 2.",
                "For instance, the pair (0, 3) in the matrix under the entry S = C, D is obtained as follows.",
                "U1( C, D ) = δ1(K, η3 AGC C,D ) = u1(K † η3 AGC C,D ) − u1(K).",
                "The first term of this is the utility of 1 in the system K where we implement η3 for the cooperating agent, i.e., 1, only.",
                "This means that the transitions are R \\ {(s, s)}.",
                "In this system, still ϕ1 4 = A E♦p1 is the highest goal for agent 1.",
                "This is the same utility for 1 as in K, and hence, δ1(K, η3 AGC C,D ) = 0.",
                "Agent 2 of course benefits if agent 1 complies with η3 while 2 does not.",
                "His utility would be 3, since η3 AGC C,D is in fact η1. 5.1 Individually Rational Normative Systems A normative system is individually rational if every agent would fare better if the normative system were imposed than otherwise.",
                "This is a necessary, although not sufficient condition on a norm to expect that everybody respects it.",
                "Note that η3 of our example is individually rational for both 1 and 2, although this is not a stable situation: given that the other plays C, i is better of by playing D. We can easily characterise individually rationality with respect to the corresponding game in strategic form, as follows.",
                "Let Σ = M , η be a social system.",
                "Then the following are equivalent: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 885 f(xk) ... s0 s1 s2 s3 s4 s(2k−1) s2k t(x1) f(x1) t(x2) f(x2) t(xk) Figure 3: The Kripke structure produced in the reduction of Theorem 2; all transitions are associated with agent 1, the only initial state is s0. 1. η is individually rational in M ; 2. ∀i ∈ AG, Ui (SC ) > Ui (SD ) in the game GΣ.",
                "The decision problem associated with individually rational normative systems is as follows: INDIVIDUALLY RATIONAL NORMATIVE SYSTEM (IRNS): Given: Multi-agent system M .",
                "Question: Does there exist an individually rational normative system for M ?",
                "THEOREM 2.",
                "IRNS is NP-complete, even in one-agent systems.",
                "PROOF.",
                "For membership of NP, guess a normative system η, and verify that it is individually rational.",
                "Since η ⊆ R, we will be able to guess it in nondeterministic polynomial time.",
                "To verify that it is individually rational, we check that for all i, we have ui (K † η) > ui (K); computing K † η is just set subtraction, so can be done in polynomial time, while determining the value of ui (K) for any K can be done with a polynomial number of model checking calls, each of which requires only time polynomial in the K and γ.",
                "Hence verifying that ui (K † η) > ui (K) requires only polynomial time.",
                "For NP-hardness, we reduce SAT [12, p.77].",
                "Given a SAT instance ϕ over Boolean variables x1, . . . , xk , we produce an instance of IRNS as follows.",
                "First, we define a single agent A = {1}.",
                "For each Boolean variable xi in the SAT instance, we create two Boolean variables t(xi ) and f (xi ) in the IRNS instance.",
                "We then create a Kripke structure Kϕ with 2k + 1 states, as shown in Figure 3: arcs in this graph correspond to transitions in Kϕ.",
                "Let ϕ∗ be the result of systematically substituting for every Boolean variable xi in ϕ the CTL expression (E ft(xi )).",
                "Next, consider the following formulae: k^ i=1 E f(t(xi ) ∨ f (xi )) (1) k^ i=1 ¬((E ft(xi )) ∧ (E ff (xi ))) (2) We then define the goal hierarchy for all agent 1 as follows: γ1[0] = γ1[1] = (1) ∧ (2) ∧ ϕ∗ We claim there is an individually rational normative system for the instance so constructed iff ϕ is satisfiable.",
                "First, notice that any individually rational normative system must force γ1[1] to be true, since in the original system, we do not have γ1[1].",
                "For the ⇒ direction, if there is an individually rational normative system η, then we construct a satisfying assignment for ϕ by considering the arcs that are forbidden by η: formula (1) ensures that we must forbid an arc to either a t(xi ) or a f (xi ) state for all variables xi , but (2) ensures that we cannot forbid arcs to both.",
                "So, if we forbid an arc to a t(xi ) state then in the corresponding valuation for ϕ we make xi false, while if we forbid an arc to a f (xi ) state then we make xi true.",
                "The fact that ϕ∗ is part of the goal ensures that the normative system is indeed a valuation for ϕ.",
                "For ⇐, note that for any satisfying valuation for ϕ we can construct an individually rational normative system η, as follows: if the valuation makes xi true, we forbid the arc to the f (xi ) state, while if the valuation makes xi false, we forbid the arc to the t(xi ) state.",
                "The resulting normative system ensures γ1[1], and is thus individually rational.",
                "Notice that the Kripke structure constructed in the reduction contains just a single agent, and so the Theorem is proven. 5.2 Pareto Efficient Normative Systems Pareto efficiency is a basic measure of how good a particular outcome is for a group of agents [11, p.7].",
                "Intuitively, an outcome is Pareto efficient if there is no other outcome that makes every agent better off.",
                "In our framework, suppose we are given a social system Σ = M , η , and asked whether η is Pareto efficient.",
                "This amounts to asking whether or not there is some other normative system η such that every agent would be better off under η than with η.",
                "If η makes every agent better off than η, then we say η Pareto dominates η.",
                "The decision problem is as follows: PARETO EFFICIENT NORMATIVE SYSTEM (PENS): Given: Multi-agent system M and normative system η over M .",
                "Question: Is η Pareto efficient for M ?",
                "THEOREM 3.",
                "PENS is co-NP-complete, even for one-agent systems.",
                "PROOF.",
                "Let M and η be as in the Theorem.",
                "We show that the complement problem to PENS, which we refer to as PARETO DOMINATED, is NP-complete.",
                "In this problem, we are given M and η, and we are asked whether η is Pareto dominated, i.e., whether or not there exists some η over M such that η makes every agent better off than η.",
                "For membership of NP, simply guess a normative system η , and verify that for all i ∈ A, we have ui (K † η ) > ui (K † η) - verifying requires a polynomial number of model checking problems, each of which takes polynomial time.",
                "Since η ⊆ R, the normative system can be guessed in non-deterministic polynomial time.",
                "For NP-hardness, we reduce IRNS, which we know to be NPcomplete from Theorem 2.",
                "Given an instance M of IRNS, we let M in the instance of PARETO DOMINATED be as in the IRNS instance, and define the normative system for PARETO DOMINATED to be η∅, the empty normative system.",
                "Now, it is straightforward that there exists a normative system η which Pareto dominates η∅ in M iff there exist an individually rational normative system in M .",
                "Since the complement problem is NP-complete, it follows that PENS is co-NP-complete. 886 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) η0 η1 η2 η3 η4 η5 η6 η7 η8 u1(K † η) 4 4 7 6 5 0 0 8 0 u2(K † η) 4 7 4 6 0 5 8 0 0 Table 1: Utilities for all possible norms in our example How about Pareto efficient norms for our toy example?",
                "Settling this question amounts to finding the dominant normative systems among η0 = η∅, η1, η2, η3 defined before, and η4 = {(s, t)}, η5 = {(t, s)}, η6 = {(s, s), (t, s)}, η7 = {(t, t), (s, t)} and η8 = {(s, t), (t, s)}.",
                "The utilities for each system are given in Table 1.",
                "From this, we infer that the Pareto efficient norms are η1, η2, η3, η6 and η7.",
                "Note that η8 prohibits the resource to be passed from one agent to another, and this is not good for any agent (since we have chosen S0 = {s, t}, no agent can be sure to ever get the resource, i.e., goal ϕi 1 is not true in K † η8). 5.3 Nash Implementation Normative Systems The most famous solution concept in game theory is of course Nash equilibrium [11, p.14].",
                "A collection of strategies, one for each agent, is said to form a Nash equilibrium if no agent can benefit by doing anything other than playing its strategy, under the assumption that the other agents play theirs.",
                "Nash equilibria are important because they provide stable solutions to the problem of what strategy an agent should play.",
                "Note that in our toy example, although η3 is individually rational for each agent, it is not a Nash equilibrium, since given this norm, it would be beneficial for agent 1 to deviate (and likewise for 2).",
                "In our framework, we say a social system Σ = M , η (where η = η∅) is a Nash implementation if SC (i.e., everyone complying with the normative system) forms a Nash equilibrium in the game GΣ.",
                "The intuition is that if Σ is a Nash implementation, then complying with the normative system is a reasonable solution for all concerned: there can be no benefit to deviating from it, indeed, there is a positive incentive for all to comply.",
                "If Σ is not a Nash implementation, then the normative system is unlikely to succeed, since compliance is not rational for some agents. (Our choice of terminology is deliberately chosen to reflect the way the term Nash implementation is used in implementation theory, or mechanism design [11, p.185], where a game designer seeks to achieve some outcomes by designing the rules of the game such that these outcomes are equilibria.)",
                "NASH IMPLEMENTATION (NI) : Given: Multi-agent system M .",
                "Question: Does there exist a non-empty normative system η over M such that M , η forms a Nash implementation?",
                "Verifying that a particular social system forms a Nash implementation can be done in polynomial time - it amounts to checking: ∀i ∈ A : ui (K † η) ≥ ui (K † (η {i})).",
                "This, clearly requires only a polynomial number of model checking calls, each of which requires only polynomial time.",
                "THEOREM 4.",
                "The NI problem is NP-complete, even for twoagent systems.",
                "PROOF.",
                "For membership of NP, simply guess a normative system η and check that it forms a Nash implementation; since η ⊆ R, guessing can be done in non-deterministic polynomial time, and as s(2k+1) 1 1 1 1 1 1 11 1 1 11 2 2 2 2 2 2 2 2 2 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) 2 2 t(x1) f(x1) t(x2) f(x2) t(xk) f(xk) ...... s0 Figure 4: Reduction for Theorem 4. we argued above, verifying that it forms a Nash implementation can be done in polynomial time.",
                "For NP-hardness, we reduce SAT.",
                "Suppose we are given a SAT instance ϕ over Boolean variables x1, . . . , xk .",
                "Then we construct an instance of NI as follows.",
                "We create two agents, A = {1, 2}.",
                "For each Boolean variable xi we create two Boolean variables, t(xi ) and f (xi ), and we then define a Kripke structure as shown in Figure 4, with s0 being the only initial state; the arc labelling in Figure 4 gives the α function, and each state is labelled with the propositions that are true in that state.",
                "For each Boolean variable xi , we define the formulae xi and x⊥ i as follows: xi = E f(t(xi ) ∧ E f((E f(t(xi ))) ∧ A f(¬f (xi )))) x⊥ i = E f(f (xi ) ∧ E f((E f(f (xi ))) ∧ A f(¬t(xi )))) Let ϕ∗ be the formula obtained from ϕ by systematically substituting xi for xi .",
                "Each agent has three goals: γi [0] = for both i ∈ {1, 2}, while γ1[1] = k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) γ2[1] = E fE f k^ i=1 ((E f(t(xi ))) ∧ (E f(f (xi )))) and finally, for both agents, γi [2] being the conjunction of the following formulae: The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 887 k^ i=1 (xi ∨ x⊥ i ) (3) k^ i=1 ¬(xi ∧ x⊥ i ) (4) k^ i=1 ¬(E f(t(xi )) ∧ E f(f (xi ))) (5) ϕ∗ (6) We denote the multi-agent system so constructed by Mϕ.",
                "Now, we prove that the SAT instance ϕ is satisfiable iff Mϕ has a Nash implementation normative system: For the ⇒ direction, suppose ϕ is satisfiable, and let X be a satisfying valuation, i.e., a set of Boolean variables making ϕ true.",
                "We can extract from X a Nash implementation normative system η as follows: if xi ∈ X , then η includes the arc from s0 to the state in which f (xi ) is true, and also includes the arc from s(2k + 1) to the state in which f (xi ) is true; if xi ∈ X , then η includes the arc from s0 to the state in which t(xi ) is true, and also includes the arc from s(2k + 1) to the state in which t(xi ) is true.",
                "No other arcs, apart from those so defined, as included in η.",
                "Notice that η is individually rational for both agents: if they both comply with the normative system, then they will have their γi [2] goals achieved, which they do not in the basic system.",
                "To see that η forms a Nash implementation, observe that if either agent defects from η, then neither will have their γi [2] goals achieved: agent 1 strictly prefers (C, C) over (D, C), and agent 2 strictly prefers (C, C) over (C, D).",
                "For the ⇐ direction, suppose there exists a Nash implementation normative system η, in which case η = ∅.",
                "Then ϕ is satisfiable; for suppose not.",
                "Then the goals γi [2] are not achievable by any normative system, (by construction).",
                "Now, since η must forbid at least one transition, then at least one agent would fail to have its γi [1] goal achieved if it complied, so at least one would do better by defecting, i.e., not complying with η.",
                "But this contradicts the assumption that η is a Nash implementation, i.e., that (C, C) forms a Nash equilibrium.",
                "This result is perhaps of some technical interest beyond the specific concerns of the present paper, since it is related to two problems that are of wider interest: the <br>complexity</br> of mechanism design [5], and the <br>complexity</br> of computing Nash equilibria [6, 7] 5.4 Richer Goal Languages It is interesting to consider what happens to the complexity of the problems we consider above if we allow richer languages for goals: in particular, CTL ∗ [9].",
                "The main difference is that determining ui (K) in a given multi-agent system M when such a goal language is used involves solving a PSPACE-complete problem (since model checking for CTL ∗ is PSPACE-complete [8]).",
                "In fact, it seems that for each of the three problems we consider above, the corresponding problem under the assumption of a CTL ∗ representation for goals is also PSPACE-complete.",
                "It cannot be any easier, since determining the utility of a particular Kripke structure involves solving a PSPACE-complete problem.",
                "To see membership in PSPACE we can exploit the fact that PSPACE = NPSPACE [12, p.150], and so we can guess the desired normative system, applying a PSPACE verification procedure to check that it has the desired properties. 6.",
                "CONCLUSIONS Social norms are supposed to restrict our behaviour.",
                "Of course, such a restriction does not have to be bad: the fact that an agents behaviour is restricted may seem a limitation, but there may be benefits if he can assume that others will also constrain their behaviour.",
                "The question then, for an agent is, how to be sure that others will comply with a norm.",
                "And, for a system designer, how to be sure that the system will behave socially, that is, according to its norm.",
                "Game theory is a very natural tool to analyse and answer these questions, which involve strategic considerations, and we have proposed a way to translate key questions concerning logic-based normative systems to game theoretical questions.",
                "We have proposed a logical framework to reason about such scenarios, and we have given some computational costs for settling some of the main questions about them.",
                "Of course, our approach is in many senses open for extension or enrichment.",
                "An obvious issue is to consider is the <br>complexity</br> of the questions we give for more practical representations of models (cf. [1]), and to consider other classes of allowable goals. 7.",
                "REFERENCES [1] T. Agotnes, W. van der Hoek, J.",
                "A. Rodriguez-Aguilar, C. Sierra, and M. Wooldridge.",
                "On the logic of normative systems.",
                "In Proc.",
                "IJCAI-07, Hyderabad, India, 2007. [2] R. Alur, T. A. Henzinger, and O. Kupferman.",
                "Alternating-time temporal logic.",
                "Jnl. of the ACM, 49(5):672-713, 2002. [3] K. Binmore.",
                "Game Theory and the Social Contract Volume 1: Playing Fair.",
                "The MIT Press: Cambridge, MA, 1994. [4] K. Binmore.",
                "Game Theory and the Social Contract Volume 2: Just Playing.",
                "The MIT Press: Cambridge, MA, 1998. [5] V. Conitzer and T. Sandholm.",
                "<br>complexity</br> of mechanism design.",
                "In Proc.",
                "UAI, Edmonton, Canada, 2002. [6] V. Conitzer and T. Sandholm.",
                "<br>complexity</br> results about nash equilibria.",
                "In Proc.",
                "IJCAI-03, pp. 765-771, Acapulco, Mexico, 2003. [7] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou.",
                "The <br>complexity</br> of computing a Nash equilibrium.",
                "In Proc.",
                "STOC, Seattle, WA, 2006. [8] E. A. Emerson.",
                "Temporal and modal logic.",
                "In Handbook of Theor.",
                "Comp.",
                "Sci.",
                "Vol.",
                "B, pages 996-1072.",
                "Elsevier, 1990. [9] E. A. Emerson and J. Y. Halpern.",
                "Sometimes and not never revisited: on branching time versus linear time temporal logic.",
                "Jnl. of the ACM, 33(1):151-178, 1986. [10] D. Fitoussi and M. Tennenholtz.",
                "Choosing social laws for multi-agent systems: Minimality and simplicity.",
                "Artificial Intelligence, 119(1-2):61-101, 2000. [11] M. J. Osborne and A. Rubinstein.",
                "A Course in Game Theory.",
                "The MIT Press: Cambridge, MA, 1994. [12] C. H. Papadimitriou.",
                "Computational <br>complexity</br>.",
                "Addison-Wesley: Reading, MA, 1994. [13] Y. Shoham and M. Tennenholtz.",
                "On the synthesis of useful social laws for artificial agent societies.",
                "In Proc.",
                "AAAI, San Diego, CA, 1992. [14] Y. Shoham and M. Tennenholtz.",
                "On social laws for artificial agent societies: Off-line design.",
                "In Computational Theories of Interaction and Agency, pages 597-618.",
                "The MIT Press: Cambridge, MA, 1996. [15] W. van der Hoek, M. Roberts, and M. Wooldridge.",
                "Social laws in alternating time: Effectiveness, feasibility, and synthesis.",
                "Synthese, 2007. [16] M. Wooldridge and W. van der Hoek.",
                "On obligations and normative ability.",
                "Jnl. of Appl.",
                "Logic, 3:396-420, 2005. 888 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "2030, N-5020 Bergen Norway tag@hib.no Wiebe van der Hoek Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK wiebe@csc.liv.ac.uk Michael Wooldridge Dept of Computer Science University of Liverpool Liverpool L69 7ZF UK mjw@csc.liv.ac.uk ABSTRACT We develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority, and investigate the computational <br>complexity</br> and game theoretic properties of this model.",
                "We then characterise the computational <br>complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the <br>complexity</br> of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete.",
                "We then characterise the computational <br>complexity</br> of a number of decision problems associated with these Kripke-based normative system games; for example, we show that the <br>complexity</br> of checking whether there exists a normative system which has the property of being a Nash implementation is NP-complete. 2.",
                "However, our basic <br>complexity</br> results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.",
                "Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard <br>complexity</br> theoretic assumptions) than model checking CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM . 0."
            ],
            "translated_annotated_samples": [
                "En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la <br>complejidad</br> computacional y las propiedades teóricas de juegos de este modelo.",
                "Luego caracterizamos la <br>complejidad</br> computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la <br>complejidad</br> de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa.",
                "Luego caracterizamos la <br>complejidad</br> computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la <br>complejidad</br> de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa.",
                "Sin embargo, nuestros resultados de <br>complejidad</br> básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría.",
                "Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de <br>complejidad</br> teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0."
            ],
            "translated_text": "Juegos de sistemas normativos Thomas ◦ Agotnes Depto. de Ingeniería Informática Colegio Universitario de Bergen PB. En 2030, N-5020 Bergen, Noruega tag@hib.no Wiebe van der Hoek Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido wiebe@csc.liv.ac.uk Michael Wooldridge Dept de Ciencias de la Computación Universidad de Liverpool Liverpool L69 7ZF Reino Unido mjw@csc.liv.ac.uk RESUMEN Desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos de prioridad creciente, e investigamos la <br>complejidad</br> computacional y las propiedades teóricas de juegos de este modelo. En el modelo subyacente de sistemas normativos, utilizamos estructuras de Kripke para representar las posibles transiciones de un sistema multiagente. Un sistema normativo es simplemente un subconjunto de la estructura de Kripke, que contiene los arcos que están prohibidos por el sistema normativo. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Cómputo (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Luego caracterizamos la <br>complejidad</br> computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la <br>complejidad</br> de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Sistemas Multiagente; I.2.4 [Formalismos y Métodos de Representación del Conocimiento] Términos Generales Teoría 1. Los sistemas normativos, o leyes sociales, han demostrado ser un enfoque atractivo para la coordinación en sistemas multiagente [13, 14, 10, 15, 1]. Aunque las diversas aproximaciones a los sistemas normativos propuestas en la literatura difieren en detalles técnicos, todas comparten la misma intuición básica de que un sistema normativo es un conjunto de restricciones sobre el comportamiento de los agentes en el sistema; al imponer estas restricciones, se espera que surja algún objetivo deseable. La idea de utilizar leyes sociales para coordinar sistemas multiagente fue propuesta por Shoham y Tennenholtz [13, 14]; su enfoque fue ampliado por van der Hoek et al. para incluir la idea de especificar un objetivo global deseable para una ley social como una fórmula lógica, con la idea de que el sistema normativo sería considerado exitoso si, después de implementarlo (es decir, después de eliminar todas las acciones prohibidas), la fórmula del objetivo estuviera garantizada de ser satisfecha en el sistema [15]. Sin embargo, este modelo no tuvo en cuenta las preferencias de los agentes individuales, y por lo tanto no consideró el posible comportamiento estratégico de los agentes al decidir si cumplir o no con el sistema normativo. Este modelo de sistemas normativos fue ampliado aún más al atribuir a cada agente un único objetivo en [16]. Sin embargo, este modelo todavía era demasiado limitado para capturar los tipos de toma de decisiones que tienen lugar cuando un agente decide si cumplir o no con una ley social. En realidad, entran en juego consideraciones estratégicas: un agente tiene en cuenta no solo si el sistema normativo sería beneficioso para sí mismo, sino también si otros agentes elegirán participar racionalmente. En este artículo, desarrollamos un modelo de sistemas normativos en el que se asume que los agentes tienen múltiples objetivos, de prioridad creciente. Especificamos los objetivos de un agente como una jerarquía de fórmulas de Lógica del Árbol de Computación (CTL), una lógica ampliamente utilizada para representar las propiedades de las estructuras de Kripke [8]: la intuición es que los objetivos más arriba en la jerarquía son preferidos por el agente sobre aquellos que aparecen más abajo en la jerarquía. Usando este esquema, definimos un modelo de utilidad ordinal, lo que a su vez nos permite interpretar nuestros sistemas normativos basados en Kripke como juegos, en los que los agentes deben determinar si cumplir con el sistema normativo o no. Por lo tanto, proporcionamos un puente muy natural entre las estructuras lógicas y los idiomas y las técnicas y conceptos de la teoría de juegos, que han demostrado ser muy poderosos para analizar escenarios de estilo de contrato social como sistemas normativos [3, 4]. Luego caracterizamos la <br>complejidad</br> computacional de varios problemas de decisión asociados con estos juegos de sistemas normativos basados en Kripke; por ejemplo, demostramos que la <br>complejidad</br> de verificar si existe un sistema normativo que tiene la propiedad de ser una implementación de Nash es NP-completa. Utilizamos estructuras de Kripke como nuestro modelo semántico básico para sistemas multiagentes [8]. Una estructura de Kripke es esencialmente un grafo dirigido, con el conjunto de vértices S correspondiente a los posibles estados del sistema que se está modelando, y la relación R ⊆ S × S capturando las posibles transiciones del sistema; intuitivamente, estas transiciones son causadas por agentes en el sistema realizando acciones, aunque no incluimos dichas acciones en nuestro modelo semántico (ver, por ejemplo, [13, 2, 15] para modelos relacionados que incluyen acciones como ciudadanos de primera clase). Dejamos que S0 denote el conjunto de posibles estados iniciales del sistema. Nuestro modelo está destinado a corresponder al conocido modelo de concurrencia entrelazada de la literatura de sistemas reactivos: por lo tanto, un arco corresponde a la ejecución de una acción atómica por uno de los procesos en el sistema, a los que llamamos agentes. Es importante tener en cuenta que, a diferencia de modelos como [2, 15], aquí no estamos modelando una acción sincrónica. Esta suposición no es esencial para nuestro análisis, pero simplifica en gran medida la presentación. Sin embargo, encontramos conveniente incluir en nuestro modelo a los agentes que causan transiciones. Por lo tanto, asumimos un conjunto A de agentes, y etiquetamos cada transición en R con el agente que causa la transición a través de una función α: R → A. Finalmente, usamos un vocabulario Φ = {p, q, . . .} de variables booleanas para expresar las propiedades de los estados individuales S: utilizamos una función V : S → 2Φ para etiquetar cada estado con las variables booleanas verdaderas (o satisfechas) en ese estado. Reuniendo estos componentes, una estructura de Kripke etiquetada por agentes (sobre Φ) es una 6-tupla: K = S, S0, R, A, α, V, donde: • S es un conjunto finito y no vacío de estados, • S0 ⊆ S (S0 = ∅) es el conjunto de estados iniciales; • R ⊆ S × S es una relación binaria total en S, a la que nos referimos como la relación de transición; • A = {1, . . . , n} es un conjunto de agentes; • α: R → A etiqueta cada transición en R con un agente; y • V: S → 2Φ etiqueta cada estado con el conjunto de variables proposicionales verdaderas en ese estado. En aras de la brevedad, de aquí en adelante nos referiremos a un agente etiquetado como estructura de Kripke simplemente como una estructura de Kripke. Un camino sobre una relación de transición R es una secuencia infinita de estados π = s0, s1, . . . que debe cumplir la propiedad de que ∀u ∈ N: (su , su+1) ∈ R. Si u ∈ N, entonces denotamos por π[u] el componente indexado por u en π (así π[0] denota el primer elemento, π[1] el segundo, y así sucesivamente). Un camino π tal que π[0] = s es un camino s. Dejemos que ΠR(s) denote el conjunto de s-caminos sobre R; dado que usualmente será claro en el contexto, a menudo omitimos la referencia a R y simplemente escribimos Π(s). A veces nos referiremos y pensaremos en un s-camino como una posible computación, o evolución del sistema, desde s. EJEMPLO 1. Nuestro ejemplo en ejecución es de un sistema con un recurso no compartible único, el cual es deseado por dos agentes. Considera la estructura de Kripke representada en la Figura 1. Tenemos dos estados, s y t, y dos variables booleanas correspondientes p1 y p2, que son 1. En la literatura de lógica temporal de tiempo de ramificación, se dice que una relación R ⊆ S × S es total si ∀s ∃s : (s, s ) ∈ R. Nótese que a veces se utiliza el término relación total para referirse a relaciones R ⊆ S × S tales que para cada par de elementos s, s ∈ S tenemos o bien (s, s ) ∈ R o bien (s , s) ∈ R; no estamos utilizando el término de esta manera aquí. También vale la pena señalar que para algunos dominios, puede ser más apropiado aplicar otras restricciones en lugar de simplemente la totalidad. Por ejemplo, uno podría considerar el requisito de totalidad del agente, que en cada estado, cada agente tiene al menos una transición posible disponible: ∀s∀i ∈ A∃s : (s, s ) ∈ R y α(s, s ) = i. Pi se puede interpretar como que el agente i tiene actualmente control sobre el recurso. Cada agente tiene dos posibles acciones, cuando posee el recurso: o bien regalarlo o conservarlo. Obviamente hay infinitamente muchos caminos s y caminos t diferentes. Digamos que nuestro conjunto de estados iniciales S0 es igual a {s, t}, es decir, no hacemos ninguna suposición sobre quién tiene inicialmente el control sobre el recurso. 2.1 CTL Ahora definimos la Lógica de Árbol de Computación (CTL), una lógica temporal de tiempo de ramificación destinada a representar las propiedades de las estructuras de Kripke [8]. Ten en cuenta que dado que CTL es bien conocido y ampliamente documentado en la literatura, nuestra presentación, aunque completa, será algo concisa. Utilizaremos CTL para expresar los objetivos de los agentes. La sintaxis de CTL está definida por la siguiente gramática: ϕ ::= | p | ¬ϕ | ϕ ∨ ϕ | E fϕ | E(ϕ U ϕ) | A fϕ | A(ϕ U ϕ) donde p ∈ Φ. Denotamos el conjunto de fórmulas CTL sobre Φ por LΦ; dado que Φ se entiende, generalmente omitimos hacer referencia a ella. La semántica de CTL se da con respecto a la relación de satisfacción |=, que se cumple entre pares de la forma K, s (donde K es una estructura de Kripke y s es un estado en K) y fórmulas del lenguaje. La relación de satisfacción se define de la siguiente manera: K, s |= ; K, s |= p si y solo si p ∈ V (s) (donde p ∈ Φ); K, s |= ¬ϕ si y solo si no K, s |= ϕ; K, s |= ϕ ∨ ψ si y solo si K, s |= ϕ o K, s |= ψ; K, s |= A fϕ si y solo si ∀π ∈ Π(s) : K, π[1] |= ϕ; K, s |= E fϕ si y solo si ∃π ∈ Π(s) : K, π[1] |= ϕ; K, s |= A(ϕ U ψ) si y solo si ∀π ∈ Π(s), ∃u ∈ N, tal que. K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ K, s |= E(ϕ U ψ) si y solo si ∃π ∈ Π(s), ∃u ∈ N, tal que K, π[u] |= ψ y ∀v, (0 ≤ v < u) : K, π[v] |= ϕ Se asume que los conectivos lógicos clásicos restantes (∧, →, ↔) están definidos como abreviaturas en términos de ¬, ∨, de manera convencional. Los operadores temporales CTL restantes están definidos: A♦ϕ ≡ A( U ϕ) E♦ϕ ≡ E( U ϕ) A ϕ ≡ ¬E♦¬ϕ E ϕ ≡ ¬A♦¬ϕ Decimos que ϕ es satisfacible si K, s |= ϕ para alguna estructura de Kripke K y estado s en K; ϕ es válida si K, s |= ϕ para todas las estructuras de Kripke K y estados s en K. El problema de verificar si K, s |= ϕ para un K, s, ϕ dado (verificación de modelos) se puede hacer en tiempo polinómico determinista, mientras que verificar si un ϕ dado es satisfacible o si ϕ es válido es EXPTIME-completo [8]. Escribimos K |= ϕ si K, s0 |= ϕ para todo s0 ∈ S0, y |= ϕ si K |= ϕ para todo K. 882 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 3. SISTEMAS NORMATIVOS Para nuestros propósitos, un sistema normativo es simplemente un conjunto de restricciones sobre el comportamiento de agentes en un sistema [1]. Más precisamente, un sistema normativo define, para cada posible transición del sistema, si esa transición se considera legal o no. Los diferentes sistemas normativos pueden diferir en si una transición es legal o no. Formalmente, un sistema normativo η (con respecto a una estructura de Kripke K = S, S0 , R, A, α, V) es simplemente un subconjunto de R, tal que R \\ η es una relación total. El requisito de que R\\η sea total es una restricción de razonabilidad: evita sistemas normativos que conducen a estados sin sucesor. Sea N (R) = {η : (η ⊆ R) & (R \\ η es total)} el conjunto de sistemas normativos sobre R. La interpretación prevista de un sistema normativo η es que (s, s ) ∈ η significa que la transición (s, s ) está prohibida en el contexto de η; por lo tanto, R \\ η denota las transiciones legales de η. Dado que se asume que η es razonable, se garantiza que existe una transición legal hacia afuera para cada estado. Denotamos el sistema normativo vacío como η∅, por lo tanto, η∅ = ∅. Se debe tener en cuenta que el sistema normativo vacío η∅ es razonable con respecto a cualquier relación de transición R. El efecto de implementar un sistema normativo en una estructura de Kripke es eliminar de ella todas las transiciones que están prohibidas según este sistema normativo (ver [15, 1]). Si K es una estructura de Kripke, y η es un sistema normativo sobre K, entonces K † η denota la estructura de Kripke obtenida a partir de K al eliminar las transiciones prohibidas en η. Formalmente, si K = S, S0, R, A, α, V, y η ∈ N(R), entonces dejemos que K†η = K sea la estructura de Kripke K = S, S0, R, A, α, V donde: • S = S, S0 = S0, A = A, y V = V; • R = R \\ η; y • α es la restricción de α a R: α(s, s') = j α(s, s') si (s, s') ∈ R, indefinido en otro caso. Observa que para todo K, tenemos K † η∅ = K. EJEMPLO 1. (continuación) Al pensar en términos de equidad, parece natural considerar sistemas normativos η que contengan (s, s) o (t, t). Un sistema normativo con (s, t) no sería justo, en el sentido de que A♦A ¬p1 ∨ A♦A ¬p2 se cumple: en todos los caminos, a partir de algún momento, un agente tendrá control para siempre. Para futuras referencias, fijemos η1 = {(s, s)}, η2 = {(t, t)}, y η3 = {(s, s), (t, t)}. Más tarde, abordaremos la cuestión de si los agentes deberían elegir racionalmente cumplir con un sistema normativo particular. En este contexto, es útil definir operadores en sistemas normativos que correspondan a grupos de agentes que se desvían del sistema normativo. Formalmente, sea K = S, S0, R, A, α, V una estructura de Kripke, sea C ⊆ A un conjunto de agentes sobre K, y sea η un sistema normativo sobre K. Entonces: • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que corresponden a las acciones de los agentes en C. Llamamos a η C la restricción de η a C, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Así, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen cumplir con el sistema normativo. • η C denota el sistema normativo que es igual a η excepto que solo contiene los arcos de η que no corresponden a acciones de agentes en C. Llamamos a η C la exclusión de C de η, y se define como: η C = {(s, s ) : (s, s ) ∈ η & α(s, s ) ∈ C}. Por lo tanto, K † (η C) es la estructura de Kripke que resulta si solo los agentes en C eligen no cumplir con el sistema normativo (es decir, los únicos que cumplen son aquellos en A \\ C). Ten en cuenta que tenemos η C = η (A\\C) y η C = η (A\\C). EJEMPLO 1. (Continuación) Tenemos η1 {1} = η1 = {(s, s)}, mientras que η1 {1} = η∅ = η1 {2}. De manera similar, tenemos η3 {1} = {(s, s)} y η3 {1} = {(t, t)}. 4. OBJETIVOS Y UTILIDADES A continuación, queremos ser capaces de capturar los objetivos que tienen los agentes, ya que estos impulsarán las consideraciones estratégicas de un agente, en particular, como veremos, consideraciones sobre si cumplir o no con un sistema normativo. Modelaremos los objetivos de un agente como una lista priorizada de fórmulas CTL, que representan propiedades cada vez más deseadas que el agente desea mantener. La interpretación prevista de una jerarquía de objetivos γi para el agente i ∈ A es que cuanto más arriba esté un objetivo en la jerarquía, más deseado es por i. Ten en cuenta que asumimos que si un agente puede lograr un objetivo en un nivel particular de su jerarquía de objetivos, entonces no le preocupa los objetivos más bajos en la jerarquía. Formalmente, una jerarquía de objetivos, γ, (sobre una estructura de Kripke K) es una secuencia finita y no vacía de fórmulas CTL γ = (ϕ0, ϕ1, . . . , ϕk ) en la que, por convención, ϕ0 = . Utilizamos una notación de indexación de números naturales para extraer los elementos de una jerarquía de objetivos, por lo que si γ = (ϕ0, ϕ1, . . . , ϕk ) entonces γ[0] = ϕ0, γ[1] = ϕ1, y así sucesivamente. Denotamos el índice más grande de cualquier elemento en γ por |γ|. Una estructura Kripke particular K se dice que satisface un objetivo en el índice x en la jerarquía de objetivos γ si K |= γ[x], es decir, si γ[x] se cumple en todos los estados iniciales S0 de K. Una propiedad potencialmente obvia de las jerarquías de objetivos es la monotonicidad: donde los objetivos en niveles más altos en la jerarquía implican lógicamente a los de niveles más bajos en la jerarquía. Formalmente, una jerarquía de objetivos γ es monótona si para todo x ∈ {1, . . . , |γ|} ⊆ N, tenemos |= γ[x] → γ[x − 1]. El tipo más simple de jerarquía de metas monótonas es aquella en la que γ[x + 1] = γ[x] ∧ ψx+1 para algún ψx+1, por lo que en cada nivel sucesivo de la jerarquía, agregamos nuevas restricciones a la meta del nivel anterior. Aunque esta es una propiedad natural de muchas jerarquías de objetivos, no es una propiedad que exigimos de todas las jerarquías de objetivos. EJEMPLO 1. (continuación) Supongamos que los agentes tienen objetivos similares, pero opuestos: cada agente i quiere mantener la fuente para sí mismo tan a menudo y durante tanto tiempo como sea posible. Define la jerarquía de objetivos de cada agente como: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) El objetivo más deseado del agente i es, en cada cálculo, siempre tener el recurso pi (esto se expresa en ϕi 8). Gracias a nuestra restricción de razonabilidad, este objetivo implica ϕi 7, que dice que, sin importar cómo evolucionen los caminos de computación, siempre será que todos The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 883 continuaciones llegarán a un punto en el que pi, y, además, hay una continuación en la que pi siempre se cumple. La meta ϕi 6 es una restricción de equidad implícita en ella. Ten en cuenta que A♦pi dice que cada computación eventualmente llega a un estado pi. Esto puede significar que después de que haya ocurrido pi, nunca volverá a ocurrir. ϕi evita esto: dice que, sin importar dónde te encuentres, debería haber un estado pi futuro. El objetivo ϕi 5 es similar al objetivo fuerte ϕi 8, pero acepta que esto solo se logra en algunas computaciones, eventualmente. ϕi 4 requiere que en cada camino, siempre haya una continuación que eventualmente dé pi. La meta ϕi 3 dice que pi debería ser verdadero en alguna rama, a partir de algún momento. Implica ϕi 2, lo cual expresa que hay un cálculo tal que en todo momento durante él, es posible elegir una continuación que eventualmente satisfaga pi. Esto implica ϕi 1, lo cual indica que pi al menos no debería ser imposible. Si incluso eliminamos esa demanda, tenemos el objetivo trivial ϕi 0. Observamos que puede parecer más natural expresar una restricción de equidad ϕi 6 como A ♦pi. Sin embargo, esta no es una fórmula CTL adecuada. De hecho, es una fórmula en CTL ∗ [9], y en esta lógica, las dos expresiones serían equivalentes. Sin embargo, nuestros resultados de <br>complejidad</br> básica en las siguientes secciones no se aplicarían al lenguaje más rico CTL ∗2, y el precio a pagar por esto es que debemos formular nuestros objetivos deseados de una manera algo más engorrosa de lo que idealmente nos gustaría. Por supuesto, nuestro marco básico no exige que los objetivos se expresen en CTL; igualmente podrían expresarse en CTL ∗ o incluso en ATL [2] (como en [15]). Comentaremos sobre las implicaciones de las representaciones alternativas de objetivos al concluir la siguiente sección. Un sistema multiagente reúne una estructura de Kripke (que representa las propiedades básicas de un sistema en consideración: su espacio de estados y las posibles transiciones de estado que pueden ocurrir en él), junto con una jerarquía de objetivos, una para cada agente, que representa las aspiraciones de los agentes en el sistema. Formalmente, un sistema multiagente, M, es una n-tupla (n + 1): M = K, γ1, . . . , γn donde K es una estructura de Kripke, y para cada agente i en K, γi es una jerarquía de objetivos sobre K. 4.1 La utilidad de los sistemas normativos Ahora podemos definir la utilidad de una estructura de Kripke para un agente. La idea es que la utilidad de una estructura de Kripke es el índice más alto de cualquier objetivo que esté garantizado para ese agente en la estructura de Kripke. Hacemos esto preciso en la función ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Nótese que utilizando estas definiciones de metas y utilidad, nunca tiene sentido tener una meta ϕ en el índice n si hay una meta lógicamente más débil ψ en el índice n + k en la jerarquía: por definición de utilidad, nunca podría ser n para ninguna estructura K. EJEMPLO 1. (continuación) Sea M = K, γ1, γ2 el sistema multiagente de la Figura 1, con γ1 y γ2 como se definió anteriormente en este ejemplo. Recuerde que hemos definido S0 como {s, t}. Entonces, u1(K) = u2(K) = 4: el objetivo ϕ4 es verdadero en S0, pero ϕ5 no lo es. Para ver que ϕ2 4 = A E♦p2 es verdadero en s, por ejemplo: observe que en cada camino siempre es el caso que hay una transición a t, en la cual p2 es verdadero. Observa que dado que para cualquier jerarquía de objetivos γi tenemos γ[0] = , entonces para todas las estructuras de Kripke, ui (K) está bien definido, con ui (K) ≥ 2. El modelado de verificación de modelos CTL ∗ es PSPACE-completo, y por lo tanto mucho peor (bajo suposiciones estándar de <br>complejidad</br> teórica) que la verificación de modelos CTL [8]. η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figura 2: Beneficios de implementar un sistema normativo η (izquierda) y pagos para el juego ΣM. 0. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}