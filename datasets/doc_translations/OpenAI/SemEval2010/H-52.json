{
    "id": "H-52",
    "original_text": "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings. Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index. However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected. In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically. Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts. We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts. A speech recognizer generates word confusion networks and phonetic lattices. The transcripts are indexed for query processing and ranking purpose. The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1]. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1. INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data. The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool. In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts. Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12]. These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals. One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts. While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data. In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12]. However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results. OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model. It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary. The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28]. In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated. Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones. The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts. The main drawback of this approach is the inherent high error rate of the transcripts. Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system. A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms. We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms. Consequently, we need to merge pieces of information retrieved from word index and phonetic index. Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking. In classical IR, the index stores for each occurrence of a term, its offset. Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable. The only element of comparison between phonetic and word transcripts are the timestamps. No previous work combining word and phonetic approach has been done on phrase search. We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp. We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms. We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1]. The paper is organized as follows. We describe the audio processing in Section 2. The indexing and retrieval methods are presented in section 3. Experimental setup and results are given in Section 4. In Section 5, we give an overview of related work. Finally, we conclude in Section 6. 2. AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data. It works in speaker-independent mode. For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics. Typically, ASR generates lattices that can be considered as directed acyclic graphs. Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis. The 1-best path transcript is obtained from the lattice using dynamic programming techniques. Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN). Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal. One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice. As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1. Compute the posterior probabilities for all edges in the word lattice. 2. Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3. Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities. The 1-best path of a WCN is obtained from the path containing the best hypotheses. As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice. Typical structures of a lattice and a WCN are given in Figure 1. Figure 1: Typical structures of a lattice and a WCN. 3. RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words. Generally, the accuracy of a word transcript is characterized by its word error rate (WER). There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech. Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized. These misses reduce the recall of the search. Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript. These misses reduce the precision of the search. Search recall can be enhanced by expanding the transcript with extra words. These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR. Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision. Using an appropriate ranking model, we can avoid the decrease in precision. Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval. We have adapted this model of IV search to term detection. In word transcripts, OOV terms are deleted or substituted. Therefore, the usage of phonetic transcripts is more desirable. However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices. We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data. A query is a phrase containing several words. The queries are text and not speech. Note that this task is different from the more classical task of spoken document retrieval. Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences. By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech. For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts. Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u. In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D). Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above. The terms are extracted from the query. The vocabulary of the ASR system building word transcripts is given. Terms that are part of this vocabulary are IV terms; the other terms are OOV. For an IV query term, the posting list is extracted from the word index. For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10]. For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy). The posting list of each phone is extracted from the phonetic index. The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query. First, we check that the words and phones appear in the right order according to their begin times. Second, we check that the gap in time between adjacent words and phones is reasonable. Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds. For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically. In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones. Our query processing does not allow substitutions and deletions. Example: Let us consider the phrase query prosody research. The term prosody is OOV and the term research is IV. The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy). The posting list of each phone is extracted from the phonetic index. We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds. We obtain occurrences of the term prosody. The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds. Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index. The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices. The STD evaluation has focused on the fourth query type. It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms. Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences. Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj). This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1. If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection. We use the information provided by the word index. We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index. We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other. We define a scoring function that is related to the average gap in time between the different phones. Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ). We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1. The duration of the keyword occurrence is tk l − tk 0 + dk l . Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence. For each phone, we give the begin time and the duration in second. Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01). Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01). According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1. In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy. The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec. Our goal is to estimate for each found occurrence how likely the query appears. It is different from classical IR that aims to rank the results and not to score them. Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase. We have determined empirically the value of γn = 1/n. The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4. EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1]. It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG). As shown in Section 4.2, these different collections have different accuracies. CTS and CONFMTG are spontaneous speech. For the experiments, we have processed the query set provided by NIST that includes 1100 queries. Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not. Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST. We have used the IBM research prototype ASR system, described in [26], for transcribing speech data. We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy. We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3. For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct. We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts. Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data. Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be. The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores. This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17]. Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV). The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold. For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 . Therefore, β = 999.9. Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials. It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q). Tspeech is the total amount of speech in the collection (in seconds). ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence. It ranges from −∞ to +1. MTWV is the maximum term-weighted value over the range of all possible values of θ. It ranges from 0 to +1. We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A). We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve. We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts. WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively. The substitution error rate (SUBR) is defined by S S + D + I × 100. Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner. Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs. The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts. That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall. The value of the threshold θ per source type is reported in Table 2. It is correlated to the accuracy of the transcripts. Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses. The higher the WER is, the higher the θ threshold should be. BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile. Concerning the index size, note that our index is compressed using IR index compression techniques. The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices. Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech. HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic). The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN. WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems. Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4. We provide also the DET curve for WCN phonetic approach in Figure 2. The point that maximizes the TWV, the MTWV, is specified on each curve. Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2. As expected, we can see that MTWV and ATWV decrease in higher WER. The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type. Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path. It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs. This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval. The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score. Therefore, the effect of false alarms added by WCNs is reduced. WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants. For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts. The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration. We can see that we performed better on longer queries. One of the reasons is the fact that the ASR system is more accurate on long words. Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms. The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system. We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices. Table 6 summarizes the retrieval performance according to each approach and to each type of queries. Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null. Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach. As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries. This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5. RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents. Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12]. An LVCSR system is used to transcribe the speech into 1-best path word transcripts. The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index. A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14]. This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners). Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors. An alternative approach consists of using word lattices in order to improve the effectiveness of SDR. Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors. From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus. Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript. The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities. Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL). This data structure is similar to WCN and leads to a more compact index. The offset of the terms in the speech documents is also stored in the index. However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech. Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses. Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search. However, in the above works, the problem of queries containing OOV terms is not addressed. Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23]. The classical approach consists of using phonetic transcripts. The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones. The retrieval is based on searching the string of phones representing the query in the phonetic transcript. To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices. They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27]. However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index. Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate. Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach. Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived. They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index. However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms. Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval. However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data. An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms. This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6. CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources. Previously, phonetic-based and word-based approaches have been used for IR on speech data. The former suffers from low accuracy and the latter from limited vocabulary of the recognition system. In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches. The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index. The scoring of OOV terms is based on the proximity (in time) between the different phones. The scoring of IV terms is based on information provided by the WCNs. We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms. This approach always outperforms the other approaches using only word index or phonetic index. As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7. ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8. REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar. General indexation of weighted automata - application to spoken utterance retrieval. In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter. Mutual relevance feedback for multimodal query formulation in video retrieval. In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005. ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan. Advances in phonetic word spotting. In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001. ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young. Open-vocabulary speech indexing for voice and video mail retrieval. In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer. Juru at TREC 10Experiments with Index Pruning. In Proceedings of the Tenth Text Retrieval Conference (TREC-10). National Institute of Standards and Technology. NIST, 2001. [8] C. Chelba and A. Acero. Indexing uncertainty for spoken document search. In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero. Position specific posterior lattices for indexing speech. In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen. Conditional and joint models for grapheme-to-phoneme conversion. In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller. Phonetic searching applied to on-line distance learning modules. In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop. Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees. The TREC spoken document retrieval track: A success story. In Proceedings of the Ninth Text Retrieval Conference (TREC-9). National Institute of Standards and Technology. NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi. A general algorithm for word graph matrix decomposition. In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James. The application of classical information retrieval techniques to spoken documents. PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James. A system for unrestricted topic retrieval from radio news broadcasts. In Proc. ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker. An experimental study of an audio indexing system for the web. In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory. Spoken document retrieval from call-center conversations. In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006. ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke. Finding consensus in speech recognition: word error minimization and other applications of confusion networks. Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki. The DET curve in assessment of detection task performance. In Proc. Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue. Subword-based approaches for spoken document retrieval. Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide. Fast two-stage vocabulary-independent search in spontaneous speech. In Acoustics, Speech, and Signal Processing. Proceedings. (ICASSP). IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat. Lattice-based search for spoken utterance retrieval. In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang. Vocabulary-independent search in spontaneous speech. In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira. AT&T at TREC-7. In Proceedings of the Seventh Text Retrieval Conference (TREC-7). National Institute of Standards and Technology. NIST, 1999. [25] A. Singhal and F. Pereira. Document expansion for speech retrieval. In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999. ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig. The IBM 2004 conversational telephony system for rich transcription. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan. Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting. In Acoustics, Speech, and Signal Processing. Proceedings. (ICASSP). IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones. Effects of out of vocabulary words in spoken document retrieval (poster session). In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000. ACM Press.",
    "original_translation": "Vocabulary Detección de término hablado independiente Jonathan Mamou Ibm Haifa Investigation Labs Haifa 31905, Israel mamuu@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan Ibm T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {Bhuvana, Siohan@Us.ibm.Resumen Estamos interesados en recuperar información de datos del habla como noticias de transmisión, conversaciones telefónicas y reuniones de mesa redonda. Hoy en día, la mayoría de los sistemas utilizan grandes herramientas de reconocimiento de voz continuo de vocabulario para producir transcripciones de palabras;Las transcripciones se indexan y los términos de consulta se recuperan del índice. Sin embargo, los términos de consulta que no son parte del vocabulario de los reconocedores no se pueden recuperar, y el retiro de la búsqueda se ve afectado. Además de la transcripción de palabras de salida, los sistemas avanzados proporcionan también transcripciones fonéticas, contra las cuales los términos de consulta pueden coincidir fonéticamente. Dichas transcripciones fonéticas sufren de menor precisión y no pueden ser una alternativa a las transcripciones de palabras. Presentamos un sistema independiente de vocabulario que puede manejar consultas arbitrarias, explotando la información proporcionada al tener transcripciones de palabras y transcripciones fonéticas. Un reconocimiento de voz genera redes de confusión de palabras y redes fonéticas. Las transcripciones están indexadas para el procesamiento de consultas y el propósito de clasificación. El valor del método propuesto se demuestra por el alto rendimiento relativo de nuestro sistema, que recibió la clasificación general más alta para los datos del habla en inglés de EE. UU. En la reciente evaluación de detección de términos hablados NIST [1]. Categorías y descriptores de asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información Términos generales Algoritmos 1. INTRODUCCIÓN La cantidad rápida y creciente de datos hablados requiere soluciones para indexar y buscar estos datos. El enfoque clásico consiste en convertir las transcripciones de discurso a palabras utilizando una gran herramienta de reconocimiento de voz continuo de vocabulario (LVCSR). En la última década, la mayoría de los esfuerzos de investigación en la recuperación de datos hablados se han centrado en extender las técnicas clásicas de IR a las transcripciones de palabras. Algunos de estos trabajos se han realizado en el marco de las pistas de recuperación de documentos hablados de NIST TREC y son descritos por Garofolo et al.[12]. Estas pistas se centraron en la recuperación de un corpus de noticias de transmisión habladas por profesionales. Una de las conclusiones de esas pistas fue que la efectividad de la recuperación depende principalmente de la precisión de las transcripciones. Si bien la precisión de los sistemas de reconocimiento de voz automático (ASR) depende del escenario y el entorno, los sistemas de vanguardia alcanzaron una precisión de más del 90% en la transcripción de dichos datos. En 2000, Garofolo et al.concluyó que la recuperación de documentos hablados es un problema resuelto [12]. Sin embargo, un inconveniente significativo de tales enfoques es que la búsqueda en consultas que contienen términos fuera del vocabulario (OOV) no devolverán ningún resultado. Los términos de OOV faltan palabras del vocabulario del sistema ASR y se reemplazan en la transcripción de salida por alternativas que son probables, dado el modelo acústico de reconocimiento y el modelo de lenguaje. Se ha observado experimentalmente que más del 10% de las consultas de los usuarios pueden contener términos de OOV [16], ya que las consultas a menudo se relacionan con entidades nombradas que generalmente tienen una cobertura deficiente en el vocabulario ASR. Los efectos de los términos de consulta de OOV en la recuperación de datos hablados son discutidos por Woodland et al.[28]. En muchas aplicaciones, la tasa de OOV puede empeorar con el tiempo a menos que el vocabulario de los reconocedores se actualice periódicamente. Otro enfoque consiste en convertir el discurso en transcripciones fonéticas y representar la consulta como una secuencia de teléfonos. La recuperación se basa en la búsqueda de la secuencia de teléfonos que representan la consulta en las transcripciones fonéticas. El principal inconveniente de este enfoque es la alta tasa de error inherente de las transcripciones. Por lo tanto, dicho enfoque no puede ser una alternativa a las transcripciones de palabras, especialmente para los términos de consulta in-vocabulario (iv) que forman parte del vocabulario del sistema ASR. Una solución sería combinar los dos enfoques diferentes presentados anteriormente: indexamos ambas transcripciones de palabras y transcripciones fonéticas;Durante el procesamiento de la consulta, la información se recupera del índice de palabras para términos IV y del índice fonético para términos OOV. Nos gustaría poder procesar también consultas híbridas, es decir, consultas que incluyen términos IV y OOV. En consecuencia, necesitamos fusionar piezas de información recuperadas del índice de palabras y el índice fonético. La información de proximidad sobre los ocurrencias de los términos de consulta se requiere para la búsqueda de frases y para la clasificación basada en la proximidad. En el IR clásico, las tiendas índice para cada ocurrencia de un término, su compensación. Por lo tanto, no podemos fusionar listas de publicación recuperadas por índice fonético con las recuperadas por el índice de palabras ya que el desplazamiento de los ocurrencias recuperados de los dos índices diferentes no es comparable. El único elemento de comparación entre transcripciones fonéticas y de palabras son las marcas de tiempo. No se ha realizado ningún trabajo previo que combine palabras y enfoque fonético en la búsqueda de frases. Presentamos un esquema novedoso para la recuperación de información que consiste en el almacenamiento, durante el proceso de indexación, para cada unidad de indexación (teléfono o palabra) su marca de tiempo. Buscamos consultas fusionando la información recuperada de los dos índices diferentes, índice de palabras e índice fonético, de acuerdo con las marcas de tiempo de los términos de la consulta. Analizamos la efectividad de la recuperación de este enfoque en los datos de evaluación de detección de términos hablados de NIST [1]. El papel está organizado de la siguiente manera. Describimos el procesamiento de audio en la Sección 2. Los métodos de indexación y recuperación se presentan en la Sección 3. La configuración experimental y los resultados se dan en la Sección 4. En la Sección 5, damos una visión general del trabajo relacionado. Finalmente, concluimos en la Sección 6. 2. Sistema automático de reconocimiento de voz Utilizamos un sistema ASR para transcribir datos del habla. Funciona en modo independiente del altavoz. Para los mejores resultados de reconocimiento, un modelo acústico independiente del hablante y un modelo de lenguaje están entrenados de antemano en datos con características similares. Por lo general, ASR genera redes que pueden considerarse como gráficos acíclicos dirigidos. Cada vértice en una red se asocia con una marca de tiempo y cada borde (u, v) está etiquetado con una hipótesis de palabra o teléfono y su probabilidad previa, que es la probabilidad de la señal delimitada por las marcas de tiempo de los vértices u y v, dado.la hipótesis. La mejor transcripción de ruta se obtiene de la red utilizando técnicas de programación dinámica. Mangu et al.[18] y Hakkani-Tur et al.[13] propone una representación compacta de una red de palabras llamada red de confusión de palabras (WCN). Cada borde (U, V) está etiquetado con una hipótesis de la palabra y su probabilidad posterior, es decir, la probabilidad de la palabra dada la señal. Una de las principales ventajas de WCN es que también proporciona una alineación para todas las palabras en la red. Como se explica en [13], los tres pasos principales para construir un WCN a partir de una red de palabras son los siguientes: 1. Calcule las probabilidades posteriores para todos los bordes en la palabra red.2. Extraiga una ruta de la palabra red (que puede ser el 1 mejor, el más largo o cualquier ruta aleatoria), y llamarlo la ruta pivote de la alineación.3. Visite la palabra red, y alinee todas las transiciones con el pivote, fusionando las transiciones que corresponden a la misma palabra (o etiqueta) y ocurren en el mismo intervalo de tiempo sumando sus probabilidades posteriores. La mejor ruta de un WCN se obtiene de la ruta que contiene las mejores hipótesis. Como se indica en [18], aunque los WCN son más compactos que las redes de palabras, en general, la mejor ruta obtenida de WCN tiene una mejor precisión de la palabra que la ruta de 1 mejor obtenida de la red de palabras correspondiente. Las estructuras típicas de una red y un WCN se dan en la Figura 1. Figura 1: Estructuras típicas de una red y un WCN.3. Modelo de recuperación El principal problema con la recuperación de la información de los datos hablados es la baja precisión de la transcripción, particularmente en términos de interés, como entidades nombradas y palabras de contenido. En general, la precisión de una transcripción de Word se caracteriza por su tasa de error de palabras (WER). Hay tres tipos de errores que pueden ocurrir en una transcripción: sustitución de un término que es parte del discurso por otro término, la eliminación de un término hablado que es parte del discurso y la inserción de un término que no es parte del discurso. Las sustituciones y deleciones reflejan el hecho de que no se reconoce una ocurrencia de un término en la señal del habla. Estas fallas reducen el retiro de la búsqueda. Las sustituciones e inserciones reflejan el hecho de que un término que no es parte de la señal del habla aparece en la transcripción. Estas fallas reducen la precisión de la búsqueda. El retiro de búsqueda se puede mejorar expandiendo la transcripción con palabras adicionales. Estas palabras se pueden tomar de las otras alternativas proporcionadas por el WCN;Es posible que estas alternativas se hayan hablado, pero no fueron la mejor opción del ASR. Tal expansión tiende a corregir las sustituciones y las deleciones y, en consecuencia, podría mejorar el recuerdo, pero probablemente reducirá la precisión. Usando un modelo de clasificación apropiado, podemos evitar la disminución de la precisión. Mamou et al.han presentado en [17] la mejora en el retiro y el mapa buscando en WCN en lugar de considerar solo la 1 mejor transcripción de palabras de ruta en el contexto de la recuperación de documentos hablados. Hemos adaptado este modelo de búsqueda IV a la detección de términos. En las transcripciones de palabras, los términos de OOV se eliminan o se sustituyen. Por lo tanto, el uso de transcripciones fonéticas es más deseable. Sin embargo, debido a su baja precisión, hemos preferido usar solo la mejor ruta extraída de las redes fonéticas. Mostraremos que el uso de transcripciones fonéticas tiende a mejorar el retiro sin afectar demasiado la precisión, utilizando una clasificación apropiada.3.1 Tarea de detección de documentos hablados Como se indica en el Plan de Evaluación STD 2006 [2], la tarea consiste en encontrar todas las coincidencias exactas de una consulta específica en un corpus determinado de datos del habla. Una consulta es una frase que contiene varias palabras. Las consultas son texto y no del habla. Tenga en cuenta que esta tarea es diferente de la tarea más clásica de la recuperación de documentos hablados. Las transcripciones manuales del discurso no son proporcionadas, pero los evaluadores utilizan para encontrar verdaderos acontecimientos. Por definición, las verdaderas ocurrencias de una consulta se encuentran automáticamente buscando las transcripciones manuales utilizando la siguiente regla: la brecha entre las palabras adyacentes en una consulta debe ser inferior a 0.5 segundos en el discurso correspondiente. Para evaluar los resultados, cada ocurrencia de salida del sistema se considera correcta o no de acuerdo con si está cerca en el tiempo a una verdadera ocurrencia de la consulta recuperada de las transcripciones manuales;Se juzga como correcto si el punto medio de la ocurrencia de salida del sistema es menor o igual a 0.5 segundos desde el período de tiempo de una verdadera ocurrencia de la consulta.3.2 Indexación Hemos utilizado el mismo proceso de indexación para WCN y transcripciones fonéticas. Cada aparición de una unidad de indexación (palabra o teléfono) U en una transcripción d se indexa con la siguiente información: • El tiempo de inicio t de la ocurrencia de u, • la duración d de la ocurrencia de u. Además, para la indexación de WCN, almacenamos • El nivel de confianza de la aparición de U en el momento t que se evalúa por su probabilidad posterior PR (U | T, D), • El rango de la ocurrencia de U entre las otras hipótesiscomenzando al mismo tiempo t, rango (u | t, d). Tenga en cuenta que, dado que la tarea es encontrar coincidencias exactas de las consultas de frases, no hemos filtrado palabras de parada y el corpus no tiene vistas antes de indexar.3.3 Búsqueda a continuación, presentamos nuestro enfoque para lograr la tarea STD utilizando los índices descritos anteriormente. Los términos se extraen de la consulta. Se da el vocabulario de las transcripciones de palabras de construcción del sistema ASR. Los términos que forman parte de este vocabulario son términos IV;Los otros términos son OOV. Para un término de consulta IV, la lista de publicación se extrae del índice de palabras. Para un término de consulta OOV, el término se convierte en una secuencia de teléfonos utilizando un modelo de n-gram de entropía máxima articular [10]. Por ejemplo, el término prosodia se convierte en la secuencia de teléfonos (P, R, Aa, Z, Ih, D, Iy). La lista de publicación de cada teléfono se extrae del índice fonético. El siguiente paso consiste en fusionar las diferentes listas de publicación de acuerdo con la marca de tiempo de los ocurrencias para crear resultados que coincidan con la consulta. Primero, verificamos que las palabras y los teléfonos aparecen en el orden correcto de acuerdo con sus tiempos de comienzo. En segundo lugar, verificamos que la brecha en el tiempo entre palabras y teléfonos adyacentes sea razonable. Continuación de los requisitos de la evaluación de STD, la distancia en el tiempo entre dos términos de consulta adyacentes debe ser inferior a 0.5 segundos. Para la búsqueda de OOV, verificamos que la distancia en el tiempo entre dos teléfonos adyacentes de un término de consulta es menor que 0.2 segundos;Este valor se ha determinado empíricamente. De tal manera, podemos reducir el efecto de los errores de inserción, ya que permitimos inserciones entre las palabras y los teléfonos adyacentes. Nuestro procesamiento de consultas no permite sustituciones y deleciones. Ejemplo: consideremos la investigación de la prosodia de la consulta de frases. El término prosodia es OOV y el término investigación es IV. El término prosodia se convierte en la secuencia de teléfonos (P, R, A, Z, In, Diy). La lista de publicación de cada teléfono se extrae del índice fonético. Fusionamos las listas de publicación de los teléfonos de tal manera que la secuencia de teléfonos aparece en el orden correcto y la brecha en el tiempo entre los pares de teléfonos (P, R), (R, AA), (AA, Z), (Z, (Z,ih), (ih, d), (d, iy) es inferior a 0.2 segundos. Obtenemos ocurrencias del término prosodia. La lista de publicación de la investigación se extrae del índice de palabras y la fusionamos con los ocurrencias que se encuentran para la prosodia de tal manera que aparecen en el orden correcto y la distancia en el tiempo entre la prosodia y la investigación es inferior a 0.5 segundos. Tenga en cuenta que nuestro modelo de indexación permite buscar diferentes tipos de consultas: 1. Consultas que contienen solo términos IV utilizando el índice de palabras.2. Consultas que contienen solo términos OOV utilizando el índice fonético.3. Consultas de palabras clave que contienen términos IV y OOV utilizando el índice de palabras para términos IV y el índice fonético para términos OOV;Para el procesamiento de consultas, los diferentes conjuntos de coincidencias se unifican si los términos de consulta tienen o semántica e se cruzan si los términos de consulta tienen y semántica.4. Consultas de frases que contienen términos IV y OOV;Para el procesamiento de consultas, las listas de publicación de los términos IV recuperados del índice de palabras se fusionan con las listas de publicación de los términos OOV recuperados del índice fonético. La fusión es posible ya que hemos almacenado las marcas de tiempo para cada unidad de indexación (palabra y teléfono) en ambos índices. La evaluación de STD se ha centrado en el cuarto tipo de consulta. Es la tarea más difícil ya que necesitamos combinar listas de publicación recuperadas de los índices fonéticos y de palabras.3.4 Ranking Dado que los términos IV y los términos OOV se recuperan de dos índices diferentes, proponemos dos funciones diferentes para obtener una ocurrencia de un término;Posteriormente, se asigna un puntaje agregado a la consulta en función de los puntajes de los términos de consulta. Debido a que la tarea es la detección de términos, no utilizamos un criterio de frecuencia de documento para clasificar los ocurrencias. Consideremos una consulta q = (k0, ..., kn), asociada con un vector de impulso b = (b1, ..., bj). Este vector asocia un factor de impulso a cada rango de las diferentes hipótesis;Los factores de aumento se normalizan entre 0 y 1. Si el rango R es más grande que J, suponemos BR = 0. 3.4.1 En la clasificación de término de vocabulario para la clasificación de términos IV, extendemos el trabajo de Mamou et al.[17] Sobre la recuperación de documentos hablados a la detección de términos. Utilizamos la información proporcionada por el índice Word. Definimos la puntuación de puntaje (k, t, d) de una palabra clave k que ocurre a una vez t en la transcripción d, por la siguiente fórmula: puntaje (k, t, d) = brank (k | t, d) × pr pr)(k | t, d) Tenga en cuenta que 0 ≤ puntaje (k, t, d) ≤ 1. 3.4.2 Fuera de la clasificación de términos de vocabulario para la clasificación de términos OOV, utilizamos la información proporcionada por el índice fonético. Le damos un rango más alto a ocurrencias de términos OOV que contienen teléfonos cerca (con el tiempo) entre sí. Definimos una función de puntuación relacionada con la brecha promedio en el tiempo entre los diferentes teléfonos. Consideremos una palabra clave K convertida a la secuencia de teléfonos (PK 0, ..., PK L). Definimos el puntaje de puntaje normalizado (k, tk 0, d) de una palabra clave k = (pk 0, ..., pk l), donde cada PK I ocurre en el tiempo TK I con una duración de DK I en la transcripción D, mediante la siguiente fórmula: puntaje (k, tk 0, d) = 1-l i = 1 5 × (tk i-(tk i-1 + dk i-1)). Tenga en cuenta que de acuerdo con lo que hemos sido exigidoEn la Sección 3.3, tenemos ∀1 ≤ I ≤ L, 0 <tk I - (tk i - 1 + dk i - 1) <0.2 segundos, 0 <5 × (tk i - (tk i - 1 + dk i−1)) <1, y en consecuencia, 0 <puntaje (k, tk 0, d) ≤ 1. La duración de la aparición de palabras clave es tk l - tk 0 + dk l. Ejemplo: consideremos la secuencia (P, R, Aa, Z, Ih, D, Iy) y dos ocurrencias diferentes de la secuencia. Para cada teléfono, damos el tiempo de inicio y la duración en segundo lugar. Ocurrencia 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01). Ocurrencia 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01). Según nuestra fórmula, la puntuación de la primera ocurrencia es 0.83 y la puntuación de la segunda ocurrencia es 1. En la primera ocurrencia, probablemente haya cierta inserción o silencio entre los teléfonos P y R, y entre el teléfono D e iy. El silencio puede deberse al hecho de que los teléfonos pertenecen a dos palabras diferentes y, por lo tanto, no es una ocurrencia del término prosodia.3.4.3 Combinación La puntuación de una ocurrencia de una consulta Q en el tiempo T0 en el documento D se determina mediante la multiplicación de la puntuación de cada palabra clave KI, donde cada ki ocurre en el tiempo TI con una duración DI en la transcripción d: puntaje(Q, t0, d) = n i = 0 puntaje (ki, ti, d) γn Tenga en cuenta que de acuerdo con lo que hemos aplazado en la sección 3.3, tenemos ∀1 ≤ i ≤ n, 0 <ti-(ti-1 +di - 1) <0.5 seg. Nuestro objetivo es estimar para cada ocurrencia que se encuentra en la probabilidad de que aparezca la consulta. Es diferente del IR clásico que tiene como objetivo clasificar los resultados y no obtenerlos. Dado que la probabilidad de tener una falsa alarma es inversamente proporcional a la longitud de la consulta de la frase, hemos aumentado el puntaje de consultas por un exponente γN, que está relacionado con el número de palabras clave en la frase. Hemos determinado empíricamente el valor de γn = 1/n. El tiempo de inicio de la ocurrencia de la consulta se determina por el tiempo de inicio T0 del primer término de consulta y la duración de la ocurrencia de consulta por tn - t0 + dn.4. Experimentos 4.1 Configuración experimental Nuestro corpus consiste en el conjunto de evaluación proporcionado por NIST para la evaluación STD 2006 [1]. Incluye tres tipos de fuente diferentes en inglés de EE. UU.: Tres horas de noticias de transmisión (BNEWS), tres horas de discurso de telefonía conversacional (CTS) y dos horas de reuniones de la sala de conferencias (ConfMTG). Como se muestra en la Sección 4.2, estas diferentes colecciones tienen diferentes precisiones. CTS y ConfMTG son un discurso espontáneo. Para los experimentos, hemos procesado el conjunto de consultas proporcionado por NIST que incluye 1100 consultas. Cada consulta es una frase que contiene entre uno a cinco términos, términos comunes y raros, términos que están en las transcripciones manuales y las que no lo son. La prueba y la determinación de los valores empíricos se han logrado en otro conjunto de datos y consultas del habla, el conjunto de desarrollo, también proporcionado por NIST. Hemos utilizado el sistema ASR de IBM Research Prototype, descrito en [26], para transcribir datos del habla. Hemos producido WCN para los tres tipos de fuentes diferentes.Las mejores transcripciones fonéticas se generaron solo para BNEW y CTS, ya que las transcripciones fonéticas ConfMTG tienen una precisión demasiado baja. Hemos adaptado Juru [7], una biblioteca de búsqueda de texto completo escrita en Java, para indexar las transcripciones y almacenar las marcas de tiempo de las palabras y teléfonos;Los resultados de la búsqueda se han recuperado como se describe en la Sección 3. Para cada ocurrencia de la consulta dada, nuestro sistema sale: la ubicación del término en el registro de audio (comienza el tiempo y la duración), la puntuación que indica qué tan probable es la aparición de consulta (como se define en la Sección 3.4) y una dura(binaria) decisión sobre si la detección es correcta. Medimos la precisión y el recuerdo comparando los resultados obtenidos sobre las transcripciones automáticas (solo los resultados que tienen una decisión dura verdadera) con los resultados obtenidos sobre las transcripciones manuales de referencia. Nuestro objetivo es evaluar la capacidad del enfoque de recuperación sugerido para manejar los datos del habla transcritos. Por lo tanto, cuanto más cerca sean los resultados automáticos de los resultados manuales, mejor será la efectividad de búsqueda sobre las transcripciones automáticas. Los resultados devueltos de la transcripción manual para una consulta dada se consideran relevantes y se espera que se recuperen con los puntajes más altos. Este enfoque para medir la efectividad de la búsqueda utilizando datos manuales como referencia es muy común en la investigación de recuperación del habla [25, 22, 8, 9, 17]. Además del retiro y la precisión, utilizamos las medidas de evaluación definidas por NIST para la evaluación de STD de 2006 [2]: el valor real ponderado por término (ATWV) y el valor máximo ponderado (MTWV). El valor ponderado por el término (TWV) se calcula primero calculando las probabilidades de falsa y falsa alarma para cada consulta por separado, luego utilizando estos y una probabilidad previa (elegida arbitrariamente) para calcular valores específicos de la consulta, y finalmente promediando estos valores específicos de la consultaSobre todas las consultas Q para producir un valor general del sistema: TWV (θ) = 1 - promedioq {pmiss (q, θ) + β × pf a (q, θ)} donde β = c v (pr - 1 q - 1).θ es el umbral de detección. Para la evaluación, la relación costo/valor, C/V, se ha determinado a 0.1 y la probabilidad previa de una consulta PRQ a 10−4. Por lo tanto, β = 999.9. Las probabilidades de falsa y falsa alarma para una consulta dada Q son funciones de θ: pmiss (q, θ) = 1 - ncorrect (q, θ) ntrue (q) pf a (q, θ) = nspurious (q, θ) nnt (q) Corpus Wer (%) Subr (%) delr (%) INSR (%) BNews WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 Confmtg WCN 47.4 47 49 3 Tabla 1: Wer y distribución de los tipos de error sobre la palabra 1-Capasa ruta extraída de WCN para los diferentes tipos de fuente.donde: • nCorrect (Q, θ) es el número de detecciones correctas (recuperadas por el sistema) de la consulta Q con una puntuación mayor o igual a θ.• Nspurious (Q, θ) es el número de detecciones espurias de la consulta Q con una puntuación mayor o igual a θ.• Ntrue (Q) es el número de ocurrencias verdaderas de la consulta Q en el corpus.• NNT (Q) es el número de oportunidades para la detección incorrecta de la consulta Q en el corpus;Son las pruebas de consulta no objetivo. Se ha definido mediante la siguiente fórmula: Nnt (Q) = TsPeech - Ntrue (Q). Tspech es la cantidad total de discurso en la colección (en segundos). ATWV es el valor real ponderado por término;Es el valor de detección alcanzado por el sistema como resultado de la salida del sistema y la salida de decisión binaria para cada supuesto ocurrencia. Varía de −∞ a +1. MTWV es el valor máximo ponderado a término en el rango de todos los valores posibles de θ. Varía de 0 a +1. También hemos proporcionado la curva de compensación de errores de detección (DET) [19] de la probabilidad de Miss (PMIS) frente a la probabilidad de falsa alarma (PF A). Hemos utilizado la herramienta Stdeval para extraer los resultados relevantes de las transcripciones manuales y para calcular ATWV, MTWV y la curva DET. Hemos determinado empíricamente los siguientes valores para el vector de impulso definido en la Sección 3.4: Bi = 1 i.4.2 Análisis WER Utilizamos la tasa de error de la palabra (WER) para caracterizar la precisión de las transcripciones. Wer se define de la siguiente manera: S + D + I n × 100 donde n es el número total de palabras en el corpus, y S, I y D son el número total de errores de sustitución, inserción y eliminación, respectivamente. La tasa de error de sustitución (SUBR) se define por S S + D + I × 100. La tasa de error de eliminación (Delr) y la tasa de error de inserción (INSR) se definen de manera similar. La Tabla 1 proporciona el WER y la distribución de los tipos de error sobre las transcripciones de la ruta de 1 mejor extraídas de WCN. El WER de las transcripciones fonéticas de 1 mejor ruta es aproximadamente dos veces peor que el WER de las transcripciones de palabras. Esa es la razón por la que no hemos recuperado de las transcripciones fonéticas en los datos del habla ConfMTG.4.3 Umbral Theta Hemos determinado empíricamente un umbral de detección θ por tipo de fuente y la dura decisión de los acontecimientos que tienen una puntuación inferior a θ se establece en falso;Los eventos falsos devueltos por el sistema no se consideran recuperados y, por lo tanto, no se usan para calcular ATWV, precisión y retiro. El valor del umbral θ por tipo de fuente se informa en la Tabla 2. Está correlacionado con la precisión de las transcripciones. Básicamente, establecer un umbral tiene como objetivo eliminar de los acontecimientos recuperados, falsas alarmas sin agregar fallas. Cuanto mayor sea el que sea, mayor será el umbral θ. BNEWS CTS Confmtg 0.4 0.61 0.91 Tabla 2: Valores del umbral θ por tipo de fuente.4.4 Profección de recursos de procesamiento informamos en la Tabla 3 el perfil de recursos de procesamiento. Con respecto al tamaño del índice, tenga en cuenta que nuestro índice se comprime mediante técnicas de compresión del índice IR. El tiempo de indexación incluye tanto el procesamiento de audio (generación de transcripciones de palabras y fonéticas) como la construcción de los índices de búsqueda. Tamaño del índice 0.3267 MB/HS Tiempo de indexación 7.5627 HP/HS Uso de la memoria del índice 1653.4297 MB Velocidad de búsqueda 0.0041 SEC.P/HS Uso de la memoria de búsqueda 269.1250 MB Tabla 3: Profección de recursos de procesamiento.(HS: Horas de discurso. HP: horas de procesamiento.Sec.P: Segundos de procesamiento) 4.5 Medidas de recuperación Comparamos nuestro enfoque (WCN fonético) presentado en la Sección 4.1 con otro enfoque (1 mejor WCN fonético). La única diferencia entre estos dos enfoques es que, en 1 mejor WCN fonético, indexamos solo la 1 mejor ruta extraída del WCN en lugar de indexar todo el WCN. WCN fonético fue nuestro sistema principal para la evaluación y el mejor fonético de la WCN fue uno de nuestros sistemas de contraste. Precisión y retiro promedio, MTWV y ATWV en las 1100 consultas se dan en la Tabla 4. También proporcionamos la curva DET para el enfoque fonético de WCN en la Figura 2. El punto que maximiza el TWV, el MTWV, se especifica en cada curva. Tenga en cuenta que el rendimiento de la recuperación se ha evaluado por separado para cada tipo de fuente ya que la precisión del habla difiere por tipo de fuente como se muestra en la Sección 4.2. Como se esperaba, podemos ver que MTWV y ATWV disminuyen en más alto. El rendimiento de la recuperación se mejora cuando la medida BNews CTS confmtg WCN ATWV fonética 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 Precisión 0.94 0.90 0.65 RECURS 512 Precisión 0.95 0.91 0.66 Recuerde 0.84 0.75 0.37Tabla 4: ATWV, MTWV, precisión y retiro por tipo de fuente. Figura 2: Curva DET para el enfoque fonético de WCN.Usando WCN relativamente a la mejor ruta. Se debe al hecho de que la probabilidad de Miss se mejora al indexar todas las hipótesis proporcionadas por los WCN. Esta observación confirma los resultados mostrados por Mamou et al.[17] En el contexto de la recuperación de documentos hablados. El ATWV que hemos obtenido está cerca del MTWV;Hemos combinado nuestro modelo de clasificación con umbral apropiado θ para eliminar los resultados con una puntuación más baja. Por lo tanto, se reduce el efecto de falsas alarmas agregadas por WCNS. El enfoque fonético de WCN se utilizó en la reciente evaluación de NIST ETS y recibió la clasificación general más alta entre once participantes. A modo de comparación, el sistema que se clasificó en tercer lugar, obtuvo un ATWV de 0.8238 para BNEWS, 0.6652 para CTS y 0.1103 para ConfMTG.4.6 Influencia de la duración de la consulta en el rendimiento de la recuperación Hemos analizado el rendimiento de la recuperación de acuerdo con la duración promedio de las ocurrencias en las transcripciones manuales. El conjunto de consultas se dividió en tres cuantiles diferentes de acuerdo con la duración;Hemos informado en la Tabla 5 ATWV y MTWV de acuerdo con la duración. Podemos ver que nos desempeñamos mejor en consultas más largas. Una de las razones es el hecho de que el sistema ASR es más preciso en palabras largas. Por lo tanto, se justificó aumentar la puntuación de los resultados con el exponente γN, como se explica en la Sección 3.4.3, de acuerdo con la longitud de la consulta.cuantil 0-33 33-66 66-100 BNews ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 confmtg ATWV 5 0.4109 0.3880 Tabla 5: ATWV, MTWV según la duración de la consultaocurrencias por tipo de fuente.4.7 Procesamiento de consultas OOV vs. IV Hemos elegido al azar tres conjuntos de consultas de los conjuntos de consultas proporcionados por NIST: 50 consultas que contienen solo términos IV;50 consultas que contienen solo términos OOV;y 50 consultas híbridas que contienen términos IV y OOV. El siguiente experimento se ha logrado en la colección BNews y los términos IV y OOV se han determinado de acuerdo con el vocabulario del sistema BNEWS ASR. Nos gustaría comparar tres enfoques diferentes de recuperación: usar solo el índice de palabras;usando solo índice fonético;combinando palabras e índices fonéticos. La Tabla 6 resume el rendimiento de la recuperación de acuerdo con cada enfoque y con cada tipo de consultas. El uso de un enfoque basado en palabras para tratar con consultas OOV y híbridas afecta drásticamente el rendimiento de la recuperación;La precisión y el recuerdo son nulos. El uso de un enfoque basado en el teléfono para tratar consultas IV afecta también el rendimiento de la recuperación en relación con el enfoque basado en palabras. Como se esperaba, el enfoque que combina los índices de palabras y fonéticos presentados en la Sección 3 conduce al mismo rendimiento de recuperación que el enfoque de la palabra para las consultas IV y al mismo rendimiento de recuperación que el enfoque fonético para las consultas OOV. Este enfoque siempre supera a los demás y justifica el hecho de que necesitamos combinar la búsqueda de palabras y fonéticas.5. Trabajo relacionado en la última década, los esfuerzos de investigación en la recuperación de datos hablados se han centrado en extender técnicas clásicas de IR a documentos hablados. Algunos de estos trabajos se han realizado en el contexto de las evaluaciones de recuperación de documentos hablados de TREC y son descritos por Garofolo et al.[12]. Se utiliza un sistema LVCSR para transcribir el discurso a las mejores transcripciones de palabras de ruta. Las transcripciones se indexan como texto limpio: para cada ocurrencia, su documento, su desplazamiento de palabras e información adicional se almacenan en el índice. Se utiliza un sistema IR genérico sobre el texto para detectar palabras y búsqueda como lo describen Brown et al.[6] y James [14]. Esta palabra fonética de palabras de estratíndex y precisión fonética retiro de precisión recordar precisión recuerdo IV consultas 0.8 0.96 0.11 0.77 0.8 0.96 consultas Oov 0 0 0.13 0.79 0.13 0.79 Consultas híbridas 0 0 0.15 0.71 0.89 0.83 Tabla 6: Comparación de palabras y enfoque fonético en IV y OOV y OOV y OOV y OOV y OOV y OOV y OOV y OOVconsultas Egy funciona bien para transcripciones como las colecciones de noticias de transmisión que tienen un WER bajo (en el rango de 15%-30%) y son redundantes por naturaleza (la misma información se habla varias veces en diferentes modales). Además, los algoritmos se han probado principalmente en consultas largas establecidas en inglés simple y la recuperación de tales consultas es más sólido contra los errores de reconocimiento de voz. Un enfoque alternativo consiste en usar redes de palabras para mejorar la efectividad de SDR. Singhal et al.[24, 25] propone agregar algunos términos a la transcripción para aliviar las fallas de recuperación debido a errores ASR. Desde una perspectiva IR, una forma clásica de traer nuevos términos es la expansión del documento utilizando un corpus similar. Su enfoque consiste en el uso de redes de palabras para determinar qué palabras devueltas por un algoritmo de expansión del documento deben agregarse a la transcripción original. La necesidad de usar un algoritmo de expansión de documentos estaba justificado por el hecho de que las redes de palabras con las que trabajaban, carecen de información sobre las probabilidades de palabras. Chelba y Acero en [8, 9] proponen una red de palabras más compacta, la red posterior específica de posición (PSPL). Esta estructura de datos es similar a WCN y conduce a un índice más compacto. La compensación de los términos en los documentos del habla también se almacena en el índice. Sin embargo, el marco de evaluación se lleva a cabo en conferencias que están relativamente planificadas, en contraste con el discurso conversacional. Su modelo de clasificación se basa en el término nivel de confianza, pero no tiene en cuenta el rango del término entre las otras hipótesis. Mamou et al.[17] propone un modelo para la recuperación de documentos hablados utilizando WCN para mejorar el retiro y el mapa de la búsqueda. Sin embargo, en los trabajos anteriores, no se aborda el problema de las consultas que contienen términos de OOV. Los enfoques populares para tratar las consultas de OOV se basan en transcripciones de sub-palabras, donde las sub-palabras son típicamente teléfonos, sílabas o fragmentos de palabras (secuencias de teléfonos) [11, 20, 23]. El enfoque clásico consiste en el uso de transcripciones fonéticas. Las transcripciones se indexan de la misma manera que las palabras en el uso de técnicas de recuperación de texto clásico;Durante el procesamiento de la consulta, la consulta se representa como una secuencia de teléfonos. La recuperación se basa en la búsqueda de la cadena de teléfonos que representan la consulta en la transcripción fonética. Para tener en cuenta las altas tasas de error de reconocimiento, algunos otros sistemas utilizan transcripciones más ricas como redes fonéticas. Son atractivos ya que acomodan las condiciones de alta tasa de error, así como permiten que se usen consultas OOV [15, 3, 20, 23, 21, 27]. Sin embargo, las redes fonéticas contienen muchos bordes que se superponen a tiempo con la misma etiqueta fonética y son difíciles de indexar. Además, además de la mejora en el recuerdo de la búsqueda, la precisión se ve afectada ya que las redes fonéticas a menudo son inexactas. En consecuencia, los enfoques fonéticos deben usarse solo para la búsqueda de OOV;Para buscar consultas que contengan también términos IV, esta técnica afecta el rendimiento de la recuperación en comparación con el enfoque basado en palabras. Saraclar y Sproat en [22] muestran una mejora en la precisión de la detección de palabras para consultas IV y OOV, utilizando redes fonéticas y de palabras, donde se puede derivar una medida de confianza de una palabra o un teléfono. Proponen tres estrategias de recuperación diferentes: buscar tanto la palabra como los índices fonéticos y unificar los dos conjuntos diferentes de resultados;Busque el índice de palabras para consultas IV, busque consultas fonéticas para consultas OOV;Busque el índice de palabras y si no se devuelve ningún resultado, busque el índice fonético. Sin embargo, no se propone una estrategia para tratar las consultas de frases que contienen términos IV y OOV. Amir et al.En [5, 4] propone fusionar un enfoque de palabra con un enfoque fonético en el contexto de la recuperación de videos. Sin embargo, la transcripción fonética se obtiene de un texto a la conversión fonética de la mejor ruta de la transcripción de la palabra y no se basa en una decodificación fonética de los datos del habla. Un tema importante a considerar al observar el estado del arte en la recuperación de los datos hablados es la falta de un conjunto de pruebas común y los términos de consulta apropiados. Este artículo utiliza dicha tarea y la evaluación de STD es un buen resumen del rendimiento de diferentes enfoques en las mismas condiciones de prueba.6. Conclusiones Este trabajo estudia cómo la detección de términos hablados independientes de vocabulario puede realizarse de manera eficiente en diferentes fuentes de datos. Anteriormente, los enfoques fonéticos y basados en palabras se han utilizado para IR en los datos del habla. El primero sufre de baja precisión y el segundo del vocabulario limitado del sistema de reconocimiento. En este documento, hemos presentado un modelo independiente de vocabulario de indexación y búsqueda que combina ambos enfoques. El sistema puede lidiar con todo tipo de consultas, aunque las frases que deben combinarse para la recuperación, información extraída de dos índices diferentes, un índice de palabras y un índice fonético. La puntuación de los términos OOV se basa en la proximidad (en el tiempo) entre los diferentes teléfonos. La puntuación de los términos IV se basa en la información proporcionada por el WCNS. Hemos mostrado una mejora en el rendimiento de la recuperación cuando se usa todos los WCN y no solo en la mejor ruta y cuando se utilizan un índice fonético para la búsqueda de términos de consulta OOV. Este enfoque siempre supera a los otros enfoques utilizando solo el índice de palabras o el índice fonético. Como trabajo futuro, compararemos nuestro modelo para la búsqueda de OOV en las transcripciones fonéticas con un modelo de recuperación basado en la distancia de edición.7. Agradecimientos Jonathan Mamou agradece a David Carmel y Ron Hoory por sus discusiones útiles e interesantes.8. Referencias [1] Sitio web de evaluación de Término hablado de NIST, http://www.nist.gov/speech/tests/std/.[2] Plan de evaluación NIST Termking Terme (STD) 2006, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf.[3] C. Allauzen, M. Mohri y M. Saraclar. Indexación general de autómatas ponderados: aplicación a recuperación de expresión hablada. En Actas del Taller de HLT-NAACL 2004 sobre enfoques interdiciplinarios para la indexación y recuperación del habla, Boston, MA, EE. UU., 2004. [4] A. Amir, M. Berg y H. Permuter. Comentarios de relevancia mutua para la formulación de consultas multimodales en la recuperación de video. En Mir 05: Actas del 7º Taller Internacional de ACM Sigmm sobre recuperación de información multimedia, páginas 17-24, Nueva York, NY, EE. UU., 2005. ACM Press.[5] A. Amir, A. Efrat y S. Srinivasan. Avances en la manchación de palabras fonéticas. En CIKM 01: Actas de la Décima Conferencia Internacional sobre Gestión de Información y Conocimiento, páginas 580-582, Nueva York, NY, EE. UU., 2001. ACM Press.[6] M. Brown, J. Foote, G. Jones, K. Jones y S. Young. Indexación del discurso de vocabulario abierto para la recuperación de correo de voz y video. En Actas ACM Multimedia 96, páginas 307-316, Hong-Kong, noviembre de 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka y A. Soffer. Juru en TREC 10Experimentos con poda de índice. En Actas de la Décima Conferencia de Recuperación de Textos (TREC-10). Instituto Nacional de Normas y Tecnología. NIST, 2001. [8] C. Chelba y A. Acero. Indexación de incertidumbre para la búsqueda de documentos hablados. En Interspeech 2005, páginas 61-64, Lisboa, Portugal, 2005. [9] C. Chelba y A. Acero. Posición Vueltas posteriores específicas para indexar el habla. En Actas de la 43a Conferencia Anual de la Asociación de Lingüística Computacional (ACL), Ann Arbor, MI, 2005. [10] S. Chen. Modelos condicionales y conjuntos para la conversión de grafema a fonema. En EuroSpeech 2003, Ginebra, Suiza, 2003. [11] M. Clements, S. Robertson y M. Miller. La búsqueda fonética aplicada a los módulos de aprendizaje de distancia en línea. En el Taller de Procesamiento de señales digitales, 2002 y el 2º Taller de Educación de Procesamiento de señales. Actas de 2002 IEEE 10, páginas 186-191, 2002. [12] J. Garofolo, G. Auzanne y E. Voorhees. La pista de recuperación de documentos de TREC: una historia de éxito. En Actas de la Novena Conferencia de Recuperación de Textos (TREC-9). Instituto Nacional de Normas y Tecnología. NIST, 2000. [13] D. Hakkani-Tur y G. Riccardi. Un algoritmo general para la descomposición de la matriz de gráficos de Word. En Actas de la Conferencia de Internación IEEE sobre Acústica, Procesamiento de habla y señal (ICASSP), páginas 596-599, Hong-Kong, 2003. [14] D. James. La aplicación de técnicas de recuperación de información clásica a documentos hablados. Tesis doctoral, Universidad de Cambridge, Downing College, 1995. [15] D. A. James. Un sistema para la recuperación de temas sin restricciones de las transmisiones de Radio News. En Proc. ICASSP 96, páginas 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong y E. Whittaker. Un estudio experimental de un sistema de indexación de audio para la web. En Actas de ICSLP, 1996. [17] J. Mamou, D. Carmel y R. Hoory. Recuperación de documentos hablados de las conversaciones del centro de llamadas. En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 51-58, Nueva York, NY, EE. UU., 2006. ACM Press.[18] L. Mangu, E. Brill y A. Stolcke. Encontrar consenso en el reconocimiento de voz: minimización de errores de palabras y otras aplicaciones de redes de confusión. Computer Speech and Language, 14 (4): 373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski y M. Przybocki. La curva DET en la evaluación del rendimiento de la tarea de detección. En Proc. EuroSpeech 97, páginas 1895-1898, Rhodes, Grecia, 1997. [20] K. Ng y V. W. Zue. Enfoques basados en subvenciones para la recuperación de documentos hablados. Speech Commun., 32 (3): 157-186, 2000. [21] Y. Peng y F. Seide. Búsqueda rápida de vocabulario de dos etapas en discurso espontáneo. En acústica, habla y procesamiento de señales. Actas.(ICASSP). IEEE International Conference, Volumen 1, páginas 481-484, 2005. [22] M. Saraclar y R. Sproat. Búsqueda basada en la red para la recuperación de expresión hablada. En HLT-Naacl 2004: PRINCIPIOS PRINCIPALES, Páginas 129-136, Boston, Massachusetts, EE. UU., 2004. [23] F. Seide, P. Yu, C. Ma y E. Chang. Búsqueda independiente del vocabulario en el discurso espontáneo. En ICASSP-2004, IEEE International Conference on Acoustics, Speech and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis y F. Pereira. AT&T en TREC-7. En Actas de la Séptima Conferencia de Recuperación de Textos (TREC-7). Instituto Nacional de Normas y Tecnología. NIST, 1999. [25] A. Singhal y F. Pereira. Expansión del documento para la recuperación del habla. En Sigir 99: Actas de la 22a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 34-41, Nueva York, NY, EE. UU., 1999. ACM Press.[26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon y G. Zweig. El sistema de telefonía conversacional IBM 2004 para una transcripción rica. En Actas de la Conferencia Internacional IEEE sobre Acústica, Procesamiento de discursos y señales (ICASSP), marzo de 2005. [27] K. Thambiratnam y S. Sridharan. Búsquedas dinámicas de la contabilidad telefónica de la matrícula para el vocabulario sin restricciones muy rápido y preciso. En acústica, habla y procesamiento de señales. Actas.(ICASSP). IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin y K. S. Jones. Efectos de las palabras fuera del vocabulario en la recuperación de documentos hablados (sesión de carteles). En Sigir 00: Actas de la 23a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 372-374, Nueva York, NY, EE. UU., 2000. ACM Press.",
    "original_sentences": [
        "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
        "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
        "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
        "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
        "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
        "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
        "A speech recognizer generates word confusion networks and phonetic lattices.",
        "The transcripts are indexed for query processing and ranking purpose.",
        "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
        "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
        "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
        "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
        "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
        "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
        "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
        "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
        "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
        "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
        "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
        "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
        "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
        "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
        "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
        "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
        "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
        "The main drawback of this approach is the inherent high error rate of the transcripts.",
        "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
        "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
        "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
        "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
        "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
        "In classical IR, the index stores for each occurrence of a term, its offset.",
        "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
        "The only element of comparison between phonetic and word transcripts are the timestamps.",
        "No previous work combining word and phonetic approach has been done on phrase search.",
        "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
        "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
        "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
        "The paper is organized as follows.",
        "We describe the audio processing in Section 2.",
        "The indexing and retrieval methods are presented in section 3.",
        "Experimental setup and results are given in Section 4.",
        "In Section 5, we give an overview of related work.",
        "Finally, we conclude in Section 6. 2.",
        "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
        "It works in speaker-independent mode.",
        "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
        "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
        "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
        "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
        "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
        "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
        "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
        "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
        "Compute the posterior probabilities for all edges in the word lattice. 2.",
        "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
        "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
        "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
        "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
        "Typical structures of a lattice and a WCN are given in Figure 1.",
        "Figure 1: Typical structures of a lattice and a WCN. 3.",
        "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
        "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
        "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
        "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
        "These misses reduce the recall of the search.",
        "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
        "These misses reduce the precision of the search.",
        "Search recall can be enhanced by expanding the transcript with extra words.",
        "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
        "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
        "Using an appropriate ranking model, we can avoid the decrease in precision.",
        "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
        "We have adapted this model of IV search to term detection.",
        "In word transcripts, OOV terms are deleted or substituted.",
        "Therefore, the usage of phonetic transcripts is more desirable.",
        "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
        "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
        "A query is a phrase containing several words.",
        "The queries are text and not speech.",
        "Note that this task is different from the more classical task of spoken document retrieval.",
        "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
        "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
        "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
        "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
        "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
        "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
        "The terms are extracted from the query.",
        "The vocabulary of the ASR system building word transcripts is given.",
        "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
        "For an IV query term, the posting list is extracted from the word index.",
        "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
        "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
        "The posting list of each phone is extracted from the phonetic index.",
        "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
        "First, we check that the words and phones appear in the right order according to their begin times.",
        "Second, we check that the gap in time between adjacent words and phones is reasonable.",
        "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
        "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
        "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
        "Our query processing does not allow substitutions and deletions.",
        "Example: Let us consider the phrase query prosody research.",
        "The term prosody is OOV and the term research is IV.",
        "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
        "The posting list of each phone is extracted from the phonetic index.",
        "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
        "We obtain occurrences of the term prosody.",
        "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
        "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
        "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
        "The STD evaluation has focused on the fourth query type.",
        "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
        "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
        "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
        "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
        "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
        "We use the information provided by the word index.",
        "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
        "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
        "We define a scoring function that is related to the average gap in time between the different phones.",
        "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
        "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
        "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
        "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
        "For each phone, we give the begin time and the duration in second.",
        "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
        "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
        "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
        "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
        "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
        "Our goal is to estimate for each found occurrence how likely the query appears.",
        "It is different from classical IR that aims to rank the results and not to score them.",
        "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
        "We have determined empirically the value of γn = 1/n.",
        "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
        "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
        "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
        "As shown in Section 4.2, these different collections have different accuracies.",
        "CTS and CONFMTG are spontaneous speech.",
        "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
        "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
        "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
        "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
        "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
        "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
        "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
        "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
        "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
        "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
        "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
        "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
        "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
        "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
        "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
        "Therefore, β = 999.9.",
        "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
        "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
        "Tspeech is the total amount of speech in the collection (in seconds).",
        "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
        "It ranges from −∞ to +1.",
        "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
        "It ranges from 0 to +1.",
        "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
        "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
        "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
        "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
        "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
        "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
        "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
        "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
        "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
        "The value of the threshold θ per source type is reported in Table 2.",
        "It is correlated to the accuracy of the transcripts.",
        "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
        "The higher the WER is, the higher the θ threshold should be.",
        "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
        "Concerning the index size, note that our index is compressed using IR index compression techniques.",
        "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
        "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
        "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
        "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
        "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
        "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
        "We provide also the DET curve for WCN phonetic approach in Figure 2.",
        "The point that maximizes the TWV, the MTWV, is specified on each curve.",
        "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
        "As expected, we can see that MTWV and ATWV decrease in higher WER.",
        "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
        "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
        "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
        "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
        "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
        "Therefore, the effect of false alarms added by WCNs is reduced.",
        "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
        "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
        "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
        "We can see that we performed better on longer queries.",
        "One of the reasons is the fact that the ASR system is more accurate on long words.",
        "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
        "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
        "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
        "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
        "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
        "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
        "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
        "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
        "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
        "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
        "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
        "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
        "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
        "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
        "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
        "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
        "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
        "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
        "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
        "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
        "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
        "This data structure is similar to WCN and leads to a more compact index.",
        "The offset of the terms in the speech documents is also stored in the index.",
        "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
        "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
        "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
        "However, in the above works, the problem of queries containing OOV terms is not addressed.",
        "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
        "The classical approach consists of using phonetic transcripts.",
        "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
        "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
        "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
        "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
        "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
        "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
        "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
        "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
        "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
        "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
        "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
        "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
        "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
        "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
        "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
        "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
        "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
        "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
        "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
        "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
        "The scoring of IV terms is based on information provided by the WCNs.",
        "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
        "This approach always outperforms the other approaches using only word index or phonetic index.",
        "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
        "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
        "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
        "General indexation of weighted automata - application to spoken utterance retrieval.",
        "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
        "Mutual relevance feedback for multimodal query formulation in video retrieval.",
        "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
        "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
        "Advances in phonetic word spotting.",
        "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
        "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
        "Open-vocabulary speech indexing for voice and video mail retrieval.",
        "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
        "Juru at TREC 10Experiments with Index Pruning.",
        "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
        "National Institute of Standards and Technology.",
        "NIST, 2001. [8] C. Chelba and A. Acero.",
        "Indexing uncertainty for spoken document search.",
        "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
        "Position specific posterior lattices for indexing speech.",
        "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
        "Conditional and joint models for grapheme-to-phoneme conversion.",
        "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
        "Phonetic searching applied to on-line distance learning modules.",
        "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
        "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
        "The TREC spoken document retrieval track: A success story.",
        "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
        "National Institute of Standards and Technology.",
        "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
        "A general algorithm for word graph matrix decomposition.",
        "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
        "The application of classical information retrieval techniques to spoken documents.",
        "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
        "A system for unrestricted topic retrieval from radio news broadcasts.",
        "In Proc.",
        "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
        "An experimental study of an audio indexing system for the web.",
        "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
        "Spoken document retrieval from call-center conversations.",
        "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
        "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
        "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
        "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
        "The DET curve in assessment of detection task performance.",
        "In Proc.",
        "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
        "Subword-based approaches for spoken document retrieval.",
        "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
        "Fast two-stage vocabulary-independent search in spontaneous speech.",
        "In Acoustics, Speech, and Signal Processing.",
        "Proceedings. (ICASSP).",
        "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
        "Lattice-based search for spoken utterance retrieval.",
        "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
        "Vocabulary-independent search in spontaneous speech.",
        "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
        "AT&T at TREC-7.",
        "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
        "National Institute of Standards and Technology.",
        "NIST, 1999. [25] A. Singhal and F. Pereira.",
        "Document expansion for speech retrieval.",
        "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
        "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
        "The IBM 2004 conversational telephony system for rich transcription.",
        "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
        "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
        "In Acoustics, Speech, and Signal Processing.",
        "Proceedings. (ICASSP).",
        "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
        "Effects of out of vocabulary words in spoken document retrieval (poster session).",
        "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
        "ACM Press."
    ],
    "error_count": 0,
    "keys": {
        "spoken term detection": {
            "translated_key": "detección de términos hablados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent <br>spoken term detection</br> Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST <br>spoken term detection</br> evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST <br>spoken term detection</br> 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent <br>spoken term detection</br> can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST <br>spoken term detection</br> 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST <br>spoken term detection</br> (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Vocabulario Independiente \"Detección de términos hablados\" Jonathan Mamou Ibm Haifa Investigation Labs Haifa 31905, Israel Mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan Ibm T. J. Watson Research Center York Counts, N.Y. 10598, USA {Bhuvana, Siohan}Resumen .com Estamos interesados en recuperar información de datos del habla como noticias de transmisión, conversaciones telefónicas y reuniones de mesa redonda.",
                "El valor del método propuesto se demuestra por el alto rendimiento relativo de nuestro sistema, que recibió la clasificación general más alta para los datos del habla en inglés en la evaluación reciente de \"detección de términos hablados\" de NIST [1].",
                "Analizamos la efectividad de la recuperación de este enfoque en los datos de evaluación de 2006 \"Detección de términos hablados\" NIST [1].",
                "Conclusiones Este trabajo estudia cómo la \"detección de términos hablados\" independientes del vocabulario puede realizarse de manera eficiente en diferentes fuentes de datos.",
                "Referencias [1] NIST \"Detección de términos hablados\" Sitio web de evaluación 2006, http://www.nist.gov/speech/tests/std/.[2] NIST \"Detección de términos hablados\" (STD) Plan de evaluación 2006, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf.[3] C. Allauzen, M. Mohri y M. Saraclar."
            ],
            "translated_text": "",
            "candidates": [
                "detección de términos hablados",
                "Detección de términos hablados",
                "detección de términos hablados",
                "detección de términos hablados",
                "detección de términos hablados",
                "Detección de términos hablados",
                "detección de términos hablados",
                "detección de términos hablados",
                "detección de términos hablados",
                "Detección de términos hablados",
                "Detección de términos hablados"
            ],
            "error": []
        },
        "vocabulary": {
            "translated_key": "vocabulario",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>vocabulary</br> Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large <br>vocabulary</br> continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers <br>vocabulary</br> cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a <br>vocabulary</br> independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large <br>vocabulary</br> continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-<br>vocabulary</br> (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system <br>vocabulary</br> and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR <br>vocabulary</br>.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers <br>vocabulary</br> is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-<br>vocabulary</br> (IV) query terms that are part of the <br>vocabulary</br> of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The <br>vocabulary</br> of the ASR system building word transcripts is given.",
                "Terms that are part of this <br>vocabulary</br> are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In <br>vocabulary</br> term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of <br>vocabulary</br> term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the <br>vocabulary</br> of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how <br>vocabulary</br> independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited <br>vocabulary</br> of the recognition system.",
                "In this paper, we have presented a <br>vocabulary</br> independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-<br>vocabulary</br> speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage <br>vocabulary</br>-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "<br>vocabulary</br>-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted <br>vocabulary</br> keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of <br>vocabulary</br> words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Detección de término hablado de \"Vocabulary\" Jonathan Mamou Ibm Haifa Investigation Labs Haifa 31905, Israel Mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan Ibm T. J. Watson Research Center York Counts, N.Y. 10598, USA {Bhuvana, Siohan}Resumen .com Estamos interesados en recuperar información de datos del habla como noticias de transmisión, conversaciones telefónicas y reuniones de mesa redonda.",
                "Hoy en día, la mayoría de los sistemas usan grandes herramientas continuas de reconocimiento de voz \"vocabulario\" para producir transcripciones de palabras;Las transcripciones se indexan y los términos de consulta se recuperan del índice.",
                "Sin embargo, los términos de consulta que no son parte del \"vocabulario\" de los reconocedores no se pueden recuperar, y el retiro de la búsqueda se ve afectado.",
                "Presentamos un sistema independiente \"vocabulario\" que puede manejar consultas arbitrarias, explotando la información proporcionada al tener ambas transcripciones de palabras y transcripciones fonéticas.",
                "El enfoque clásico consiste en convertir las transcripciones del discurso a las palabras utilizando una gran herramienta de reconocimiento continuo de voz \"vocabulario\" (LVCSR).",
                "Sin embargo, un inconveniente significativo de tales enfoques es que la búsqueda en consultas que contienen términos fuera del \"vocabulario\" (OOV) no devolverán ningún resultado.",
                "Los términos de OOV faltan palabras del \"vocabulario\" del sistema ASR y se reemplazan en la transcripción de salida por alternativas que son probables, dado el modelo acústico de reconocimiento y el modelo de lenguaje.",
                "Se ha observado experimentalmente que más del 10% de las consultas de los usuarios pueden contener términos de OOV [16], ya que las consultas a menudo se relacionan con entidades nombradas que generalmente tienen una cobertura deficiente en el \"vocabulario\" de ASR.",
                "En muchas aplicaciones, la tasa de OOV puede empeorar con el tiempo a menos que el \"vocabulario\" de los reconocedores se actualice periódicamente.",
                "Por lo tanto, dicho enfoque no puede ser una alternativa a las transcripciones de palabras, especialmente para los términos de consulta de in- \"vocabulario\" (iv) que forman parte del \"vocabulario\" del sistema ASR.",
                "Se da el \"vocabulario\" de las transcripciones de palabras de construcción del sistema ASR.",
                "Los términos que forman parte de este \"vocabulario\" son términos IV;Los otros términos son OOV.",
                "Si el rango R es más grande que J, asumimos BR = 0. 3.4.1 En la clasificación de término \"Vocabulario\" para la clasificación de términos IV, extendemos el trabajo de Mamou et al.[17] Sobre la recuperación de documentos hablados a la detección de términos.",
                "Definimos la puntuación de puntaje (k, t, d) de una palabra clave k que ocurre a una vez t en la transcripción d, por la siguiente fórmula: puntaje (k, t, d) = brank (k | t, d) × pr pr)(k | t, d) Tenga en cuenta que 0 ≤ puntaje (k, t, d) ≤ 1. 3.4.2 Fuera de la clasificación de término \"vocabulario\" para la clasificación de términos OOV, utilizamos la información proporcionada por el índice fonético.",
                "El siguiente experimento se ha logrado en la colección BNews y los términos IV y OOV se han determinado de acuerdo con el \"vocabulario\" del sistema BNEWS ASR.",
                "Conclusiones Este trabajo estudia cómo la detección de términos de voz \"vocabulario\" se puede realizar de manera eficiente en diferentes fuentes de datos.",
                "El primero sufre de baja precisión y el segundo del \"vocabulario\" limitado del sistema de reconocimiento.",
                "En este artículo, hemos presentado un modelo independiente de \"vocabulario\" de indexación y búsqueda que combina ambos enfoques.",
                "Open- \"Vocabulario\" indexación del discurso para la recuperación de correo de voz y video.",
                "Search independiente rápida de dos etapas \"Vocabulario\" en discurso espontáneo.",
                "\"Vocabulario\", búsqueda independiente en el discurso espontáneo.",
                "Búsquedas de la contabilidad de teléfono dinámico de la matrícula para detectar una observación clave de la palabra clave \"vocabulario sin restricciones\" muy rápida y precisa.",
                "Efectos de las palabras de \"vocabulario\" en la recuperación de documentos hablados (sesión de carteles)."
            ],
            "translated_text": "",
            "candidates": [
                "vocabulario",
                "Vocabulary",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "Vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "vocabulario",
                "Vocabulario",
                "vocabulario",
                "Vocabulario",
                "vocabulario",
                "Vocabulario",
                "vocabulario",
                "vocabulario sin restricciones",
                "vocabulario",
                "vocabulario"
            ],
            "error": []
        },
        "speech datum retrieval": {
            "translated_key": "Recuperación de dato de habla",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "phonetic transcript": {
            "translated_key": "transcripción fonética",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the <br>phonetic transcript</br>.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the <br>phonetic transcript</br> is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "La recuperación se basa en la búsqueda de la cadena de teléfonos que representan la consulta en la \"transcripción fonética\".",
                "Sin embargo, la \"transcripción fonética\" se obtiene de un texto a la conversión fonética de la mejor ruta de la transcripción de la palabra y no se basa en una decodificación fonética de los datos del habla."
            ],
            "translated_text": "",
            "candidates": [
                "transcripción fonética",
                "transcripción fonética",
                "transcripción fonética",
                "transcripción fonética"
            ],
            "error": []
        },
        "vocabulary independent system": {
            "translated_key": "Sistema independiente de vocabulario",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a <br>vocabulary independent system</br> that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Presentamos un \"sistema independiente de vocabulario\" que puede manejar consultas arbitrarias, explotando la información proporcionada por tener ambas transcripciones de palabras y transcripciones fonéticas."
            ],
            "translated_text": "",
            "candidates": [
                "Sistema independiente de vocabulario",
                "sistema independiente de vocabulario"
            ],
            "error": []
        },
        "speech recognizer": {
            "translated_key": "reconocimiento de voz",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A <br>speech recognizer</br> generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Un \"reconocimiento de voz\" genera redes de confusión de palabras y redes fonéticas."
            ],
            "translated_text": "",
            "candidates": [
                "reconocimiento de voz",
                "reconocimiento de voz"
            ],
            "error": []
        },
        "indexing timestamp": {
            "translated_key": "marca de tiempo de indexación",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "word index": {
            "translated_key": "índice de palabras",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the <br>word index</br> for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from <br>word index</br> and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by <br>word index</br> since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, <br>word index</br> and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the <br>word index</br>.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the <br>word index</br> and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the <br>word index</br>. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the <br>word index</br> for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the <br>word index</br>.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only <br>word index</br>; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the <br>word index</br> for IV queries, search the phonetic index for OOV queries; search the <br>word index</br> and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a <br>word index</br> and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only <br>word index</br> or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Una solución sería combinar los dos enfoques diferentes presentados anteriormente: indexamos ambas transcripciones de palabras y transcripciones fonéticas;Durante el procesamiento de la consulta, la información se recupera del \"índice de palabras\" para términos IV y del índice fonético para términos OOV.",
                "En consecuencia, necesitamos fusionar piezas de información recuperadas del \"índice de palabras\" y el índice fonético.",
                "Por lo tanto, no podemos fusionar listas de publicación recuperadas por índice fonético con las recuperadas por \"índice de palabras\" ya que la compensación de los ocurrencias recuperados de los dos índices diferentes no es comparable.",
                "Buscamos consultas fusionando la información recuperada de los dos índices diferentes, \"índice de palabras\" e índice fonético, de acuerdo con las marcas de tiempo de los términos de la consulta.",
                "Para un término de consulta IV, la lista de publicación se extrae del \"índice de palabras\".",
                "La lista de publicación de la investigación se extrae del \"índice de palabras\" y la fusionamos con los acontecimientos encontrados para la prosodia de tal manera que aparecen en el orden correcto y la distancia en el tiempo entre la prosodia y la investigación es inferior a 0.5 segundos.",
                "Tenga en cuenta que nuestro modelo de indexación permite buscar diferentes tipos de consultas: 1. Consultas que contienen solo términos IV utilizando el \"índice de palabras\".2. Consultas que contienen solo términos OOV utilizando el índice fonético.3. Consultas de palabras clave que contienen términos IV y OOV utilizando el \"índice de palabras\" para términos IV y el índice fonético para términos OOV;Para el procesamiento de consultas, los diferentes conjuntos de coincidencias se unifican si los términos de consulta tienen o semántica e se cruzan si los términos de consulta tienen y semántica.4. Consultas de frases que contienen términos IV y OOV;Para el procesamiento de consultas, las listas de publicación de los términos IV recuperados del índice de palabras se fusionan con las listas de publicación de los términos OOV recuperados del índice fonético.",
                "Utilizamos la información proporcionada por el \"índice de palabras\".",
                "Nos gustaría comparar tres enfoques diferentes de recuperación: usar solo \"índice de palabras\";usando solo índice fonético;combinando palabras e índices fonéticos.",
                "Proponen tres estrategias de recuperación diferentes: buscar tanto la palabra como los índices fonéticos y unificar los dos conjuntos diferentes de resultados;Busque en las consultas del \"índice de palabras\" para las consultas IV, busque consultas fonéticas para consultas OOV;Busque el \"índice de palabras\" y si no se devuelve ningún resultado, busque el índice fonético.",
                "El sistema puede lidiar con todo tipo de consultas, aunque las frases que deben combinarse para la recuperación, información extraída de dos índices diferentes, un \"índice de palabras\" y un índice fonético.",
                "Este enfoque siempre supera a los otros enfoques utilizando solo \"índice de palabras\" o índice fonético."
            ],
            "translated_text": "",
            "candidates": [
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras",
                "índice de palabras"
            ],
            "error": []
        },
        "phonetic index": {
            "translated_key": "índice fonético",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the <br>phonetic index</br> for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and <br>phonetic index</br>.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by <br>phonetic index</br> with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and <br>phonetic index</br>, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the <br>phonetic index</br>.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the <br>phonetic index</br>.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the <br>phonetic index</br>. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the <br>phonetic index</br> for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the <br>phonetic index</br>.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only <br>phonetic index</br>; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the <br>phonetic index</br> for OOV queries; search the word index and if no result is returned, search the <br>phonetic index</br>.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a <br>phonetic index</br>.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using <br>phonetic index</br> for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or <br>phonetic index</br>.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Una solución sería combinar los dos enfoques diferentes presentados anteriormente: indexamos ambas transcripciones de palabras y transcripciones fonéticas;Durante el procesamiento de la consulta, la información se recupera del índice de palabras para términos IV y del \"índice fonético\" para términos OOV.",
                "En consecuencia, necesitamos fusionar piezas de información recuperadas del índice de palabras y el \"índice fonético\".",
                "Por lo tanto, no podemos fusionar listas de publicación recuperadas por \"índice fonético\" con las recuperadas por índice de palabras ya que el desplazamiento de los ocurrencias recuperados de los dos índices diferentes no es comparable.",
                "Buscamos consultas fusionando la información recuperada de los dos índices diferentes, el índice de palabras y el \"índice fonético\", de acuerdo con las marcas de tiempo de los términos de la consulta.",
                "La lista de publicación de cada teléfono se extrae del \"índice fonético\".",
                "La lista de publicación de cada teléfono se extrae del \"índice fonético\".",
                "Tenga en cuenta que nuestro modelo de indexación permite buscar diferentes tipos de consultas: 1. Consultas que contienen solo términos IV utilizando el índice de palabras.2. Consultas que contienen solo términos OOV utilizando el \"índice fonético\".3. Consultas de palabras clave que contienen términos IV y OOV utilizando el índice de palabras para términos IV y el \"índice fonético\" para términos OOV;Para el procesamiento de consultas, los diferentes conjuntos de coincidencias se unifican si los términos de consulta tienen o semántica e se cruzan si los términos de consulta tienen y semántica.4. Consultas de frases que contienen términos IV y OOV;Para el procesamiento de consultas, las listas de publicación de los términos IV recuperados del índice de palabras se fusionan con las listas de publicación de los términos OOV recuperados del índice fonético.",
                "Definimos la puntuación de puntaje (k, t, d) de una palabra clave k que ocurre a una vez t en la transcripción d, por la siguiente fórmula: puntaje (k, t, d) = brank (k | t, d) × pr pr)(k | t, d) Tenga en cuenta que 0 ≤ puntaje (k, t, d) ≤ 1. 3.4.2 Fuera de la clasificación de términos de vocabulario para la clasificación de términos OOV, utilizamos la información proporcionada por el \"índice fonético\".",
                "Nos gustaría comparar tres enfoques diferentes de recuperación: usar solo el índice de palabras;usando solo \"índice fonético\";combinando palabras e índices fonéticos.",
                "Proponen tres estrategias de recuperación diferentes: buscar tanto la palabra como los índices fonéticos y unificar los dos conjuntos diferentes de resultados;Busque el índice de palabras para consultas IV, busque el \"índice fonético\" para consultas OOV;Busque el índice de palabras y si no se devuelve ningún resultado, busque el \"índice fonético\".",
                "El sistema puede lidiar con todo tipo de consultas, aunque las frases que necesitan combinar para la recuperación, información extraída de dos índices diferentes, un índice de palabras y un \"índice fonético\".",
                "Hemos mostrado una mejora en el rendimiento de la recuperación cuando se usa todos los WCN y no solo en la mejor ruta y cuando se usa \"índice fonético\" para la búsqueda de términos de consulta OOV.",
                "Este enfoque siempre supera a los otros enfoques utilizando solo un índice de palabras o \"índice fonético\"."
            ],
            "translated_text": "",
            "candidates": [
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético",
                "índice fonético"
            ],
            "error": []
        },
        "index merging": {
            "translated_key": "Índice de fusión",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "oov search": {
            "translated_key": "búsqueda de oov",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For <br>oov search</br>, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for <br>oov search</br>; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for <br>oov search</br> on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Para la \"búsqueda de OOV\", verificamos que la distancia en el tiempo entre dos teléfonos adyacentes de un término de consulta es menor que 0.2 segundos;Este valor se ha determinado empíricamente.",
                "En consecuencia, los enfoques fonéticos deben usarse solo para la \"búsqueda de OOV\";Para buscar consultas que contengan también términos IV, esta técnica afecta el rendimiento de la recuperación en comparación con el enfoque basado en palabras.",
                "Como un trabajo futuro, compararemos nuestro modelo para la \"búsqueda OOV\" sobre las transcripciones fonéticas con un modelo de recuperación basado en la distancia de edición.7."
            ],
            "translated_text": "",
            "candidates": [
                "búsqueda de oov",
                "búsqueda de OOV",
                "búsqueda de oov",
                "búsqueda de OOV",
                "Búsqueda de OOV",
                "búsqueda OOV"
            ],
            "error": []
        },
        "automatic speech recognition": {
            "translated_key": "Reconocimiento automático de voz",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of <br>automatic speech recognition</br> (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "<br>automatic speech recognition</br> SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Mientras que la precisión de los sistemas de \"reconocimiento de voz automático\" (ASR) depende del escenario y el entorno, los sistemas de última generación alcanzaron una precisión de más del 90% en la transcripción de dichos datos.",
                "Sistema de \"Reconocimiento de voz automático\" Utilizamos un sistema ASR para transcribir datos del habla."
            ],
            "translated_text": "",
            "candidates": [
                "Reconocimiento automático de voz",
                "reconocimiento de voz automático",
                "Reconocimiento automático de voz",
                "Reconocimiento de voz automático"
            ],
            "error": []
        },
        "speech retrieval": {
            "translated_key": "recuperación del habla",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in <br>speech retrieval</br> research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for <br>speech retrieval</br>.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Este enfoque para medir la efectividad de la búsqueda utilizando datos manuales como referencia es muy común en la investigación de \"recuperación del habla\" [25, 22, 8, 9, 17].",
                "Documento de expansión para la \"recuperación del habla\"."
            ],
            "translated_text": "",
            "candidates": [
                "recuperación del habla",
                "recuperación del habla",
                "recuperación del habla",
                "recuperación del habla"
            ],
            "error": []
        },
        "speak term detection": {
            "translated_key": "Hablar Detección de términos",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing out-of-vocabulary (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "out-of-vocabulary": {
            "translated_key": "fuera del vocabulario",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Vocabulary Independent Spoken Term Detection Jonathan Mamou IBM Haifa Research Labs Haifa 31905, Israel mamou@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan IBM T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {bhuvana,siohan}@us.ibm.com ABSTRACT We are interested in retrieving information from speech data like broadcast news, telephone conversations and roundtable meetings.",
                "Today, most systems use large vocabulary continuous speech recognition tools to produce word transcripts; the transcripts are indexed and query terms are retrieved from the index.",
                "However, query terms that are not part of the recognizers vocabulary cannot be retrieved, and the recall of the search is affected.",
                "In addition to the output word transcript, advanced systems provide also phonetic transcripts, against which query terms can be matched phonetically.",
                "Such phonetic transcripts suffer from lower accuracy and cannot be an alternative to word transcripts.",
                "We present a vocabulary independent system that can handle arbitrary queries, exploiting the information provided by having both word transcripts and phonetic transcripts.",
                "A speech recognizer generates word confusion networks and phonetic lattices.",
                "The transcripts are indexed for query processing and ranking purpose.",
                "The value of the proposed method is demonstrated by the relative high performance of our system, which received the highest overall ranking for US English speech data in the recent NIST Spoken Term Detection evaluation [1].",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms 1.",
                "INTRODUCTION The rapidly increasing amount of spoken data calls for solutions to index and search this data.",
                "The classical approach consists of converting the speech to word transcripts using a large vocabulary continuous speech recognition (LVCSR) tool.",
                "In the past decade, most of the research efforts on spoken data retrieval have focused on extending classical IR techniques to word transcripts.",
                "Some of these works have been done in the framework of the NIST TREC Spoken Document Retrieval tracks and are described by Garofolo et al. [12].",
                "These tracks focused on retrieval from a corpus of broadcast news stories spoken by professionals.",
                "One of the conclusions of those tracks was that the effectiveness of retrieval mostly depends on the accuracy of the transcripts.",
                "While the accuracy of automatic speech recognition (ASR) systems depends on the scenario and environment, state-of-the-art systems achieved better than 90% accuracy in transcription of such data.",
                "In 2000, Garofolo et al. concluded that Spoken document retrieval is a solved problem [12].",
                "However, a significant drawback of such approaches is that search on queries containing <br>out-of-vocabulary</br> (OOV) terms will not return any results.",
                "OOV terms are missing words from the ASR system vocabulary and are replaced in the output transcript by alternatives that are probable, given the recognition acoustic model and the language model.",
                "It has been experimentally observed that over 10% of user queries can contain OOV terms [16], as queries often relate to named entities that typically have a poor coverage in the ASR vocabulary.",
                "The effects of OOV query terms in spoken data retrieval are discussed by Woodland et al. [28].",
                "In many applications the OOV rate may get worse over time unless the recognizers vocabulary is periodically updated.",
                "Another approach consists of converting the speech to phonetic transcripts and representing the query as a sequence of phones.",
                "The retrieval is based on searching the sequence of phones representing the query in the phonetic transcripts.",
                "The main drawback of this approach is the inherent high error rate of the transcripts.",
                "Therefore, such approach cannot be an alternative to word transcripts, especially for in-vocabulary (IV) query terms that are part of the vocabulary of the ASR system.",
                "A solution would be to combine the two different approaches presented above: we index both word transcripts and phonetic transcripts; during query processing, the information is retrieved from the word index for IV terms and from the phonetic index for OOV terms.",
                "We would like to be able to process also hybrid queries, i.e, queries that include both IV and OOV terms.",
                "Consequently, we need to merge pieces of information retrieved from word index and phonetic index.",
                "Proximity information on the occurrences of the query terms is required for phrase search and for proximity-based ranking.",
                "In classical IR, the index stores for each occurrence of a term, its offset.",
                "Therefore, we cannot merge posting lists retrieved by phonetic index with those retrieved by word index since the offset of the occurrences retrieved from the two different indices are not comparable.",
                "The only element of comparison between phonetic and word transcripts are the timestamps.",
                "No previous work combining word and phonetic approach has been done on phrase search.",
                "We present a novel scheme for information retrieval that consists of storing, during the indexing process, for each unit of indexing (phone or word) its timestamp.",
                "We search queries by merging the information retrieved from the two different indices, word index and phonetic index, according to the timestamps of the query terms.",
                "We analyze the retrieval effectiveness of this approach on the NIST Spoken Term Detection 2006 evaluation data [1].",
                "The paper is organized as follows.",
                "We describe the audio processing in Section 2.",
                "The indexing and retrieval methods are presented in section 3.",
                "Experimental setup and results are given in Section 4.",
                "In Section 5, we give an overview of related work.",
                "Finally, we conclude in Section 6. 2.",
                "AUTOMATIC SPEECH RECOGNITION SYSTEM We use an ASR system for transcribing speech data.",
                "It works in speaker-independent mode.",
                "For best recognition results, a speaker-independent acoustic model and a language model are trained in advance on data with similar characteristics.",
                "Typically, ASR generates lattices that can be considered as directed acyclic graphs.",
                "Each vertex in a lattice is associated with a timestamp and each edge (u, v) is labeled with a word or phone hypothesis and its prior probability, which is the probability of the signal delimited by the timestamps of the vertices u and v, given the hypothesis.",
                "The 1-best path transcript is obtained from the lattice using dynamic programming techniques.",
                "Mangu et al. [18] and Hakkani-Tur et al. [13] propose a compact representation of a word lattice called word confusion network (WCN).",
                "Each edge (u, v) is labeled with a word hypothesis and its posterior probability, i.e., the probability of the word given the signal.",
                "One of the main advantages of WCN is that it also provides an alignment for all of the words in the lattice.",
                "As explained in [13], the three main steps for building a WCN from a word lattice are as follows: 1.",
                "Compute the posterior probabilities for all edges in the word lattice. 2.",
                "Extract a path from the word lattice (which can be the 1-best, the longest or any random path), and call it the pivot path of the alignment. 3.",
                "Traverse the word lattice, and align all the transitions with the pivot, merging the transitions that correspond to the same word (or label) and occur in the same time interval by summing their posterior probabilities.",
                "The 1-best path of a WCN is obtained from the path containing the best hypotheses.",
                "As stated in [18], although WCNs are more compact than word lattices, in general the 1-best path obtained from WCN has a better word accuracy than the 1-best path obtained from the corresponding word lattice.",
                "Typical structures of a lattice and a WCN are given in Figure 1.",
                "Figure 1: Typical structures of a lattice and a WCN. 3.",
                "RETRIEVAL MODEL The main problem with retrieving information from spoken data is the low accuracy of the transcription particularly on terms of interest such as named entities and content words.",
                "Generally, the accuracy of a word transcript is characterized by its word error rate (WER).",
                "There are three kinds of errors that can occur in a transcript: substitution of a term that is part of the speech by another term, deletion of a spoken term that is part of the speech and insertion of a term that is not part of the speech.",
                "Substitutions and deletions reflect the fact that an occurrence of a term in the speech signal is not recognized.",
                "These misses reduce the recall of the search.",
                "Substitutions and insertions reflect the fact that a term which is not part of the speech signal appears in the transcript.",
                "These misses reduce the precision of the search.",
                "Search recall can be enhanced by expanding the transcript with extra words.",
                "These words can be taken from the other alternatives provided by the WCN; these alternatives may have been spoken but were not the top choice of the ASR.",
                "Such an expansion tends to correct the substitutions and the deletions and consequently, might improve recall but will probably reduce precision.",
                "Using an appropriate ranking model, we can avoid the decrease in precision.",
                "Mamou et al. have presented in [17] the enhancement in the recall and the MAP by searching on WCN instead of considering only the 1-best path word transcript in the context of spoken document retrieval.",
                "We have adapted this model of IV search to term detection.",
                "In word transcripts, OOV terms are deleted or substituted.",
                "Therefore, the usage of phonetic transcripts is more desirable.",
                "However, due to their low accuracy, we have preferred to use only the 1-best path extracted from the phonetic lattices.",
                "We will show that the usage of phonetic transcripts tends to improve the recall without affecting the precision too much, using an appropriate ranking. 3.1 Spoken document detection task As stated in the STD 2006 evaluation plan [2], the task consists in finding all the exact matches of a specific query in a given corpus of speech data.",
                "A query is a phrase containing several words.",
                "The queries are text and not speech.",
                "Note that this task is different from the more classical task of spoken document retrieval.",
                "Manual transcripts of the speech are not provided but are used by the evaluators to find true occurrences.",
                "By definition, true occurrences of a query are found automatically by searching the manual transcripts using the following rule: the gap between adjacent words in a query must be less than 0.5 seconds in the corresponding speech.",
                "For evaluating the results, each system output occurrence is judged as correct or not according to whether it is close in time to a true occurrence of the query retrieved from manual transcripts; it is judged as correct if the midpoint of the system output occurrence is less than or equal to 0.5 seconds from the time span of a true occurrence of the query. 3.2 Indexing We have used the same indexing process for WCN and phonetic transcripts.",
                "Each occurrence of a unit of indexing (word or phone) u in a transcript D is indexed with the following information: • the begin time t of the occurrence of u, • the duration d of the occurrence of u.",
                "In addition, for WCN indexing, we store • the confidence level of the occurrence of u at the time t that is evaluated by its posterior probability Pr(u|t, D), • the rank of the occurrence of u among the other hypotheses beginning at the same time t, rank(u|t, D).",
                "Note that since the task is to find exact matches of the phrase queries, we have not filtered stopwords and the corpus is not stemmed before indexing. 3.3 Search In the following, we present our approach for accomplishing the STD task using the indices described above.",
                "The terms are extracted from the query.",
                "The vocabulary of the ASR system building word transcripts is given.",
                "Terms that are part of this vocabulary are IV terms; the other terms are OOV.",
                "For an IV query term, the posting list is extracted from the word index.",
                "For an OOV query term, the term is converted to a sequence of phones using a joint maximum entropy N-gram model [10].",
                "For example, the term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "The next step consists of merging the different posting lists according to the timestamp of the occurrences in order to create results matching the query.",
                "First, we check that the words and phones appear in the right order according to their begin times.",
                "Second, we check that the gap in time between adjacent words and phones is reasonable.",
                "Conforming to the requirements of the STD evaluation, the distance in time between two adjacent query terms must be less than 0.5 seconds.",
                "For OOV search, we check that the distance in time between two adjacent phones of a query term is less that 0.2 seconds; this value has been determined empirically.",
                "In such a way, we can reduce the effect of insertion errors since we allow insertions between the adjacent words and phones.",
                "Our query processing does not allow substitutions and deletions.",
                "Example: Let us consider the phrase query prosody research.",
                "The term prosody is OOV and the term research is IV.",
                "The term prosody is converted to the sequence of phones (p, r, aa, z, ih, d, iy).",
                "The posting list of each phone is extracted from the phonetic index.",
                "We merge the posting lists of the phones such that the sequence of phones appears in the right order and the gap in time between the pairs of phones (p, r), (r, aa), (aa, z), (z, ih), (ih, d), (d, iy) is less than 0.2 seconds.",
                "We obtain occurrences of the term prosody.",
                "The posting list of research is extracted from the word index and we merge it with the occurrences found for prosody such that they appear in the right order and the distance in time between prosody and research is less than 0.5 seconds.",
                "Note that our indexing model allows to search for different types of queries: 1. queries containing only IV terms using the word index. 2. queries containing only OOV terms using the phonetic index. 3. keyword queries containing both IV and OOV terms using the word index for IV terms and the phonetic index for OOV terms; for query processing, the different sets of matches are unified if the query terms have OR semantics and intersected if the query terms have AND semantics. 4. phrase queries containing both IV and OOV terms; for query processing, the posting lists of the IV terms retrieved from the word index are merged with the posting lists of the OOV terms retrieved from the phonetic index.",
                "The merging is possible since we have stored the timestamps for each unit of indexing (word and phone) in both indices.",
                "The STD evaluation has focused on the fourth query type.",
                "It is the hardest task since we need to combine posting lists retrieved from phonetic and word indices. 3.4 Ranking Since IV terms and OOV terms are retrieved from two different indices, we propose two different functions for scoring an occurrence of a term; afterward, an aggregate score is assigned to the query based on the scores of the query terms.",
                "Because the task is term detection, we do not use a document frequency criterion for ranking the occurrences.",
                "Let us consider a query Q = (k0, ..., kn), associated with a boosting vector B = (B1, ..., Bj).",
                "This vector associates a boosting factor to each rank of the different hypotheses; the boosting factors are normalized between 0 and 1.",
                "If the rank r is larger than j, we assume Br = 0. 3.4.1 In vocabulary term ranking For IV term ranking, we extend the work of Mamou et al. [17] on spoken document retrieval to term detection.",
                "We use the information provided by the word index.",
                "We define the score score(k, t, D) of a keyword k occurring at a time t in the transcript D, by the following formula: score(k, t, D) = Brank(k|t,D) × Pr(k|t, D) Note that 0 ≤ score(k, t, D) ≤ 1. 3.4.2 Out of vocabulary term ranking For OOV term ranking, we use the information provided by the phonetic index.",
                "We give a higher rank to occurrences of OOV terms that contain phones close (in time) to each other.",
                "We define a scoring function that is related to the average gap in time between the different phones.",
                "Let us consider a keyword k converted to the sequence of phones (pk 0 , ..., pk l ).",
                "We define the normalized score score(k, tk 0 , D) of a keyword k = (pk 0 , ..., pk l ), where each pk i occurs at time tk i with a duration of dk i in the transcript D, by the following formula: score(k, tk 0 , D) = 1 − l i=1 5 × (tk i − (tk i−1 + dk i−1)) l Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ l, 0 < tk i − (tk i−1 + dk i−1) < 0.2 sec, 0 < 5 × (tk i − (tk i−1 + dk i−1)) < 1, and consequently, 0 < score(k, tk 0 , D) ≤ 1.",
                "The duration of the keyword occurrence is tk l − tk 0 + dk l .",
                "Example: let us consider the sequence (p, r, aa, z, ih, d, iy) and two different occurrences of the sequence.",
                "For each phone, we give the begin time and the duration in second.",
                "Occurrence 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01).",
                "Occurrence 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01).",
                "According to our formula, the score of the first occurrence is 0.83 and the score of the second occurrence is 1.",
                "In the first occurrence, there are probably some insertion or silence between the phone p and r, and between the phone d and iy.",
                "The silence can be due to the fact that the phones belongs to two different words ans therefore, it is not an occurrence of the term prosody. 3.4.3 Combination The score of an occurrence of a query Q at time t0 in the document D is determined by the multiplication of the score of each keyword ki, where each ki occurs at time ti with a duration di in the transcript D: score(Q, t0, D) = n i=0 score(ki, ti, D)γn Note that according to what we have ex-plained in Section 3.3, we have ∀1 ≤ i ≤ n, 0 < ti −(ti−1 +di−1) < 0.5 sec.",
                "Our goal is to estimate for each found occurrence how likely the query appears.",
                "It is different from classical IR that aims to rank the results and not to score them.",
                "Since the probability to have a false alarm is inversely proportional to the length of the phrase query, we have boosted the score of queries by a γn exponent, that is related to the number of keywords in the phrase.",
                "We have determined empirically the value of γn = 1/n.",
                "The begin time of the query occurrence is determined by the begin time t0 of the first query term and the duration of the query occurrence by tn − t0 + dn. 4.",
                "EXPERIMENTS 4.1 Experimental setup Our corpus consists of the evaluation set provided by NIST for the STD 2006 evaluation [1].",
                "It includes three different source types in US English: three hours of broadcast news (BNEWS), three hours of conversational telephony speech (CTS) and two hours of conference room meetings (CONFMTG).",
                "As shown in Section 4.2, these different collections have different accuracies.",
                "CTS and CONFMTG are spontaneous speech.",
                "For the experiments, we have processed the query set provided by NIST that includes 1100 queries.",
                "Each query is a phrase containing between one to five terms, common and rare terms, terms that are in the manual transcripts and those that are not.",
                "Testing and determination of empirical values have been achieved on another set of speech data and queries, the development set, also provided by NIST.",
                "We have used the IBM research prototype ASR system, described in [26], for transcribing speech data.",
                "We have produced WCNs for the three different source types. 1-best phonetic transcripts were generated only for BNEWS and CTS, since CONFMTG phonetic transcripts have too low accuracy.",
                "We have adapted Juru [7], a full-text search library written in Java, to index the transcripts and to store the timestamps of the words and phones; search results have been retrieved as described in Section 3.",
                "For each found occurrence of the given query, our system outputs: the location of the term in the audio recording (begin time and duration), the score indicating how likely is the occurrence of query, (as defined in Section 3.4) and a hard (binary) decision as to whether the detection is correct.",
                "We measure precision and recall by comparing the results obtained over the automatic transcripts (only the results having true hard decision) to the results obtained over the reference manual transcripts.",
                "Our aim is to evaluate the ability of the suggested retrieval approach to handle transcribed speech data.",
                "Thus, the closer the automatic results to the manual results is, the better the search effectiveness over the automatic transcripts will be.",
                "The results returned from the manual transcription for a given query are considered relevant and are expected to be retrieved with highest scores.",
                "This approach for measuring search effectiveness using manual data as a reference is very common in speech retrieval research [25, 22, 8, 9, 17].",
                "Beside the recall and the precision, we use the evaluation measures defined by NIST for the 2006 STD evaluation [2]: the Actual Term-Weighted Value (ATWV) and the Maximum Term-Weighted Value (MTWV).",
                "The term-weighted value (TWV) is computed by first computing the miss and false alarm probabilities for each query separately, then using these and an (arbitrarily chosen) prior probability to compute query-specific values, and finally averaging these query-specific values over all queries q to produce an overall system value: TWV (θ) = 1 − averageq{Pmiss(q, θ) + β × PF A(q, θ)} where β = C V (Pr−1 q − 1). θ is the detection threshold.",
                "For the evaluation, the cost/value ratio, C/V , has been determined to 0.1 and the prior probability of a query Prq to 10−4 .",
                "Therefore, β = 999.9.",
                "Miss and false alarm probabilities for a given query q are functions of θ: Pmiss(q, θ) = 1 − Ncorrect(q, θ) Ntrue(q) PF A(q, θ) = Nspurious(q, θ) NNT (q) corpus WER(%) SUBR(%) DELR(%) INSR(%) BNEWS WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 CONFMTG WCN 47.4 47 49 3 Table 1: WER and distribution of the error types over word 1-best path extracted from WCNs for the different source types. where: • Ncorrect(q, θ) is the number of correct detections (retrieved by the system) of the query q with a score greater than or equal to θ. • Nspurious(q, θ) is the number of spurious detections of the query q with a score greater than or equal to θ. • Ntrue(q) is the number of true occurrences of the query q in the corpus. • NNT (q) is the number of opportunities for incorrect detection of the query q in the corpus; it is the NonTarget query trials.",
                "It has been defined by the following formula: NNT (q) = Tspeech − Ntrue(q).",
                "Tspeech is the total amount of speech in the collection (in seconds).",
                "ATWV is the actual term-weighted value; it is the detection value attained by the system as a result of the system output and the binary decision output for each putative occurrence.",
                "It ranges from −∞ to +1.",
                "MTWV is the maximum term-weighted value over the range of all possible values of θ.",
                "It ranges from 0 to +1.",
                "We have also provided the detection error tradeoff (DET) curve [19] of miss probability (Pmiss) vs. false alarm probability (PF A).",
                "We have used the STDEval tool to extract the relevant results from the manual transcripts and to compute ATWV, MTWV and the DET curve.",
                "We have determined empirically the following values for the boosting vector defined in Section 3.4: Bi = 1 i . 4.2 WER analysis We use the word error rate (WER) in order to characterize the accuracy of the transcripts.",
                "WER is defined as follows: S + D + I N × 100 where N is the total number of words in the corpus, and S, I, and D are the total number of substitution, insertion, and deletion errors, respectively.",
                "The substitution error rate (SUBR) is defined by S S + D + I × 100.",
                "Deletion error rate (DELR) and insertion error rate (INSR) are defined in a similar manner.",
                "Table 1 gives the WER and the distribution of the error types over 1-best path transcripts extracted from WCNs.",
                "The WER of the 1-best path phonetic transcripts is approximately two times worse than the WER of word transcripts.",
                "That is the reason why we have not retrieved from phonetic transcripts on CONFMTG speech data. 4.3 Theta threshold We have determined empirically a detection threshold θ per source type and the hard decision of the occurrences having a score less than θ is set to false; false occurrences returned by the system are not considered as retrieved and therefore, are not used for computing ATWV, precision and recall.",
                "The value of the threshold θ per source type is reported in Table 2.",
                "It is correlated to the accuracy of the transcripts.",
                "Basically, setting a threshold aims to eliminate from the retrieved occurrences, false alarms without adding misses.",
                "The higher the WER is, the higher the θ threshold should be.",
                "BNEWS CTS CONFMTG 0.4 0.61 0.91 Table 2: Values of the θ threshold per source type. 4.4 Processing resource profile We report in Table 3 the processing resource profile.",
                "Concerning the index size, note that our index is compressed using IR index compression techniques.",
                "The indexing time includes both audio processing (generation of word and phonetic transcripts) and building of the searchable indices.",
                "Index size 0.3267 MB/HS Indexing time 7.5627 HP/HS Index Memory Usage 1653.4297 MB Search speed 0.0041 sec.P/HS Search Memory Usage 269.1250 MB Table 3: Processing resource profile. (HS: Hours of Speech.",
                "HP: Processing Hours. sec.P: Processing seconds) 4.5 Retrieval measures We compare our approach (WCN phonetic) presented in Section 4.1 with another approach (1-best-WCN phonetic).",
                "The only difference between these two approaches is that, in 1-best-WCN phonetic, we index only the 1-best path extracted from the WCN instead of indexing all the WCN.",
                "WCN phonetic was our primary system for the evaluation and 1-best-WCN phonetic was one of our contrastive systems.",
                "Average precision and recall, MTWV and ATWV on the 1100 queries are given in Table 4.",
                "We provide also the DET curve for WCN phonetic approach in Figure 2.",
                "The point that maximizes the TWV, the MTWV, is specified on each curve.",
                "Note that retrieval performance has been evaluated separately for each source type since the accuracy of the speech differs per source type as shown in Section 4.2.",
                "As expected, we can see that MTWV and ATWV decrease in higher WER.",
                "The retrieval performance is improved when measure BNEWS CTS CONFMTG WCN phonetic ATWV 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 precision 0.94 0.90 0.65 recall 0.89 0.81 0.37 1-best-WCN phonetic ATWV 0.8279 0.7102 0.2381 MTWV 0.8319 0.7117 0.2512 precision 0.95 0.91 0.66 recall 0.84 0.75 0.37 Table 4: ATWV, MTWV, precision and recall per source type.",
                "Figure 2: DET curve for WCN phonetic approach. using WCNs relatively to 1-best path.",
                "It is due to the fact that miss probability is improved by indexing all the hypotheses provided by the WCNs.",
                "This observation confirms the results shown by Mamou et al. [17] in the context of spoken document retrieval.",
                "The ATWV that we have obtained is close to the MTWV; we have combined our ranking model with appropriate threshold θ to eliminate results with lower score.",
                "Therefore, the effect of false alarms added by WCNs is reduced.",
                "WCN phonetic approach was used in the recent NIST STD evaluation and received the highest overall ranking among eleven participants.",
                "For comparison, the system that ranked at the third place, obtained an ATWV of 0.8238 for BNEWS, 0.6652 for CTS and 0.1103 for CONFMTG. 4.6 Influence of the duration of the query on the retrieval performance We have analysed the retrieval performance according to the average duration of the occurrences in the manual transcripts.",
                "The query set was divided into three different quantiles according to the duration; we have reported in Table 5 ATWV and MTWV according to the duration.",
                "We can see that we performed better on longer queries.",
                "One of the reasons is the fact that the ASR system is more accurate on long words.",
                "Hence, it was justified to boost the score of the results with the exponent γn, as explained in Section 3.4.3, according to the length of the query. quantile 0-33 33-66 66-100 BNEWS ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 CONFMTG ATWV 0.1677 0.3493 0.3651 MTWV 0.1955 0.4109 0.3880 Table 5: ATWV, MTWV according to the duration of the query occurrences per source type. 4.7 OOV vs. IV query processing We have randomly chosen three sets of queries from the query sets provided by NIST: 50 queries containing only IV terms; 50 queries containing only OOV terms; and 50 hybrid queries containing both IV and OOV terms.",
                "The following experiment has been achieved on the BNEWS collection and IV and OOV terms has been determined according to the vocabulary of BNEWS ASR system.",
                "We would like to compare three different approaches of retrieval: using only word index; using only phonetic index; combining word and phonetic indices.",
                "Table 6 summarizes the retrieval performance according to each approach and to each type of queries.",
                "Using a word-based approach for dealing with OOV and hybrid queries affects drastically the performance of the retrieval; precision and recall are null.",
                "Using a phone-based approach for dealing with IV queries affects also the performance of the retrieval relatively to the word-based approach.",
                "As expected, the approach combining word and phonetic indices presented in Section 3 leads to the same retrieval performance as the word approach for IV queries and to the same retrieval performance as the phonetic approach for OOV queries.",
                "This approach always outperforms the others and it justifies the fact that we need to combine word and phonetic search. 5.",
                "RELATED WORK In the past decade, the research efforts on spoken data retrieval have focused on extending classical IR techniques to spoken documents.",
                "Some of these works have been done in the context of the TREC Spoken Document Retrieval evaluations and are described by Garofolo et al. [12].",
                "An LVCSR system is used to transcribe the speech into 1-best path word transcripts.",
                "The transcripts are indexed as clean text: for each occurrence, its document, its word offset and additional information are stored in the index.",
                "A generic IR system over the text is used for word spotting and search as described by Brown et al. [6] and James [14].",
                "This stratindex word phonetic word and phonetic precision recall precision recall precision recall IV queries 0.8 0.96 0.11 0.77 0.8 0.96 OOV queries 0 0 0.13 0.79 0.13 0.79 hybrid queries 0 0 0.15 0.71 0.89 0.83 Table 6: Comparison of word and phonetic approach on IV and OOV queries egy works well for transcripts like broadcast news collections that have a low WER (in the range of 15%-30%) and are redundant by nature (the same piece of information is spoken several times in different manners).",
                "Moreover, the algorithms have been mostly tested over long queries stated in plain English and retrieval for such queries is more robust against speech recognition errors.",
                "An alternative approach consists of using word lattices in order to improve the effectiveness of SDR.",
                "Singhal et al. [24, 25] propose to add some terms to the transcript in order to alleviate the retrieval failures due to ASR errors.",
                "From an IR perspective, a classical way to bring new terms is document expansion using a similar corpus.",
                "Their approach consists in using word lattices in order to determine which words returned by a document expansion algorithm should be added to the original transcript.",
                "The necessity to use a document expansion algorithm was justified by the fact that the word lattices they worked with, lack information about word probabilities.",
                "Chelba and Acero in [8, 9] propose a more compact word lattice, the position specific posterior lattice (PSPL).",
                "This data structure is similar to WCN and leads to a more compact index.",
                "The offset of the terms in the speech documents is also stored in the index.",
                "However, the evaluation framework is carried out on lectures that are relatively planned, in contrast to conversational speech.",
                "Their ranking model is based on the term confidence level but does not take into consideration the rank of the term among the other hypotheses.",
                "Mamou et al. [17] propose a model for spoken document retrieval using WCNs in order to improve the recall and the MAP of the search.",
                "However, in the above works, the problem of queries containing OOV terms is not addressed.",
                "Popular approaches to deal with OOV queries are based on sub-words transcripts, where the sub-words are typically phones, syllables or word fragments (sequences of phones) [11, 20, 23].",
                "The classical approach consists of using phonetic transcripts.",
                "The transcripts are indexed in the same manner as words in using classical text retrieval techniques; during query processing, the query is represented as a sequence of phones.",
                "The retrieval is based on searching the string of phones representing the query in the phonetic transcript.",
                "To account for the high recognition error rates, some other systems use richer transcripts like phonetic lattices.",
                "They are attractive as they accommodate high error rate conditions as well as allow for OOV queries to be used [15, 3, 20, 23, 21, 27].",
                "However, phonetic lattices contain many edges that overlap in time with the same phonetic label, and are difficult to index.",
                "Moreover, beside the improvement in the recall of the search, the precision is affected since phonetic lattices are often inaccurate.",
                "Consequently, phonetic approaches should be used only for OOV search; for searching queries containing also IV terms, this technique affects the performance of the retrieval in comparison to the word based approach.",
                "Saraclar and Sproat in [22] show improvement in word spotting accuracy for both IV and OOV queries, using phonetic and word lattices, where a confidence measure of a word or a phone can be derived.",
                "They propose three different retrieval strategies: search both the word and the phonetic indices and unify the two different sets of results; search the word index for IV queries, search the phonetic index for OOV queries; search the word index and if no result is returned, search the phonetic index.",
                "However, no strategy is proposed to deal with phrase queries containing both IV and OOV terms.",
                "Amir et al. in [5, 4] propose to merge a word approach with a phonetic approach in the context of video retrieval.",
                "However, the phonetic transcript is obtained from a text to phonetic conversion of the 1-best path of the word transcript and is not based on a phonetic decoding of the speech data.",
                "An important issue to be considered when looking at the state-of-the-art in retrieval of spoken data, is the lack of a common test set and appropriate query terms.",
                "This paper uses such a task and the STD evaluation is a good summary of the performance of different approaches on the same test conditions. 6.",
                "CONCLUSIONS This work studies how vocabulary independent spoken term detection can be performed efficiently over different data sources.",
                "Previously, phonetic-based and word-based approaches have been used for IR on speech data.",
                "The former suffers from low accuracy and the latter from limited vocabulary of the recognition system.",
                "In this paper, we have presented a vocabulary independent model of indexing and search that combines both the approaches.",
                "The system can deal with all kinds of queries although the phrases that need to combine for the retrieval, information extracted from two different indices, a word index and a phonetic index.",
                "The scoring of OOV terms is based on the proximity (in time) between the different phones.",
                "The scoring of IV terms is based on information provided by the WCNs.",
                "We have shown an improvement in the retrieval performance when using all the WCN and not only the 1-best path and when using phonetic index for search of OOV query terms.",
                "This approach always outperforms the other approaches using only word index or phonetic index.",
                "As a future work, we will compare our model for OOV search on phonetic transcripts with a retrieval model based on the edit distance. 7.",
                "ACKNOWLEDGEMENTS Jonathan Mamou is grateful to David Carmel and Ron Hoory for helpful and interesting discussions. 8.",
                "REFERENCES [1] NIST Spoken Term Detection 2006 Evaluation Website, http://www.nist.gov/speech/tests/std/. [2] NIST Spoken Term Detection (STD) 2006 Evaluation Plan, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf. [3] C. Allauzen, M. Mohri, and M. Saraclar.",
                "General indexation of weighted automata - application to spoken utterance retrieval.",
                "In Proceedings of the HLT-NAACL 2004 Workshop on Interdiciplinary Approaches to Speech Indexing and Retrieval, Boston, MA, USA, 2004. [4] A. Amir, M. Berg, and H. Permuter.",
                "Mutual relevance feedback for multimodal query formulation in video retrieval.",
                "In MIR 05: Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, pages 17-24, New York, NY, USA, 2005.",
                "ACM Press. [5] A. Amir, A. Efrat, and S. Srinivasan.",
                "Advances in phonetic word spotting.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 580-582, New York, NY, USA, 2001.",
                "ACM Press. [6] M. Brown, J. Foote, G. Jones, K. Jones, and S. Young.",
                "Open-vocabulary speech indexing for voice and video mail retrieval.",
                "In Proceedings ACM Multimedia 96, pages 307-316, Hong-Kong, November 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka, and A. Soffer.",
                "Juru at TREC 10Experiments with Index Pruning.",
                "In Proceedings of the Tenth Text Retrieval Conference (TREC-10).",
                "National Institute of Standards and Technology.",
                "NIST, 2001. [8] C. Chelba and A. Acero.",
                "Indexing uncertainty for spoken document search.",
                "In Interspeech 2005, pages 61-64, Lisbon, Portugal, 2005. [9] C. Chelba and A. Acero.",
                "Position specific posterior lattices for indexing speech.",
                "In Proceedings of the 43rd Annual Conference of the Association for Computational Linguistics (ACL), Ann Arbor, MI, 2005. [10] S. Chen.",
                "Conditional and joint models for grapheme-to-phoneme conversion.",
                "In Eurospeech 2003, Geneva, Switzerland, 2003. [11] M. Clements, S. Robertson, and M. Miller.",
                "Phonetic searching applied to on-line distance learning modules.",
                "In Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.",
                "Proceedings of 2002 IEEE 10th, pages 186-191, 2002. [12] J. Garofolo, G. Auzanne, and E. Voorhees.",
                "The TREC spoken document retrieval track: A success story.",
                "In Proceedings of the Ninth Text Retrieval Conference (TREC-9).",
                "National Institute of Standards and Technology.",
                "NIST, 2000. [13] D. Hakkani-Tur and G. Riccardi.",
                "A general algorithm for word graph matrix decomposition.",
                "In Proceedings of the IEEE Internation Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 596-599, Hong-Kong, 2003. [14] D. James.",
                "The application of classical information retrieval techniques to spoken documents.",
                "PhD thesis, University of Cambridge, Downing College, 1995. [15] D. A. James.",
                "A system for unrestricted topic retrieval from radio news broadcasts.",
                "In Proc.",
                "ICASSP 96, pages 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong, and E. Whittaker.",
                "An experimental study of an audio indexing system for the web.",
                "In Proceedings of ICSLP, 1996. [17] J. Mamou, D. Carmel, and R. Hoory.",
                "Spoken document retrieval from call-center conversations.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 51-58, New York, NY, USA, 2006.",
                "ACM Press. [18] L. Mangu, E. Brill, and A. Stolcke.",
                "Finding consensus in speech recognition: word error minimization and other applications of confusion networks.",
                "Computer Speech and Language, 14(4):373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki.",
                "The DET curve in assessment of detection task performance.",
                "In Proc.",
                "Eurospeech 97, pages 1895-1898, Rhodes, Greece, 1997. [20] K. Ng and V. W. Zue.",
                "Subword-based approaches for spoken document retrieval.",
                "Speech Commun., 32(3):157-186, 2000. [21] Y. Peng and F. Seide.",
                "Fast two-stage vocabulary-independent search in spontaneous speech.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, volume 1, pages 481-484, 2005. [22] M. Saraclar and R. Sproat.",
                "Lattice-based search for spoken utterance retrieval.",
                "In HLT-NAACL 2004: Main Proceedings, pages 129-136, Boston, Massachusetts, USA, 2004. [23] F. Seide, P. Yu, C. Ma, and E. Chang.",
                "Vocabulary-independent search in spontaneous speech.",
                "In ICASSP-2004, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis, and F. Pereira.",
                "AT&T at TREC-7.",
                "In Proceedings of the Seventh Text Retrieval Conference (TREC-7).",
                "National Institute of Standards and Technology.",
                "NIST, 1999. [25] A. Singhal and F. Pereira.",
                "Document expansion for speech retrieval.",
                "In SIGIR 99: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval, pages 34-41, New York, NY, USA, 1999.",
                "ACM Press. [26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig.",
                "The IBM 2004 conversational telephony system for rich transcription.",
                "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2005. [27] K. Thambiratnam and S. Sridharan.",
                "Dynamic match phone-lattice searches for very fast and accurate unrestricted vocabulary keyword spotting.",
                "In Acoustics, Speech, and Signal Processing.",
                "Proceedings. (ICASSP).",
                "IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin, and K. S. Jones.",
                "Effects of out of vocabulary words in spoken document retrieval (poster session).",
                "In SIGIR 00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 372-374, New York, NY, USA, 2000.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Sin embargo, un inconveniente significativo de tales enfoques es que la búsqueda en consultas que contienen términos de \"fuera del vocabulario\" (OOV) no devolverán ningún resultado."
            ],
            "translated_text": "",
            "candidates": [
                "fuera de vocabulario",
                "fuera del vocabulario"
            ],
            "error": []
        }
    }
}