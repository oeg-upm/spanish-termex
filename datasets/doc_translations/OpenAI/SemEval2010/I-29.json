{
    "id": "I-29",
    "original_text": "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment. We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution. The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others. We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure. The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set. Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities. Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change. Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver. Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1. INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules. Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions. In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program. We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution. The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds. To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents. Each agent is also given a pre-computed set of local contingency (fall-back) options. Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework. In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints. This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms. The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]). However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules. We define an agent architecture centered around incremental management of a flexible times schedule. The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change. Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change. To this schedule management infra-structure, we add two mechanisms for multi-agent coordination. Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities. Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents. This latter process uses analysis of detected conflicts in the STN as a basis for generating options. The remainder of the paper is organized as follows. We begin by briefly summarizing the general distributed scheduling problem of interest in our work. Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation. In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents. We then give some experimental results to indicate current system performance. Finally we conclude with a brief discussion of current research plans. 2. THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program. The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment. A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem. Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks. A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when. Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution. Figure 2: Subjective view for Agent 2. As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward. Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1]. Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1. At the highest, most abstract level, the root of the tree is a special task called the task group. On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods. Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world. Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources). Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero. For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed. For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality. Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed. A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes. Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles). Two types of nles can be specified: hard and soft. Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality. Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task. Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints. Figure 1 shows the complete objective view of a simple 2 agent problem. Figure 2 shows the subjective view available to agent 2 for the same problem. In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3. OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment. First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution. This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision. The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement. This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available. Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure. Figure 3: Agent Architecture. Our solution framework is made concrete in the agent architecture depicted in Figure 3. In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN. At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent. The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied. When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated. In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule. Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views). After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change. The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule. These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective. In those cases where global improvement is verified, joint changes are committed to. In the following sections we consider the mechanics of these components in more detail. 4. THE SCHEDULER As indicated above, our agent scheduler operates incrementally. Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event. There is an inherent bias toward schedule stability which provides better support for the continuity in execution. This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules. The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment. As mentioned earlier, slack can be used as a hedge against uncertain method execution times. It also provides a basis for softening the impact of inter-dependencies across agents. In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem. In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3]. An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0. Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points. An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair. As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network. This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2]. As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule). Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop. The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem. The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once. The allocator selects methods from this list and attempts to install them in the agents schedule. Failure to do so reinvokes the quality propagator with the problematic activity excluded. The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes. The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled. Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality. The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined. Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators. The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline. Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline. The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order. In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda. Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated. The allocator iteratively pops the first method mnew from the agenda and attempts to install it. This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not. If any of the enabler activities fails to install, the allocation pass fails. When successful, the enables constraints linking the enabler activities to mnew are activated. The STN rejects an infeasible enabler constraint by returning a conflict. In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure. Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods. At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods. If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5. THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict. Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized. One basic mechanism needed to model execution in the STN is a dynamic model for current time. We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point. As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established. When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods. A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent. This coordination must be robust despite the fact that the The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule. If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture. This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler. The scheduler is triggered in response to various environmental messages. There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment. Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model. We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality. Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics. We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule. The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit. As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation). The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed. These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction). Of course as execution unfolds, actual method durations may deviate from these expectations. In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process. Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update. If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method. However if the method completes with a duration shorter than expected a rescheduling action might be warranted. The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline. However, it may present a possibility for exploiting the unanticipated scheduling slack. The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est). If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor. If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period). If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline. Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs. In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities. Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing. A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested. If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent. At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair. Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates. If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule. In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model. Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule. Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality. It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view. Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict. In the case of non-temporal model changes, rescheduling action is currently always initiated. 6. INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly. Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes. In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents. More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views. A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods. These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options. Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents. In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response. Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager. Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits. Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule. When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules. If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes. The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode. Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers. More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled. For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions. If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality. The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents. To illustrate, consider again the example in Figure 1. The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3). Assume that this is Agent1s current schedule. Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25. Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30. Agent2 sends a must schedule M4 query to Agent1. Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5. However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10. Hence, Agent 2 signals to Agent1 to commit to this non-local option. Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable. Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle. Given this cycle, the mechanism proceeds in three steps. First, the constraints involved in the cycle are collected. Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes. Third, constraints in this subset are selectively retracted to The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2. Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored. If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule. To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21. Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5). Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4). If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70. However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5). Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1. In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf). Upon communication of this fact Agent 2 signals to commit. 7. EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation. This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics. No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution. INT Interdependent. Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness. Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled. SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run. OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation. Agent Quality is % of optimal durations within six experiment classes. These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run. Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible. The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality. This established a challenging benchmark for the distributed agent systems to compare against. The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator. As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems. These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute. Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%. The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events. The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons. In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure. This constitutes a case where more sophisticated reasoning over success probability would benefit this agent. The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration). The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule. Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8. STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems. Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods. This scale places much higher computational demands on all of the agents components. We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues. In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems. To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms. To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes. To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity. Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9. ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International. This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033. Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10. REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Long, and B. Kohout. C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi. Gaining efficiency and flexibility in the simple temporal problem. In Proc. 3rd Int. Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl. Temporal constraint networks. Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker. TÆMS: A framework for environment centered analysis & design of coordination mechanisms. In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448. Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser. Designing a family of coordination algorithms. In Proc. 1st. Int. Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey. Design-To-Time Real-Time Scheduling. PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger. Algorithms for a temporal decoupling problem in multi-agent planning. In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand. Interleaving temporal planning and execution in robotics domains. In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams. Remote agent: To boldly go where no AI system has gone before. Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, and M. Fromherz. On-line planning and scheduling of high-speed manufacturing. In Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams. Enabling fast flexible planning through incremental temporal reasoning with conflict extraction. In Proce. ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng. Slack-based heuristics for constraint satisfaction scheduling. In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser. Criteria-directed heuristic task scheduling. International Journal of Approximate Reasoning, 19(1):91-118, 1998. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491",
    "original_translation": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491",
    "original_sentences": [
        "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
        "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
        "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
        "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
        "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
        "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
        "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
        "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
        "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
        "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
        "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
        "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
        "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
        "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
        "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
        "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
        "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
        "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
        "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
        "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
        "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
        "We define an agent architecture centered around incremental management of a flexible times schedule.",
        "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
        "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
        "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
        "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
        "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
        "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
        "The remainder of the paper is organized as follows.",
        "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
        "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
        "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
        "We then give some experimental results to indicate current system performance.",
        "Finally we conclude with a brief discussion of current research plans. 2.",
        "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
        "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
        "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
        "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
        "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
        "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
        "Figure 2: Subjective view for Agent 2.",
        "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
        "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
        "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
        "At the highest, most abstract level, the root of the tree is a special task called the task group.",
        "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
        "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
        "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
        "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
        "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
        "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
        "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
        "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
        "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
        "Two types of nles can be specified: hard and soft.",
        "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
        "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
        "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
        "Figure 1 shows the complete objective view of a simple 2 agent problem.",
        "Figure 2 shows the subjective view available to agent 2 for the same problem.",
        "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
        "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
        "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
        "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
        "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
        "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
        "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
        "Figure 3: Agent Architecture.",
        "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
        "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
        "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
        "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
        "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
        "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
        "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
        "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
        "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
        "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
        "In those cases where global improvement is verified, joint changes are committed to.",
        "In the following sections we consider the mechanics of these components in more detail. 4.",
        "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
        "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
        "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
        "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
        "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
        "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
        "It also provides a basis for softening the impact of inter-dependencies across agents.",
        "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
        "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
        "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
        "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
        "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
        "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
        "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
        "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
        "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
        "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
        "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
        "The allocator selects methods from this list and attempts to install them in the agents schedule.",
        "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
        "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
        "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
        "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
        "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
        "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
        "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
        "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
        "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
        "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
        "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
        "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
        "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
        "If any of the enabler activities fails to install, the allocation pass fails.",
        "When successful, the enables constraints linking the enabler activities to mnew are activated.",
        "The STN rejects an infeasible enabler constraint by returning a conflict.",
        "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
        "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
        "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
        "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
        "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
        "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
        "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
        "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
        "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
        "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
        "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
        "This coordination must be robust despite the fact that the The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
        "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
        "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
        "The scheduler is triggered in response to various environmental messages.",
        "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
        "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
        "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
        "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
        "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
        "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
        "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
        "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
        "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
        "Of course as execution unfolds, actual method durations may deviate from these expectations.",
        "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
        "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
        "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
        "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
        "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
        "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
        "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
        "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
        "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
        "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
        "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
        "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
        "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
        "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
        "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
        "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
        "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
        "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
        "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
        "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
        "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
        "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
        "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
        "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
        "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
        "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
        "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
        "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
        "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
        "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
        "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
        "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
        "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
        "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
        "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
        "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
        "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
        "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
        "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
        "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
        "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
        "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
        "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
        "To illustrate, consider again the example in Figure 1.",
        "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
        "Assume that this is Agent1s current schedule.",
        "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
        "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
        "Agent2 sends a must schedule M4 query to Agent1.",
        "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
        "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
        "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
        "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
        "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
        "Given this cycle, the mechanism proceeds in three steps.",
        "First, the constraints involved in the cycle are collected.",
        "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
        "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
        "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
        "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
        "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
        "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
        "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
        "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
        "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
        "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
        "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
        "Upon communication of this fact Agent 2 signals to commit. 7.",
        "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
        "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
        "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
        "INT Interdependent.",
        "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
        "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
        "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
        "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
        "Agent Quality is % of optimal durations within six experiment classes.",
        "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
        "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
        "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
        "This established a challenging benchmark for the distributed agent systems to compare against.",
        "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
        "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
        "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
        "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
        "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
        "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
        "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
        "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
        "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
        "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
        "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
        "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
        "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
        "This scale places much higher computational demands on all of the agents components.",
        "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
        "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
        "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
        "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
        "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
        "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
        "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
        "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
        "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
        "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
        "Long, and B. Kohout.",
        "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
        "Gaining efficiency and flexibility in the simple temporal problem.",
        "In Proc. 3rd Int.",
        "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
        "Temporal constraint networks.",
        "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
        "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
        "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
        "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
        "Designing a family of coordination algorithms.",
        "In Proc. 1st.",
        "Int.",
        "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
        "Design-To-Time Real-Time Scheduling.",
        "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
        "Algorithms for a temporal decoupling problem in multi-agent planning.",
        "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
        "Interleaving temporal planning and execution in robotics domains.",
        "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
        "Remote agent: To boldly go where no AI system has gone before.",
        "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
        "Do, and M. Fromherz.",
        "On-line planning and scheduling of high-speed manufacturing.",
        "In Proc.",
        "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
        "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
        "In Proce.",
        "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
        "Slack-based heuristics for constraint satisfaction scheduling.",
        "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
        "Criteria-directed heuristic task scheduling.",
        "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
    ],
    "translated_text_sentences": [
        "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido.",
        "Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución.",
        "El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras.",
        "Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental.",
        "El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles.",
        "La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes.",
        "Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto.",
        "Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable).",
        "Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1.",
        "INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución.",
        "Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación.",
        "En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA.",
        "Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución.",
        "El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución.",
        "Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes.",
        "A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas).",
        "Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo.",
        "En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas.",
        "Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia.",
        "Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]).",
        "Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo.",
        "Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos.",
        "La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación.",
        "El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario.",
        "A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes.",
        "La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes.",
        "Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes.",
        "Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones.",
        "El resto del documento está organizado de la siguiente manera.",
        "Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo.",
        "A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento.",
        "En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes.",
        "Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema.",
        "Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2.",
        "EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA.",
        "El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico.",
        "Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema.",
        "En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales.",
        "Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo.",
        "Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución.",
        "Figura 2: Vista subjetiva para el Agente 2.",
        "A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general.",
        "Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1].",
        "Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1.",
        "En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas.",
        "En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos.",
        "Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo.",
        "Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria).",
        "Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero.",
        "Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos).",
        "Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva.",
        "Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron.",
        "Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta.",
        "Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL).",
        "Se pueden especificar dos tipos de NLEs: duro y suave.",
        "Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración.",
        "El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad.",
        "Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo.",
        "Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas.",
        "La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes.",
        "La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema.",
        "En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3.",
        "RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo.",
        "Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única.",
        "Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución.",
        "El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global.",
        "Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible.",
        "El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental.",
        "Figura 3: Arquitectura del Agente.",
        "Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3.",
        "En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente.",
        "En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente.",
        "El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales.",
        "Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza.",
        "En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario.",
        "Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas).",
        "Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto.",
        "El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario.",
        "Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local.",
        "En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos.",
        "En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4.",
        "EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental.",
        "Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento.",
        "Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución.",
        "Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes.",
        "La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente.",
        "Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos.",
        "También proporciona una base para suavizar el impacto de las interdependencias entre agentes.",
        "En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores.",
        "En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada.",
        "En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente.",
        "Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0.",
        "Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo.",
        "El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado.",
        "A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red.",
        "Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2].",
        "A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma).",
        "De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado.",
        "El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes.",
        "Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo.",
        "El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes.",
        "La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida.",
        "El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución.",
        "La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada.",
        "Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad.",
        "La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores.",
        "Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores.",
        "El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes.",
        "Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma.",
        "Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad.",
        "Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda.",
        "Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos.",
        "El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo.",
        "Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté.",
        "Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla.",
        "Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan.",
        "El STN rechaza una restricción de habilitador inviable devolviendo un conflicto.",
        "En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo.",
        "Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados.",
        "A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos.",
        "Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5.",
        "La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto.",
        "En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan).",
        "Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual.",
        "Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario.",
        "A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método.",
        "Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados.",
        "Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado.",
        "Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional.",
        "La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado.",
        "Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente.",
        "Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador.",
        "El programador se activa en respuesta a varios mensajes ambientales.",
        "Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno.",
        "Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo.",
        "Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global.",
        "Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas.",
        "Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente.",
        "El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten.",
        "Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN).",
        "El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes.",
        "Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario).",
        "Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas.",
        "En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario.",
        "Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución.",
        "Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método.",
        "Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación.",
        "La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes.",
        "Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto.",
        "La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est).",
        "Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor.",
        "Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación).",
        "Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite.",
        "Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción.",
        "En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente.",
        "Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose.",
        "Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado.",
        "Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente.",
        "En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local.",
        "Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente.",
        "Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario.",
        "En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes.",
        "Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual.",
        "Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad.",
        "También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva.",
        "Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN.",
        "En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6.",
        "COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia.",
        "Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos.",
        "En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados.",
        "Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas.",
        "Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes).",
        "Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales.",
        "Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes.",
        "En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad.",
        "La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones.",
        "Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten.",
        "En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad.",
        "Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales.",
        "Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario.",
        "El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético.",
        "Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados.",
        "Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados.",
        "Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas.",
        "Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local.",
        "Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes.",
        "Para ilustrar, considera nuevamente el ejemplo en la Figura 1.",
        "La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3).",
        "Suponga que este es el horario actual del Agente1.",
        "Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25.",
        "Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30.",
        "El Agente2 envía una consulta M4 de programación obligatoria al Agente1.",
        "Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5.",
        "Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10.",
        "Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local.",
        "Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable.",
        "Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo.",
        "Dado este ciclo, el mecanismo avanza en tres pasos.",
        "Primero, se recopilan las restricciones involucradas en el ciclo.",
        "Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos.",
        "Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2.",
        "Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN.",
        "Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad.",
        "Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21.",
        "El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5).",
        "Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4).",
        "Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70.",
        "Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5).",
        "La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1.",
        "De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo).",
        "Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7.",
        "RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators.",
        "Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD.",
        "Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución.",
        "INTER Interdependiente.",
        "Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal.",
        "La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas.",
        "Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución.",
        "Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores.",
        "La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos.",
        "Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema.",
        "Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible.",
        "El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global.",
        "Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen.",
        "La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS.",
        "Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas.",
        "Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar.",
        "Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%.",
        "El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos.",
        "El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones.",
        "En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite.",
        "Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente.",
        "La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración).",
        "Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado.",
        "Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8.",
        "ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes.",
        "Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos.",
        "Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes.",
        "Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos.",
        "Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes.",
        "Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados.",
        "Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos.",
        "Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación.",
        "Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9.",
        "AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International.",
        "Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033.",
        "Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10.",
        "REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
        "Largo, y B. Kohout.",
        "Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi.",
        "Ganando eficiencia y flexibilidad en el problema temporal simple.",
        "En Proc. 3rd Int.",
        "Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl.",
        "Redes de restricciones temporales.",
        "Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker.",
        "TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación.",
        "En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448.",
        "Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser.",
        "Diseñando una familia de algoritmos de coordinación.",
        "En Proc. 1ro.",
        "Int.",
        "Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey.",
        "Planificación en tiempo real de diseño a tiempo.",
        "Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger.",
        "Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente.",
        "En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand.",
        "Entrelazando la planificación temporal y la ejecución en dominios de robótica.",
        "En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams.",
        "Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes.",
        "Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
        "Do, y M. Fromherz.",
        "Planificación y programación en línea de fabricación de alta velocidad.",
        "En Proc.",
        "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams.",
        "Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos.",
        "En proceso.",
        "ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng.",
        "Heurísticas basadas en Slack para la programación de satisfacción de restricciones.",
        "En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser.",
        "Programación heurística dirigida por criterios.",
        "Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998.",
        "El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491"
    ],
    "error_count": 7,
    "keys": {
        "managing schedule": {
            "translated_key": "gestionar horarios",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of <br>managing schedule</br>s in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of <br>managing schedule</br>s in an uncertain, distributed environment."
            ],
            "translated_annotated_samples": [
                "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de <br>gestionar horarios</br> en un entorno incierto y distribuido."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de <br>gestionar horarios</br> en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "distributed environment": {
            "translated_key": "entorno incierto y distribuido",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, <br>distributed environment</br>.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and <br>distributed environment</br> as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, <br>distributed environment</br>.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and <br>distributed environment</br> as defined by the DARPA Coordinators program."
            ],
            "translated_annotated_samples": [
                "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un <br>entorno incierto y distribuido</br>.",
                "En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un <br>entorno incierto y distribuido</br>. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "agent architecture": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an <br>agent architecture</br> for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an <br>agent architecture</br> centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the <br>agent architecture</br> we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: <br>agent architecture</br>.",
                "Our solution framework is made concrete in the <br>agent architecture</br> depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the <br>agent architecture</br>.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the <br>agent architecture</br> to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 <br>agent architecture</br> was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "We describe an <br>agent architecture</br> for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "We define an <br>agent architecture</br> centered around incremental management of a flexible times schedule.",
                "Next, we introduce the <br>agent architecture</br> we have developed to solve this problem and sketch its operation.",
                "Figure 3: <br>agent architecture</br>.",
                "Our solution framework is made concrete in the <br>agent architecture</br> depicted in Figure 3."
            ],
            "translated_annotated_samples": [
                "Describimos una <br>arquitectura de agente</br> para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental.",
                "Definimos una <br>arquitectura de agente</br> centrada en la gestión incremental de un horario flexible de tiempos.",
                "A continuación, presentamos la <br>arquitectura del agente</br> que hemos desarrollado para resolver este problema y esbozamos su funcionamiento.",
                "Figura 3: Arquitectura del Agente.",
                "Nuestro marco de solución se concreta en la <br>arquitectura del agente</br> representada en la Figura 3."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una <br>arquitectura de agente</br> para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una <br>arquitectura de agente</br> centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la <br>arquitectura del agente</br> que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la <br>arquitectura del agente</br> representada en la Figura 3. ",
            "candidates": [],
            "error": [
                [
                    "arquitectura de agente",
                    "arquitectura de agente",
                    "arquitectura del agente",
                    "arquitectura del agente"
                ]
            ]
        },
        "schedule": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established <br>schedule</br>, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents <br>schedule</br> (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents <br>schedule</br> when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating <br>schedule</br> changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished <br>schedule</br>, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents <br>schedule</br>, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times <br>schedule</br>.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for <br>schedule</br> change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize <br>schedule</br> change.",
                "To this <br>schedule</br> management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local <br>schedule</br> changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating <br>schedule</br> changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed <br>schedule</br> management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial <br>schedule</br> is also distributed to the agents, and each agents <br>schedule</br> indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed <br>schedule</br> dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local <br>schedule</br> might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new <br>schedule</br>.",
                "Whenever local <br>schedule</br> constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the <br>schedule</br> of one or more other agents that will enable the local agent to raise the quality of its <br>schedule</br>.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new <br>schedule</br> in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current <br>schedule</br> to accommodate the event.",
                "There is an inherent bias toward <br>schedule</br> stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents <br>schedule</br> is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a <br>schedule</br> or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the <br>schedule</br>).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents <br>schedule</br>.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times <br>schedule</br> enables us to use a conflict-driven approach to <br>schedule</br> repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new <br>schedule</br>) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the <br>schedule</br> running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the <br>schedule</br> to maximize quality, and/or transmitting a revised <br>schedule</br>.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised <br>schedule</br> in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current <br>schedule</br> cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete <br>schedule</br> of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid <br>schedule</br> for an agents activities, which does not require change to any other agents <br>schedule</br>.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current <br>schedule</br>, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed <br>schedule</br> consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during <br>schedule</br> construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the <br>schedule</br> can be used to absorb some of this unpredictability and modulate invocation of a <br>schedule</br> revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the <br>schedule</br> can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the <br>schedule</br>, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised <br>schedule</br> is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the <br>schedule</br>.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current <br>schedule</br>.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant <br>schedule</br> or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint <br>schedule</br> changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or <br>schedule</br> of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting <br>schedule</br> execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local <br>schedule</br> changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local <br>schedule</br> change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local <br>schedule</br>.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of <br>schedule</br> changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local <br>schedule</br> under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local <br>schedule</br>, the temporal constraints on the local target activity, and the set of must-<br>schedule</br> enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current <br>schedule</br>.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must <br>schedule</br> M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its <br>schedule</br> to get M4 on, resulting in a new lower quality <br>schedule</br> of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the <br>schedule</br>, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local <br>schedule</br>.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could <br>schedule</br> M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to <br>schedule</br> M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the <br>schedule</br> this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial <br>schedule</br>.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established <br>schedule</br>, but none possessing a global view of either the problem or solution.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents <br>schedule</br> (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents <br>schedule</br> when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating <br>schedule</br> changes to those agents with inter-dependent activities.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished <br>schedule</br>, but none possessing a global view of either the problem or solution."
            ],
            "translated_annotated_samples": [
                "Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un <br>horario</br> global preestablecido, pero ninguno posee una visión global del problema o la solución.",
                "Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la <br>agenda de los agentes</br> (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental.",
                "El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el <br>horario</br> de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles.",
                "La coordinación básica con otros agentes se logra simplemente comunicando los cambios de <br>horario</br> a aquellos agentes con actividades interdependientes.",
                "Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un <br>horario</br> global preestablecido, pero ninguno posee una visión global del problema o la solución."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un <br>horario</br> global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la <br>agenda de los agentes</br> (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el <br>horario</br> de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de <br>horario</br> a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un <br>horario</br> global preestablecido, pero ninguno posee una visión global del problema o la solución. ",
            "candidates": [],
            "error": [
                [
                    "horario",
                    "agenda de los agentes",
                    "horario",
                    "horario",
                    "horario"
                ]
            ]
        },
        "inter-dependent activities": {
            "translated_key": "actividades interdependientes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with <br>inter-dependent activities</br>.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with <br>inter-dependent activities</br> so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with <br>inter-dependent activities</br>.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with <br>inter-dependent activities</br> so that they can align their decisions accordingly."
            ],
            "translated_annotated_samples": [
                "La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con <br>actividades interdependientes</br>.",
                "COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con <br>actividades interdependientes</br> para que puedan alinear sus decisiones en consecuencia."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con <br>actividades interdependientes</br>. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con <br>actividades interdependientes</br> para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "geographical separation": {
            "translated_key": "separación geográfica",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as <br>geographical separation</br> of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Such factors as <br>geographical separation</br> of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions."
            ],
            "translated_annotated_samples": [
                "Factores como la <br>separación geográfica</br> de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la <br>separación geográfica</br> de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "flexible time": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a <br>flexible time</br>s representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of <br>flexible time</br>s frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a <br>flexible time</br>s schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based <br>flexible time</br>s representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with <br>flexible time</br>s scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The <br>flexible time</br>s representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under <br>flexible time</br>s scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the <br>flexible time</br>s representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a <br>flexible time</br>s representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The advantages of <br>flexible time</br>s frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "We define an agent architecture centered around incremental management of a <br>flexible time</br>s schedule.",
                "First is the use of a STN-based <br>flexible time</br>s representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "The coupling of incremental scheduling with <br>flexible time</br>s scheduling adds additional leverage in an uncertain, multiagent execution environment."
            ],
            "translated_annotated_samples": [
                "Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental.",
                "Se ha demostrado las ventajas de los marcos de <br>tiempo flexibles</br> en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]).",
                "Definimos una arquitectura de agente centrada en la gestión incremental de un <br>horario flexible</br> de tiempos.",
                "Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única.",
                "La combinación de la programación incremental con la programación de <br>tiempos flexibles</br> añade una ventaja adicional en un entorno de ejecución incierto y multiagente."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de <br>tiempo flexibles</br> en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un <br>horario flexible</br> de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de <br>tiempos flexibles</br> añade una ventaja adicional en un entorno de ejecución incierto y multiagente. ",
            "candidates": [],
            "error": [
                [
                    "tiempo flexibles",
                    "horario flexible",
                    "tiempos flexibles"
                ]
            ]
        },
        "centralized planning": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various <br>centralized planning</br> and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "The advantages of flexible times frameworks have been demonstrated in various <br>centralized planning</br> and scheduling contexts (e.g., [12, 8, 9, 10, 11])."
            ],
            "translated_annotated_samples": [
                "Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11])."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "management": {
            "translated_key": "gestión",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed <br>management</br> of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed <br>management</br> of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental <br>management</br> of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule <br>management</br> infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule <br>management</br> problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Distributed <br>management</br> of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "INTRODUCTION The practical constraints of many application environments require distributed <br>management</br> of executing plans and schedules.",
                "We define an agent architecture centered around incremental <br>management</br> of a flexible times schedule.",
                "To this schedule <br>management</br> infra-structure, we add two mechanisms for multi-agent coordination.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule <br>management</br> problem that we address in this paper is that put forth by the DARPA Coordinators program."
            ],
            "translated_annotated_samples": [
                "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido.",
                "INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la <br>gestión</br> distribuida de planes y horarios en ejecución.",
                "Definimos una arquitectura de agente centrada en la <br>gestión</br> incremental de un horario flexible de tiempos.",
                "A esta infraestructura de <br>gestión</br> de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes.",
                "EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de <br>gestión</br> de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la <br>gestión</br> distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la <br>gestión</br> incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de <br>gestión</br> de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de <br>gestión</br> de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "scheduler-execution": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight <br>scheduler-execution</br> coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Incremental scheduling frameworks are ideally suited for domains requiring tight <br>scheduler-execution</br> coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event."
            ],
            "translated_annotated_samples": [
                "Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "slack": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of <br>slack</br> as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, <br>slack</br> can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling <br>slack</br>.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "<br>slack</br>-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "This representation allows the explicit use of <br>slack</br> as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "As mentioned earlier, <br>slack</br> can be used as a hedge against uncertain method execution times.",
                "However, it may present a possibility for exploiting the unanticipated scheduling <br>slack</br>.",
                "<br>slack</br>-based heuristics for constraint satisfaction scheduling."
            ],
            "translated_annotated_samples": [
                "Esta representación permite el uso explícito de <br>holgura</br> como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia.",
                "Como se mencionó anteriormente, <br>Slack</br> se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos.",
                "Sin embargo, puede presentar una posibilidad para explotar el <br>margen de programación no previsto</br>.",
                "Heurísticas basadas en Slack para la programación de satisfacción de restricciones."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de <br>holgura</br> como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, <br>Slack</br> se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el <br>margen de programación no previsto</br>. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    "holgura",
                    "Slack",
                    "margen de programación no previsto"
                ]
            ]
        },
        "shortest path algorithm": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs <br>shortest path algorithm</br>; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "This is accomplished efficiently via the use of a standard all-pairs <br>shortest path algorithm</br>; in our implementation, we take advantage of an incremental procedure based on [2]."
            ],
            "translated_annotated_samples": [
                "Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "activity allocator": {
            "translated_key": "asignador de actividades",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an <br>activity allocator</br> that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The <br>activity allocator</br> - The <br>activity allocator</br> seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an <br>activity allocator</br> that work in a tightly integrated loop.",
                "The <br>activity allocator</br> - The <br>activity allocator</br> seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline."
            ],
            "translated_annotated_samples": [
                "De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un <br>asignador de actividades</br> que trabajan en un bucle estrechamente integrado.",
                "El Asignador de Actividades - El <br>asignador de actividades</br> busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un <br>asignador de actividades</br> que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El <br>asignador de actividades</br> busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "conflict-driven approach": {
            "translated_key": "enfoque basado en conflictos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a <br>conflict-driven approach</br> to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a <br>conflict-driven approach</br> to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict."
            ],
            "translated_annotated_samples": [
                "La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un <br>enfoque basado en conflictos</br> para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un <br>enfoque basado en conflictos</br> para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "optimistic synchronization": {
            "translated_key": "sincronización optimista",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "<br>optimistic synchronization</br> - <br>optimistic synchronization</br> is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using <br>optimistic synchronization</br>, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "<br>optimistic synchronization</br> - <br>optimistic synchronization</br> is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "Using <br>optimistic synchronization</br>, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30."
            ],
            "translated_annotated_samples": [
                "Sincronización optimista: La <br>sincronización optimista</br> es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados.",
                "Usando <br>sincronización optimista</br>, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La <br>sincronización optimista</br> es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando <br>sincronización optimista</br>, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "inter-agent coordination": {
            "translated_key": "coordinación entre agentes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail <br>inter-agent coordination</br> if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "<br>inter-agent coordination</br> Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail <br>inter-agent coordination</br> if available scheduler cycles permit.",
                "<br>inter-agent coordination</br> Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly."
            ],
            "translated_annotated_samples": [
                "El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen <br>coordinación entre agentes</br> si los ciclos del planificador disponibles lo permiten.",
                "COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen <br>coordinación entre agentes</br> si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "performance": {
            "translated_key": "rendimiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the <br>performance</br> of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system <br>performance</br>.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing multi-agent schedules in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: <br>performance</br> of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent <br>performance</br> can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest <br>performance</br> on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized <br>performance</br> issues.",
                "In addition to verifying that the <br>performance</br> on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "Using a simulator to model the environment, we compare the <br>performance</br> of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "We then give some experimental results to indicate current system <br>performance</br>.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: <br>performance</br> of year 1 agent over Coordinators evaluation.",
                "The very respectable agent <br>performance</br> can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest <br>performance</br> on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons."
            ],
            "translated_annotated_samples": [
                "Utilizando un simulador para modelar el entorno, comparamos el <br>rendimiento</br> de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable).",
                "Luego presentamos algunos resultados experimentales para indicar el <br>rendimiento</br> actual del sistema.",
                "Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores.",
                "El <br>rendimiento</br> del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos.",
                "El agente muestra su peor <br>rendimiento</br> en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el <br>rendimiento</br> de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el <br>rendimiento</br> actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El <br>rendimiento</br> del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor <br>rendimiento</br> en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multi-agent schedule": {
            "translated_key": "horarios de múltiples agentes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Distributed Management of Flexible Times Schedules Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein The Robotics Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution.",
                "The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others.",
                "We describe an agent architecture for solving this problem that couples two basic mechanisms: (1) a flexible times representation of the agents schedule (using a Simple Temporal Network) and (2) an incremental rescheduling procedure.",
                "The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agents schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set.",
                "Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities.",
                "Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change.",
                "Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal (but non-scalable) centralized MDP solver.",
                "Categories and Subject Descriptors I.2.11 [Computing Methodologies]: Artificial IntelligenceDistributed Artificial Intelligence General Terms Algorithms, Design 1.",
                "INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules.",
                "Such factors as geographical separation of executing agents, limitations on communication bandwidth, constraints relating to chain of command and the high tempo of execution dynamics may all preclude any single agent from obtaining a complete global view of the problem, and hence necessitate collaborative yet localized planning and scheduling decisions.",
                "In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program.",
                "We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution.",
                "The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds.",
                "To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents.",
                "Each agent is also given a pre-computed set of local contingency (fall-back) options.",
                "Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework.",
                "In a flexible-times representation of an agents schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints.",
                "This representation allows the explicit use of slack as a hedge against simple forms of executional uncertainty (e.g., activity durations), and its underlying implementation as a Simple Temporal Network (STN) model provides efficient updating and consistency enforcement mechanisms.",
                "The advantages of flexible times frameworks have been demonstrated in various centralized planning and scheduling contexts (e.g., [12, 8, 9, 10, 11]).",
                "However their use in distributed problem solving settings has been quite sparse ([7] is one exception), and prior approaches to multi-agent scheduling (e.g., [6, 13, 5]) have generally operated with fixed-times representations of agent schedules.",
                "We define an agent architecture centered around incremental management of a flexible times schedule.",
                "The underlying STN-based representation is used (1) to loosen the coupling between executor and scheduler threads, (2) to retain a basic ability to absorb unexpected executional delays (or speedups), and (3) to provide a basic criterion for detecting the need for schedule change.",
                "Local change is ac484 978-81-904262-7-5 (RPS) c 2007 IFAAMAS Figure 1: A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change.",
                "To this schedule management infra-structure, we add two mechanisms for multi-agent coordination.",
                "Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities.",
                "Layered over this is a non-local option generation and evaluation process (similar in some respects to [5]), aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents.",
                "This latter process uses analysis of detected conflicts in the STN as a basis for generating options.",
                "The remainder of the paper is organized as follows.",
                "We begin by briefly summarizing the general distributed scheduling problem of interest in our work.",
                "Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation.",
                "In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents.",
                "We then give some experimental results to indicate current system performance.",
                "Finally we conclude with a brief discussion of current research plans. 2.",
                "THE COORDINATORS PROBLEM As indicated above the distributed schedule management problem that we address in this paper is that put forth by the DARPA Coordinators program.",
                "The Coordinators problem is concerned generally with the collaborative execution of a joint mission by a team of agents in a highly dynamic environment.",
                "A mission is formulated as a network of tasks, which are distributed among the agents by the MASS simulator such that no agent has a complete, objective view of the whole problem.",
                "Instead, each agent receives only a subjective view containing just the portion of the task network that relates to ground tasks that it is responsible for and any remote tasks that have interdependencies with these local tasks.",
                "A pre-computed initial schedule is also distributed to the agents, and each agents schedule indicates which of its local tasks should be executed and when.",
                "Each task has an associated quality value which accrues if it is successfully executed within its constraints, and the overall goal is to maximize the quality obtained during execution.",
                "Figure 2: Subjective view for Agent 2.",
                "As execution proceeds, agents must react to unexpected results (e.g., task delays, failures) and changes to the mission (e.g., new tasks, deadline changes) generated by the simulator, recognize when scheduled tasks are no longer feasible or desirable, and coordinate with each other to take corrective, quality-maximizing rescheduling actions that keep execution of the overall mission moving forward.",
                "Problems are formally specified using a version of the TAEMS language (Task Analysis, Environment Modeling and Simulation) [4] called C TAEMS [1].",
                "Within C TAEMS, tasks are represented hierarchically, as shown in the example in Figure 1.",
                "At the highest, most abstract level, the root of the tree is a special task called the task group.",
                "On successive levels, tasks constitute aggregate activities, which can be decomposed into sets of subtasks and/or primitive activities, termed methods.",
                "Methods appear at the leaf level of C TAEMS task structures and are those that are directly executable in the world.",
                "Each declared method m can only be executed by a specified agent (denoted by ag : AgentN in Figure 1) and each agent can be executing at most one method at any given time (i.e. agents are unit-capacity resources).",
                "Method durations and quality are typically specified as discrete probability distributions, and hence known with certainty only after they have been executed.1 It is also possible for a method to fail unexpectedly in execution, in which case the reported quality is zero.",
                "For each task, a quality accumulation function qaf is defined, which specifies when and how a task accumulates quality as its subtasks (methods) are executed.",
                "For example, a task with a min qaf will accrue the quality of its child with lowest quality if all its children execute and accumulate positive quality.",
                "Tasks with sum or max qafs acquire quality as soon as one child executes with positive quality; as their qaf names suggest, their respective values ultimately will be the total or maximum quality of all children that executed.",
                "A sync-sum task will accrue quality only for those children that commence execution concurrently with the first child that executes, while an exactly-one task accrues quality only if precisely one of its children executes.",
                "Inter-dependencies between tasks/methods in the problem are modeled via non-local effects (nles).",
                "Two types of nles can be specified: hard and soft.",
                "Hard nles express 1 For simplicity, Figures 1 and 2 show only fixed values for method quality and duration.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485 causal preconditions: for example, the enables nle in Figure 1 stipulates that the target method M5 can not be executed until the source M4 accumulates quality.",
                "Soft nles, which include facilitates and hinders, are not required constraints; however, when they are in play, they amplify (or dampen) the quality and duration of the target task.",
                "Any given task or method a can also be constrained by an earliest start time and a deadline, specifying the window in which a can be feasibly executed. a may also inherit these constraints from ancestor tasks at any higher level in the task structure, and its effective execution window will be defined by the tightest of these constraints.",
                "Figure 1 shows the complete objective view of a simple 2 agent problem.",
                "Figure 2 shows the subjective view available to agent 2 for the same problem.",
                "In what follows, we will sometimes use the term activity to refer generically to both task and method nodes. 3.",
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing <br>multi-agent schedule</br>s in an uncertain and time stressed execution environment.",
                "First is the use of a STN-based flexible times representation of solution constraints, which allows execution to be driven by a set of schedules rather than a single point solution.",
                "This provides a basic hedge against temporal uncertainty and can be used to modulate the need for solution revision.",
                "The second principle is to first respond locally to exceptional events, and then, as time permits, explore nonlocal options (i.e., options involving change by 2 or more agents) for global solution improvement.",
                "This provides a means for keeping pace with execution, and for tying the amount of effort spent in more global multi-agent solution improvement to the time available.",
                "Both local and non-local problem solving time is further minimized by the use of a core incremental scheduling procedure.",
                "Figure 3: Agent Architecture.",
                "Our solution framework is made concrete in the agent architecture depicted in Figure 3.",
                "In its most basic form, an agent comprises four principal components - an Executor, a Scheduler, a Distributed State Manager (DSM), and an Options Manager - all of which share a common model of the current problem and solution state that couples a domainlevel representation of the subjective c taems task structure to an underlying STN.",
                "At any point during operation, the currently installed schedule dictates the timing and sequence of domain-level activities that will be initiated by the agent.",
                "The Executor, running in its own thread, continually monitors the enabling conditions of various pending activities, and activates the next pending activity as soon as all of its causal and temporal constraints are satisfied.",
                "When execution results are received back from the environment (MASS) and/or changes to assumed external constraints are received from other agents, the agents model of current state is updated.",
                "In cases where this update leads to inconsistency in the STN or it is otherwise recognized that the current local schedule might now be improved, the Scheduler, running on a separate thread, is invoked to revise the current solution and install a new schedule.",
                "Whenever local schedule constraints change either in response to a current state update or through manipulation by the Scheduler, the DSM is invoked to communicate these changes to interested agents (i.e., those agents that share dependencies and have overlapping subjective views).",
                "After responding locally to a given state update and communicating consequences, the agent will use any remaining computation time to explore possibilities for improvement through joint change.",
                "The Option Manager utilizes the Scheduler (in this case in hypothetical mode) to generate one or more non-local options, i.e., identifying changes to the schedule of one or more other agents that will enable the local agent to raise the quality of its schedule.",
                "These options are formulated and communicated as queries to the appropriate remote agents, who in turn hypothetically evaluate the impact of proposed changes from their local perspective.",
                "In those cases where global improvement is verified, joint changes are committed to.",
                "In the following sections we consider the mechanics of these components in more detail. 4.",
                "THE SCHEDULER As indicated above, our agent scheduler operates incrementally.",
                "Incremental scheduling frameworks are ideally suited for domains requiring tight scheduler-execution coupling: rather than recomputing a new schedule in response to every change, they respond quickly to execution events by localizing changes and making adjustments to the current schedule to accommodate the event.",
                "There is an inherent bias toward schedule stability which provides better support for the continuity in execution.",
                "This latter property is also advantageous in multi-agent settings, since solution stability tends to minimize the ripple across different agents schedules.",
                "The coupling of incremental scheduling with flexible times scheduling adds additional leverage in an uncertain, multiagent execution environment.",
                "As mentioned earlier, slack can be used as a hedge against uncertain method execution times.",
                "It also provides a basis for softening the impact of inter-dependencies across agents.",
                "In this section, we summarize the core scheduler that we have developed to solve the Coordinators problem.",
                "In subsequent sections we discuss its use in managing execution and coordinating with other agents. 4.1 STN Solution Representation To maintain the range of admissible values for the start and end times of various methods in a given agents sched486 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ule, all problem and scheduling constraints impacting these times are encoded in an underlying Simple Temporal Network (STN)[3].",
                "An STN represents temporal constraints as a graph G < N, E >, where nodes in N represent the set of time points of interest, and edges in E are distances between pairs of time points in N. A special time point, called calendar zero grounds the network and has the value 0.",
                "Constraints on activities (e.g. release time, due time, duration) and relationships between activities (e.g. parentchild relation, enables) are uniformly represented as temporal constraints (i.e., edges) between relevant start and finish time points.",
                "An agents schedule is designated as a total ordering of selected methods by posting precedence constraints between the end and start points of each ordered pair.",
                "As new methods are inserted into a schedule or external state updates require adjustments to existing constraints (e.g., substitution of an actual duration constraint, tightening of a deadline), the network propagates constraints and maintains lower and upper bounds on all time points in the network.",
                "This is accomplished efficiently via the use of a standard all-pairs shortest path algorithm; in our implementation, we take advantage of an incremental procedure based on [2].",
                "As bounds are updated, a consistency check is made for the presence of negative cycles, and the absence of any such cycle ensures the continued temporal feasibility of the network (and hence the schedule).",
                "Otherwise a conflict has been detected, and some amount of constraint retraction is necessary to restore feasibility. 4.2 Maintaining High-Quality Schedules The scheduler consists of two basic components: a quality propagator and an activity allocator that work in a tightly integrated loop.",
                "The quality propagator analyzes the activity hierarchy and collects a set of methods that (if scheduled) would maximize the quality of the agents local problem.",
                "The methods are collected without regard for resource contention; in essence, the quality propagator optimally solves a relaxed problem where agents are capable of performing an infinite number of activities at once.",
                "The allocator selects methods from this list and attempts to install them in the agents schedule.",
                "Failure to do so reinvokes the quality propagator with the problematic activity excluded.",
                "The Quality Propagator - The quality propagator performs the following actions on the C TAEMS task structure: • Computes the quality of all activities in the task structure: The expected quality qual(m) of a method m is computed from the probability distribution of the execution outcomes.",
                "The quality qual(t) of a task t is computed by applying its qaf to the assessed quality of its children. • Generates a list of contributors for each task: methods that, if scheduled, will maximize the quality obtained by the task. • Generates a list of activators for each task: methods that, if scheduled, are sufficient to qualify the task as scheduled.",
                "Methods in the activators list are chosen to minimize demands on the agents timeline without regard to quality.",
                "The first time the quality propagator is invoked, the qualities of all tasks and methods are calculated and the initial lists of contributors and activators are determined.",
                "Subsequent calls to the propagator occur as the allocator installs methods on the agents timeline: failure of the allocator to install a method causes the propagator to recompute a new list of contributors and activators.",
                "The Activity Allocator - The activity allocator seeks to install the contributors of the taskgroup identified by the quality propagator onto the agents timeline.",
                "Any currently scheduled methods that do not appear in the contributors list are first unscheduled and removed from the timeline.",
                "The contributors are then preprocessed using a quality-centric heuristic to create an agenda sorted in decreasing quality order.",
                "In addition, methods associated with a and task (i.e., min, sumand) are grouped consecutively within the agenda.",
                "Since an and task accumulates quality only if all its children are scheduled, this biases the scheduling process towards failing early (and regenerating contributors) when the methods chosen for the and cannot together be allocated.",
                "The allocator iteratively pops the first method mnew from the agenda and attempts to install it.",
                "This entails first checking that all activities that enable mnew have been scheduled, while attempting to install any enabler that is not.",
                "If any of the enabler activities fails to install, the allocation pass fails.",
                "When successful, the enables constraints linking the enabler activities to mnew are activated.",
                "The STN rejects an infeasible enabler constraint by returning a conflict.",
                "In this event any enabler activities it has scheduled are uninstalled and the allocator returns failure.",
                "Once scheduling of enablers is ensured, a feasible slot on the agents timeline within mnews time window is sought and the allocator attempts to insert mnew between two currently scheduled methods.",
                "At the STN level, mnews insertion breaks the sequencing constraint between the two extant timeline methods and attempts to insert two new sequencing constraints that chain mnew to these methods.",
                "If these insertions succeed, the routine returns success, otherwise the two extant timeline methods are relinked and allocation attempts the next possible slot for mnew insertion. 5.",
                "THE DYNAMICS OF EXECUTION Maintaining a flexible-times schedule enables us to use a conflict-driven approach to schedule repair: Rather than reacting to every event in the execution that may impact the existing schedule by computing an updated solution, the STN can absorb any change that does not cause a conflict.",
                "Consequently, computation (producing a new schedule) and communication costs (informing other agents of changes that affect them) are minimized.",
                "One basic mechanism needed to model execution in the STN is a dynamic model for current time.",
                "We employ a model proposed by [7] that establishes a current-time time point and includes a link between it and the calendar-zero time point.",
                "As each method is scheduled, a simple precedence constraint between the current-time time point and the method is established.",
                "When the scheduler receives a current time update, the link between calendar-zero and current-time is modified to reflect this new time, and the constraint propagates to all scheduled methods.",
                "A second issue concerns synchronization between the executor and the scheduler, as producer and consumer of the schedule running on different threads within a given agent.",
                "This coordination must be robust despite the fact that the The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487 executor needs to start methods for execution in real-time even while the scheduler may be reassessing the schedule to maximize quality, and/or transmitting a revised schedule.",
                "If the executor, for example, slates a method for execution based on current time while the scheduler is instantiating a revised schedule in which that method is no longer nextto-be-executed, an inconsistent state may arise within the agent architecture.",
                "This is addressed in part by introducing a freeze window; a specified short (and adjustable) time period beyond current time within which any activity slated as eligible to start in the current schedule cannot be rescheduled by the scheduler.",
                "The scheduler is triggered in response to various environmental messages.",
                "There are two types of environmental message classes that we discuss here as execution dynamics: 1) feedback as a result of method execution - both the agents own and that of other agents, and 2) changes in the C TAEMS model corresponding to a set of simulatordirected evolutions of the problem and environment.",
                "Such messages are termed updates and are treated by the scheduler as directives to permanently modify parameters in its model.",
                "We discuss these update types in turn here and defer until later the discussion of queries to the scheduler, a what-if mode initiated by a remote agent that is pursuing higher global quality.",
                "Whether it is invoked via an update or a query, the schedulers response is an option; essentially a complete schedule of activities the agent can execute along with associated quality metrics.",
                "We define a local option as a valid schedule for an agents activities, which does not require change to any other agents schedule.",
                "The overarching design for handling execution dynamics aims at anytime scheduling behavior in which a local option maximizing the local view of quality is returned quickly, possibly followed by globally higher quality schedules that entail inter-agent coordination if available scheduler cycles permit.",
                "As such, the default scheduling mode for updates is to seek the highest quality local option according to the schedulers search strategy, instantiate the option as its current schedule, and notify the executor of the revision. 5.1 Responding to Activity Execution As suggested earlier, a committed schedule consists of a sequence of methods, each with a designated [est, lst] start time window (as provided by the underlying STN representation).",
                "The executor is free to execute a method any time within its start time window, once any additional enabling conditions have been confirmed.",
                "These scheduled start time windows are established using the expected duration of each scheduled method (derived from associated method duration distributions during schedule construction).",
                "Of course as execution unfolds, actual method durations may deviate from these expectations.",
                "In these cases, the flexibility retained in the schedule can be used to absorb some of this unpredictability and modulate invocation of a schedule revision process.",
                "Consider the case of a method completion message, one of the environmental messages that could be communicated to the scheduler as an execution state update.",
                "If the completion time is coincident with the expected duration (i.e., it completes exactly as expected), then the schedulers response is to simply mark it as completed and the agent can proceed to communicate the time at which it has accumulated quality to any remote agents linked to this method.",
                "However if the method completes with a duration shorter than expected a rescheduling action might be warranted.",
                "The posting of the actual duration in the STN introduces no potential for conflict in this case, either with the latest start times (lsts) of local or remote methods that depend on this method as an enabler, or to successively scheduled methods on the agents timeline.",
                "However, it may present a possibility for exploiting the unanticipated scheduling slack.",
                "The flexible times representation afforded by the STN provides a quick means of assessing whether the next method on the timeline can begin immediate execution instead of waiting for its previously established earliest start time (est).",
                "If indeed the est of the next scheduled method can spring back to current-time once the actual duration constraint is substituted for the expected duration constraint, then the schedule can be left intact and simply communicated back to the executor.",
                "If alternatively, other problem constraints prevent this relaxation of the est, then there is forced idle time that may be exploited by revising the schedule, and the scheduler is invoked (always respecting the freeze period).",
                "If the method completes later than expected, then there is no need for rescheduling under flexible times scheduling unless 1) the method finishes later than the lst of the subsequent scheduled activity, or 2) it finishes later than its deadline.",
                "Thus we only invoke the scheduler if, upon posting the late finish in the STN, a constraint violation occurs.",
                "In the latter case no quality is accrued and rescheduling is mandated even if there are no conflicts with subsequent scheduled activities.",
                "Other execution status updates the agent may receive include: • method start - If a method sent for execution is started within its [est, lst] window, the response is to mark it as executing.",
                "A method cannot start earlier than when it is transmitted by the executor but it is possible for it to start later than requested.",
                "If the posted start time causes an inconsistency in the STN (e.g. because the expected method duration can no longer be accommodated) the duration constraint in the STN is shortened based on the known distribution until either consistency is restored or rescheduling is mandated. • method failure - Any method under execution may fail unexpectedly, garnering no quality for the agent.",
                "At this point rescheduling is mandated as the method may enable other activities or significantly impact quality in the absence of local repair.",
                "Again, the executor will proceed with execution of the next method if its start time arrives before the revised schedule is committed, and the scheduler accommodates this by respecting the freeze window. • current time advances An update on current time may arrive either alone or as part of any of the previously discussed updates.",
                "If, when updating the currenttime link in the STN (as described above), a conflict results, the execution state is inconsistent with the schedule.",
                "In this case, the scheduler proceeds as if execution were consistent with its expectations, subject to possible later updates. 488 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 5.2 Responding to Model Updates The agent can also dynamically receive changes to the agents underlying C TAEMS model.",
                "Dynamic revisions in the outcome distributions for methods already in an agents subjective view may impact the assessed quality and/or duration values that shaped the current schedule.",
                "Similarly, dynamic revisions in the designated release times and deadlines for methods and tasks already in an agents subjective view can invalidate an extant schedule or present opportunities to boost quality.",
                "It is also possible during execution to receive updates in which new methods and possibly entire task structures are given to the agent for inclusion in its subjective view.",
                "Model changes that involve temporal constraints are handled in much the same fashion as described for method starts and completions, i.e, rescheduling is required only when the posting of the revised constraints leads to an STN conflict.",
                "In the case of non-temporal model changes, rescheduling action is currently always initiated. 6.",
                "INTER-AGENT COORDINATION Having responded locally to an unexpected execution result or model change, it is necessary to communicate the consequences to agents with inter-dependent activities so that they can align their decisions accordingly.",
                "Responses that look good locally may have a sub-optimal global effect once alignments are made, and hence agents must have the ability to seek mutually beneficial joint schedule changes.",
                "In this section we summarize the coordination mechanisms provided in the agent architecture to address these issues. 6.1 Communicating Non-Local Constraints A basic means of coordination with other agents is provided by the Distributed State Mechanism (DSM), which is responsible for communicating changes made to the model or schedule of a given agent to other interested agents.",
                "More specifically, the DSM of a given agent acts to push any changes made to the time bounds, quality, or status of a local task/method to all the other agents that have that same task/method as a remote node in their subjective views.",
                "A recipient agent treats any communicated changes as additional forms of updates, in this case an update that modifies the current constraints associated with non-local (but inter-dependent) tasks or methods.",
                "These changes are handled identically to updates reflecting schedule execution results, potentially triggering the local scheduler if the need to reschedule is detected. 6.2 Generating Non-Local Options As mentioned in the previous section, the agents first response to any given query or update (either from execution or from another agent) is to generate one or more local options.",
                "Such options represent local schedule changes that are consistent with all currently known constraints originating from other agents schedules, and hence can be implemented without interaction with other agents.",
                "In many cases, however, a larger-scoped change to the schedules of two or more agents can produce a higher-quality response.",
                "Exploration of opportunities for such coordinated action by two or more agents is the responsibility of the Options Manager.",
                "Running in lower priority mode than the Executor and Scheduler, the Options Manager initiates a non-local option generation and evaluation process in response to any local schedule change made by the agent if computation time constraints permits.",
                "Generally speaking, a non-local option identifies certain relaxations (to one or more constraints imposed by methods that are scheduled by one or more remote agents) that enable the generation of a higher quality local schedule.",
                "When found, a non-local option is used by a coordinating agent to formulate queries to any other involved agents in order to determine the impact of such constraint relaxations on their local schedules.",
                "If the combined quality change reported back from a set of one or more relevant queries is a net gain, then the issuing agent signals to the other involved agents to commit to this joint set of schedule changes.",
                "The Option Manager currently employs two basic search strategies for generating non-local options, each exploiting the local scheduler in hypothetical mode.",
                "Optimistic Synchronization - Optimistic synchronization is a non-local option generation strategy where search is used to explore the impact on quality if optimistic assumptions are made about currently unscheduled remote enablers.",
                "More specifically, the strategy looks for would be contributor methods that are currently unscheduled due to the fact that one or more remote enabling (source) tasks or methods are not currently scheduled.",
                "For each such local method, the set of remote enablers are hypothetically activated, and the scheduler attempts to construct a new local schedule under these optimistic assumptions.",
                "If successful, a non-local option is generated, specifying the value of the new, higher quality local schedule, the temporal constraints on the local target activity, and the set of must-schedule enabler activities that must be scheduled by remote agents in order to achieve this local quality.",
                "The needed queries requesting the quality impact of scheduling these activities are then formulated and sent to the relevant remote agents.",
                "To illustrate, consider again the example in Figure 1.",
                "The maximum quality that Agent1 can contribute to the task group is 15 (by scheduling M1, M2 and M3).",
                "Assume that this is Agent1s current schedule.",
                "Given this state, the maximum quality that Agent2 can contribute to the task group is 10, and the total task group quality would then be 15 + 10 = 25.",
                "Using optimistic synchronization, Agent2 will generate a non-local option that indicates that if M5 becomes enabled, both M5 and M6 would be scheduled, and the quality contributed by Agent2 to the task group would become 30.",
                "Agent2 sends a must schedule M4 query to Agent1.",
                "Because of the time window constraints, Agent1 must remove M3 from its schedule to get M4 on, resulting in a new lower quality schedule of 5.",
                "However, when Agent2 receives this option response from Agent1, it determines that the total quality accumulated for the task group would be 5 + 30 = 35, a net gain of 10.",
                "Hence, Agent 2 signals to Agent1 to commit to this non-local option.",
                "Conflict-Driven Relaxation - A second strategy for generating non-local options, referred to as Conflict-Directed Relaxation, utilizes analysis of STN conflicts to identify and prioritize external constraints to relax in the event that a particular method that would increase local quality is found to be unschedulable.",
                "Recall that if a method cannot be feasibly inserted into the schedule, an attempt to do so will generate a negative cycle.",
                "Given this cycle, the mechanism proceeds in three steps.",
                "First, the constraints involved in the cycle are collected.",
                "Second, by virtue of the connections in the STN to the domain-level C TAEMS model, this set is filtered to identify the subset associated with remote nodes.",
                "Third, constraints in this subset are selectively retracted to The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489 Figure 4: A high quality task is added to the task structure of Agent2.",
                "Figure 5: If M4, M5 and M7 are scheduled, a conflict is detected by the STN. determine if STN consistency is restored.",
                "If successful, a non-local option is generated indicating which remote constraint(s) must be relaxed and by how much to allow installation of the new, higher quality local schedule.",
                "To illustrate this strategy, consider Figure 5 where Agent1 has M1, M2 and M4 on its timeline, and therefore est(M4) = 21.",
                "Agent2 has M5 and M6 on its timeline, with est(M5) = 31 (M6 could be scheduled before or after M5).",
                "Suppose that Agent2 receives a new task M7 with deadline 55 (see Figure 4).",
                "If Agent2 could schedule M7, the quality contributed by Agent2 to the task group would be 70.",
                "However, an attempt to schedule M7 together with M5 and M6 leads to a conflict, since the est(M7) = 46, dur(M7) = 10 and lft(M7) = 55 (see Figure 5).",
                "Conflict-directed relaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick to 30, and this query is communicated to Agent 1.",
                "In fact, by retracting either method M1 or M2 from the schedule this relaxation can be accommodated with no quality loss to Agent1 (due to the min qaf).",
                "Upon communication of this fact Agent 2 signals to commit. 7.",
                "EXPERIMENTAL RESULTS An initial version of the agent described in this paper was developed in collaboration with SRI International and subjected to the independently conducted Coordinators programmatic evaluation.",
                "This evaluation involved over 2000 problem instances randomly generated by a scenario generator that was configured to produce scenarios of varying Problem Class Description Agent Class Quality OD Only Dynamics.",
                "No NLEs. 97.9% (390 probs) Actual task duration & quality vary according to distribution.",
                "INT Interdependent.",
                "Frequent & 100% (360 probs) random (esp. facilitates) CHAINS Activities chained together 99.5% (360 probs) via sequences of enables NLEs (1-4 chains/prob) TT Temporal Tightness.",
                "Release - 94.9% (360 probs) Deadline windows preclude preferred high quality (longest duration) tasks from all being scheduled.",
                "SYNC Problems contain range of 97.1% (360 probs) different Sync sum tasks NTA New Task Arrival. cTaems 99.0% (360 probs) model is augmented with new tasks dynamically during run.",
                "OVERALL Avg: 98.1% (2190 probs) Std dev: 6.96 Table 1: Performance of year 1 agent over Coordinators evaluation.",
                "Agent Quality is % of optimal durations within six experiment classes.",
                "These classes, summarized in Table 1, were designed to evaluate key aspects of a set of Coordinators distributed scheduling agents, such as their ability to handle unexpected execution results, chains of nles involving multiple agents, and effective scheduling of new activities that arise unexpectedly at some point during the problem run.",
                "Year 1 evaluation problems were constrained to be small enough (3 -10 agents, 50 - 100 methods) such that comparison against an optimal centralized solver was feasible.",
                "The evaluation team employed an MDP-based solver capable of unrolling the entire search space for these problems, choosing for an agent at each execution decision point the activity most likely to produce maximum global quality.",
                "This established a challenging benchmark for the distributed agent systems to compare against.",
                "The hardware configuration used by the evaluators instantiated and ran one agent per machine, dedicating a separate machine to the MASS simulator.",
                "As reported in Table 1, the year 1 prototype agent clearly compares favorably to the benchmark on all classes, coming within 2% of the MDP optimal averaged over the entire set of 2190 problems.",
                "These results are particularly notable given that each agents STN-based scheduler does very little reasoning over the success probability of the activity sequences it selects to execute.",
                "Only simple tactics were adopted to explicitly address such uncertainty, such as the use of expected durations and quality for activities and a policy of excluding from consideration those activities with failure likelihood of >75%.",
                "The very respectable agent performance can be at least partially credited to the fact that the flexible times representation employed by the scheduler affords it an important buffer against the uncertainty of execution and exogenous events.",
                "The agent turns in its lowest performance on the TT (Temporal Tightness) experiment classes, and an examination of the agent trace logs reveals possible reasons.",
                "In about half of the TT problems the year 1 agent under-performs on, the specified time windows within which an agents ac490 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) tivities must be scheduled are so tight that any scheduled activity which executes with a longer duration than the expected value, causes a deadline failure.",
                "This constitutes a case where more sophisticated reasoning over success probability would benefit this agent.",
                "The other half of underperforming TT problems involve activities that depend on facilitation relationships in order to fit in their time windows (recall that facilitation increases quality and decreases duration).",
                "The limited facilitates reasoning performed by the year 1 scheduler sometimes causes failures to install a heavily facilitated initial schedule.",
                "Even when such activities are successfully installed they tend to be prone to deadline failures -If a source-side activity(s) either fails or exceeds its expected duration the resulting longer duration of the target activity can violate its time window deadline. 8.",
                "STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems.",
                "Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods.",
                "This scale places much higher computational demands on all of the agents components.",
                "We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues.",
                "In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems.",
                "To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms.",
                "To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes.",
                "To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity.",
                "Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling [7] to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules. 9.",
                "ACKNOWLEDGEMENTS The Year 1 agent architecture was developed in collaboration with Andrew Agno, Roger Mailler and Regis Vincent of SRI International.",
                "This paper is based on work supported by the Department of Defense Advance Research Projects Agency (DARPA) under Contract # FA8750-05-C0033.",
                "Any opinions findings and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of DARPA. 10.",
                "REFERENCES [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A.",
                "Long, and B. Kohout.",
                "C taems language specification v. 1.06, October 2005. [2] A. Cesta and A. Oddi.",
                "Gaining efficiency and flexibility in the simple temporal problem.",
                "In Proc. 3rd Int.",
                "Workshop on Temporal Representation and Reasoning, Key West FL, May 1996. [3] R. Dechter, I. Meiri, and J. Pearl.",
                "Temporal constraint networks.",
                "Artificial Intelligence, 49:61-95, May 1991. [4] K. Decker.",
                "TÆMS: A framework for environment centered analysis & design of coordination mechanisms.",
                "In G. OHare and N. Jennings, editors, Foundations of Distributed Artificial Intelligence, chapter 16, pages 429-448.",
                "Wiley Inter-Science, 1996. [5] K. Decker and V. Lesser.",
                "Designing a family of coordination algorithms.",
                "In Proc. 1st.",
                "Int.",
                "Conference on Multi-Agent Systems, San Francisco, 1995. [6] A. J. Garvey.",
                "Design-To-Time Real-Time Scheduling.",
                "PhD thesis, Univ. of Massachusetts, Feb. 1996. [7] L. Hunsberger.",
                "Algorithms for a temporal decoupling problem in multi-agent planning.",
                "In Proc. 18th National Conference on AI, 2002. [8] S. Lemai and F. Ingrand.",
                "Interleaving temporal planning and execution in robotics domains.",
                "In Proc. 19th National Conference on AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams.",
                "Remote agent: To boldly go where no AI system has gone before.",
                "Artificial Intelligence, 103(1-2):5-47, 1998. [10] W. Ruml, M. B.",
                "Do, and M. Fromherz.",
                "On-line planning and scheduling of high-speed manufacturing.",
                "In Proc.",
                "ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, and B. Williams.",
                "Enabling fast flexible planning through incremental temporal reasoning with conflict extraction.",
                "In Proce.",
                "ICAPS-05, Monterey, 2005. [12] S. Smith and C. Cheng.",
                "Slack-based heuristics for constraint satisfaction scheduling.",
                "In Proc. 12th National Conference on AI, Wash DC, July 1993. [13] T. Wagner, A. Garvey, and V. Lesser.",
                "Criteria-directed heuristic task scheduling.",
                "International Journal of Approximate Reasoning, 19(1):91-118, 1998.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491"
            ],
            "original_annotated_samples": [
                "OVERVIEW OF APPROACH Our solution framework combines two basic principles for coping with the problem of managing <br>multi-agent schedule</br>s in an uncertain and time stressed execution environment."
            ],
            "translated_annotated_samples": [
                "RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar <br>horarios de múltiples agentes</br> en un entorno de ejecución incierto y bajo presión de tiempo."
            ],
            "translated_text": "Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar <br>horarios de múltiples agentes</br> en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea \"and\" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el \"and\" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de \"qué pasaría si\" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}